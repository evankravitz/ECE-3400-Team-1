<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Team 1!</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Kaushan+Script' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700' rel='stylesheet' type='text/css'>

    <!-- Custom styles for this template -->
    <link href="css/agency.min.css" rel="stylesheet">

  </head>

  <body id="page-top">

    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-dark fixed-top" id="mainNav">
      <div class="container">
        <a class="navbar-brand js-scroll-trigger" href="#page-top"> <img class="col-sm-2"  src="./resources/origthird.PNG" alt="">ECE 3400, Fall 2017 </a>
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          Menu
          <i class="fa fa-bars"></i>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav text-uppercase ml-auto">
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#labs">Labs</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#team">Logistics</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger"  href="#about">About</a>
            </li>
            <li class="nav-item">
              <a class="nav-link"  href="https://github.com/evankravitz/ECE-3400-Team-1">GitHub</a>
            </li>


          </ul>
        </div>
      </div>
    </nav>

    <!-- Header -->
    <header class="masthead">
      <div class="container">
        <div class="intro-text">
          <div class="intro-lead-in">Bringing Destruction and Chaos to All of Mankind, It's...</div>
          <div class="intro-heading text-uppercase">Team One: The One-Ders!</div>
          <a class="btn btn-primary btn-xl text-uppercase js-scroll-trigger" href="#labs">Click Here To Eat<br>Our Robot's Dust</a>
                 <div class = "text-center"> Our robot won third place for his maze mapping, and has now retired to a farm upstate</div>
        </div>

      </div>
    </header>

    <!-- Portfolio Grid -->
    <section class="bg-light" id="labs">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading text-uppercase"> Labs and Milestones  </h2>
            <h3 class="section-subheading text-muted">"Work Work Work Workwork Workworkworkworkwork" - Rihanna</h3>
          </div>
        </div>
        <div class="row">
          <div class="col-md-3 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal1">
              <div class="portfolio-hover">
                <div class="portfolio-hover-content">
                </div>
              </div>
              <img class="img-fluid" src="img/portfolio/01-thumbnail.gif" alt="">
            </a>
            <div class="portfolio-caption">
              <h4>Lab 1</h4>
              <p class="text-muted">Learning what soul-crushing disappointment is like</p>
            </div>
          </div>
          <div class="col-md-3 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal2">
              <div class="portfolio-hover">
                <div class="portfolio-hover-content">
                </div>
              </div>
              <img class="img-fluid" src="img/portfolio/02-thumbnail.gif" alt="">
            </a>
            <div class="portfolio-caption">
              <h4>Lab 2</h4>
              <p class="text-muted">Fighting the good fight</p>
            </div>
          </div>
          <div class="col-md-3 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal3">
              <div class="portfolio-hover">
                <div class="portfolio-hover-content">
                </div>
              </div>
              <img class="img-fluid" src="img/portfolio/03-thumbnail.gif" alt="">
            </a>
            <div class="portfolio-caption">
              <h4>Lab 3</h4>
              <p class="text-muted">Growing as a robot</p>
            </div>
          </div>
          <div class="col-md-3 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal4">
              <div class="portfolio-hover">
                <div class="portfolio-hover-content">
                </div>
              </div>
              <img class="img-fluid" src="img/portfolio/04-thumbnail.gif" alt="">
            </a>
            <div class="portfolio-caption">
              <h4>Lab 4</h4>
              <p class="text-muted">Confusing madness for happiness</p>
            </div>
          </div>
          <div class="col-md-3 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal5">
              <div class="portfolio-hover">
                <div class="portfolio-hover-content">
                </div>
              </div>
              <img class="img-fluid" src="img/portfolio/05-thumbnail.gif" alt="">
            </a>
            <div class="portfolio-caption">
              <h4>Milestone 1</h4>
              <p class="text-muted">False hope</p>
            </div>
          </div>
          <div class="col-md-3 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal6">
              <div class="portfolio-hover">
                <div class="portfolio-hover-content">
                </div>
              </div>
              <img class="img-fluid" src="img/portfolio/06-thumbnail.gif" alt="">
            </a>
            <div class="portfolio-caption">
              <h4>Milestone 2</h4>
              <p class="text-muted">Existential crisis</p>
            </div>
          </div>
          <div class="col-md-3 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal10">
              <div class="portfolio-hover">
                <div class="portfolio-hover-content">
                </div>
              </div>
              <img class="img-fluid" src="img/portfolio/07-thumbnail.gif" alt="">
            </a>
            <div class="portfolio-caption">
              <h4>Milestone 3</h4>
              <p class="text-muted">Renaissance robot</p>
            </div>
          </div>
          <div class="col-md-3 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal11">
              <div class="portfolio-hover">
                <div class="portfolio-hover-content">
                </div>
              </div>
              <img class="img-fluid" src="img/portfolio/robot.gif" alt="">
            </a>
            <div class="portfolio-caption">
              <h4>Milestone 4</h4>
              <p class="text-muted">Machiavellian ascension to power</p>
            </div>
          </div>
                  

         <div class="col-md-3 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal13">
              <div class="portfolio-hover">
                <div class="portfolio-hover-content">
                </div>
              </div>
              <img class="img-fluid" src="img/portfolio/final.gif" alt="">
            </a>
            <div class="portfolio-caption">
              <h4>Final Implemented Design</h4>
              <p class="text-muted">It's too late to go back now</p>
            </div>
          </div>

            <div class="col-md-3 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal12">
              <div class="portfolio-hover">
                <div class="portfolio-hover-content">
                </div>
              </div>
              <img class="img-fluid" src="img/portfolio/ethicsbot.gif" alt="">
            </a>
            <div class="portfolio-caption">
              <h4>Ethics Homework</h4>
              <p class="text-muted">Autonomous vehicles</p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Services -->
    <section id="team">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading text-uppercase">Team Logistics</h2>
            <h3 class="section-subheading text-muted"> Here's how we got to know our way around an Arduino</h3>
          </div>
        </div>
        <div class="row text-center">
          <div class="col-md-4 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal9">
              <div class="portfolio-hover">
                <div class="portfolio-hover-content">
                </div>
              </div>
              <span class="fa-stack fa-4x">
                <i class="fa fa-circle fa-stack-2x text-info"></i>
                <i class="fa fa-hand-peace-o fa-stack-1x fa-inverse"></i>
              </span>
              <h4 class="service-heading">Team Contract</h4>

            </a>
            <div class="portfolio-caption">
              <p class="text-muted">All men need laws to govern themselves, or they are in danger of leading nasty, brutish, and short lives. Robots, on the other hand, need no such thing. But alas, we are mere mortals so here are some rules that we hold each other to. </p>
            </div>
          </div>
          <div class="col-md-4 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal7">
              <div class="portfolio-hover">
                <div class="portfolio-hover-content">
                </div>
              </div>
              <span class="fa-stack fa-4x">
                <i class="fa fa-circle fa-stack-2x text-info"></i>
                <i class="fa fa-android fa-stack-1x fa-inverse"></i>
              </span>
              <h4 class="service-heading">Meet the Wonder Bot</h4>

            </a>
            <div class="portfolio-caption">
              <p class="text-muted">Face your fears: a robot so advanced, so intelligent, so fearsome, that it can easily collapse nations and rip families apart at their seams.</p>
            </div>
          </div>

          <iv class="col-md-4 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal8">
              <div class="portfolio-hover">
                <div class="portfolio-hover-content">
                 </div>
              </div>
              <span class="fa-stack fa-4x">
                <i class="fa fa-circle fa-stack-2x text-info"></i>
                <i class="fa fa-clock-o fa-stack-1x fa-inverse"></i>
              </span>
              <h4 class="service-heading">Meeting Minutes</h4>

            </a>
            <div class="portfolio-caption">
              <p class="text-muted">We spend a lot of time with each other. We even count the seconds! 

              This is a log of every magical moment.</p>
            </div>
          </div>
        </div>
      </div>  
    </section>


 
    <!-- Team -->
    <section class="bg-light" id="about">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading text-uppercase">The Dream Team</h2>
            <h3 class="section-subheading text-muted">Together, we are your worst nightmare </h3>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-4">
            <div class="team-member">
              <img class="mx-auto rounded-circle" src="img/team/1.jpg" alt="">
              <h4>Evan Kravitz</h4>
              <p class="text-muted">esk95</p>
            </div>
          </div>
          <div class="col-sm-4">
            <div class="team-member">
              <img class="mx-auto rounded-circle" src="img/team/2.jpeg" alt="">
              <h4>Michael Solomentsev</h4>
              <p class="text-muted">mys29</p>
            </div>
          </div>
          <div class="col-sm-4">
            <div class="team-member">
              <img class="mx-auto rounded-circle" src="img/team/3.jpg" alt="">
              <h4>Jeffrey Hurd</h4>
              <p class="text-muted">jjh353</p>
            </div>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-4">
            <div class="team-member">
              <img class="mx-auto rounded-circle" src="img/team/4.png" alt="">
              <h4>Radhika Chinni</h4>
              <p class="text-muted">rpc222</p>

            </div>
          </div>
          <div class="col-sm-4">
            <div class="team-member">
              <img class="mx-auto rounded-circle" src="img/team/5.jpeg" alt="">
              <h4>Frances Koback</h4>
              <p class="text-muted">flk26</p>

            </div>
          </div>
          <div class="col-sm-4">
            <div class="team-member">
              <img class="mx-auto rounded-circle" src="img/team/6.jpg" alt="">
              <h4>Katherine Lu</h4>
              <p class="text-muted">kl645</p>

            </div>
          </div>
        </div>
        <div class="row">
          <div class="col-lg-8 mx-auto text-center">
            <p class="large text-muted">"Cause the players gonna play, play, play, play, play.     And the haters gonna hate, hate, hate, hate, hate.
             - Taylor Swift</p>
          </div>
        </div>
      </div>
    </section>

    <!-- Clients -->
    <section class="py-5">
      <div class="container">
        <div class="row">
          <div class="col-md-3 col-sm-6">
            <a href="#">
              <img class="img-fluid d-block mx-auto" src="./resources/thirdplace.PNG" alt="">
            </a>
          </div>
          <div class="col-md-3 col-sm-6">
            <a href="#">
              <img class="img-fluid d-block mx-auto" src="./resources/thirdplace.PNG" alt="">
            </a>
          </div>
          <div class="col-md-3 col-sm-6">
            <a href="#">
              <img class="img-fluid d-block mx-auto" src="./resources/thirdplace.PNG" alt="">
            </a>
          </div>
          <div class="col-md-3 col-sm-6">
            <a href="#">
              <img class="img-fluid d-block mx-auto" src="./resources/thirdplace.PNG" alt="">
            </a>
          </div>
        </div>
      </div>
    </section>



    <!-- Footer -->
    <footer>
      <div class="container">
        <div class="row">
          <div class="col-md-4">
            <span class="copyright">Copyright &copy; Your Website 2017</span>
          </div>
          <div class="col-md-4">
            <ul class="list-inline social-buttons">
              <li class="list-inline-item">
                <a href="#">
                  <i class="fa fa-twitter"></i>
                </a>
              </li>
              <li class="list-inline-item">
                <a href="#">
                  <i class="fa fa-facebook"></i>
                </a>
              </li>
              <li class="list-inline-item">
                <a href="#">
                  <i class="fa fa-linkedin"></i>
                </a>
              </li>
            </ul>
          </div>
          <div class="col-md-4">
            <ul class="list-inline quicklinks">
              <li class="list-inline-item">
                <a href="#">Privacy Policy</a>
              </li>
              <li class="list-inline-item">
                <a href="#">Terms of Use</a>
              </li>
            </ul>
          </div>
        </div>
      </div>
    </footer>

    <!-- Portfolio Modals -->

   <div class="portfolio-modal modal fade" id="portfolioModal12" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row text-left">
              <div class="col-lg-8 mx-auto">
                <div class="modal-body">
                  <li>11/13 Ethics Conversation Transcript:</li>
<li>Present: all</li>

<ul>
<li>Quiet morning today, little conversation</li>
<li>I wonder what everyone is thinking about</li>
<li>Topic: self driving cars/fatalities</li>
<li>background info - who knows what</li>
<li>TJ: Issue is that these autonomous cars are still being developed, what should be done when they are on the road</li>
<li>https://www.theguardian.com/technology/2016/jun/30/tesla-autopilot-death-self-driving-car-elon-musk ← Kirsten’s link</li>
<li>Radhika: MIT article: https://www.technologyreview.com/s/542626/why-self-driving-cars-must-be-programmed-to-kill/  </li>
<li>Another interesting article: https://qz.com/1061476/germanys-new-regulations-on-self-driving-cars-means-autonomous-vehicles-wont-compare-human-lives/</li>
<li>Talks about benefits - but starts talking about the dilemma of who should be killed when car has to choose</li>
<li>Like what if the car has to choose btw killing occupants or pedestrians</li>
<li>TJ notes that the Tesla car was just a tech failure</li>
<li>Katherine and Frannie ask whether there is a moral issue w/ the Tesla example</li>
<li>Radhika says regular cars have defects too</li>
<li>Evan says that the tech just needs to be developed better </li>
<li>Frannie: When you drive you have responsibility of killing yourself vs. pedestrian - in autonomous car you’ve given your trust to computer</li>
<li>Michael: Suggests that we narrow discussion to either Tesla example (manufacturer error) or this other issue of who to kill</li>
<li>Radhika and Katherine: They are inter-related issues, need to trust car in first place (Tesla) to have this discussion about who at fault/who should be killed</li>
<li>Frannie: Ford(?) acceleration bug</li>
<li>Everyone talks over everyone - I can’t take notes</li>
<li>We refocus - what is the specific issue we want to talk about</li>
<li>We decide: Who’s to blame when faulty car programming kills someone: Car company, driver?</li>
<li>Evan: this is a good general example, seems more applicable/common in real life as cars get more popular</li>
<li>Utilitarian test:</li>
<li>Katherine: Not really multiple people affected, more just one person injured and the car company affected</li>
<li>Frannie: suggests everyone switching to autonomous could increase safety, there’s a big util impact</li>
<li>Group discussion: everyone is gonna zone out when driving self driving cars, no one will every pay attention</li>
<li>Michael: what about if we use justice test?</li>

<li>Radhika: using the justice test might be a bit too narrow, big issue and want to consider all stakeholders</li>
<li>Katherine: Virtue test also seems to be extremely narrow. Tons of actors whose morals don’t align. Actually not even sure where to start.</li>
<li>We decide to use utilitarian test</li>
<li>TJ!: Let’s define the stakeholders</li>
<li>Radhika: Driver - their decision to drive the car, they get hurt/die</li>
<li>TJ: Pedestrians/other people on the road - could be hit, involved in accident</li> 
<li>Katherine: Car companies - huge financial incentive to not hurt anyone, potentially liable for deaths of individuals in the cars</li>
<li>Katherine: People who can’t drive - people who would get great benefits</li>
<li>Michael: Future ‘drivers’ - everyone who would potentially use self driving cars in the future</li>
<li>Whoops we skipped a step</li>
<li>What are other actions?</li>
<li>Choice btw slowly moving to self-driving cars, testing them more fully before releasing, or never having them</li>
<li>Evaluate options</li>

<li>First one: Status quo (slowly rolling out self driving cars)</li>
<li>Harm: Having potential events like Tesla accident</li>
<li>Benefit: get more testing on the road! Potentially make way safer</li>
<li>Benefit: self driving cars are on the road, making things easier/more convenient</li>

<li>Option 2: Never have any self driving cars</li>
<li>Benefits: Don’t risk peoples lives using self driving technology</li>
<li>Benefits: Don’t have to put up with any public dissent to self-driving tech</li>
<li>Costs: would give up the opportunity to develop safer roads, people who are unable to drive could not ever drive </li>
<li>Cost: could get a ton of economic benefits from self driving car technologies</li>

<li>Option 3: Fully testing self driving cars to determine fully whether they are safe</li>
<li>Benefits: Public safety, still have self driving cars</li>
<li>Benefit: Less people die? Maybe?</li>
<li>Costs: Hinder innovation</li>
<li>Costs: Take longer to actually get it tested without live scenarios</li>
<li>Costs: Self driving car companies would push back a ton</li>

<li>What would happen if the option 1 became a policy for all similar situations  </li>
<li>Should any new technology be tested on the public, before its 100% tested?</li>
<li>Medical trials example - willing participants</li>
<li> Some difference - everyone on the road is not a willing participant</li>
<li>Yes, for all similar situations with reasonable level of danger (about the same as current technology) </li>

<li> Drawing a conclusion: </li> 
<li>Status Quo: Within reasonable safety standards, slowly introducing self-driving technology to the public is fair. </li>
<li>Seems like status quo is best balance between safety of drivers and safely developing technology that will be able to protect drivers in the future</li>
</ul>

                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fa fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    
    
   <div class="portfolio-modal modal fade" id="portfolioModal13" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row text-left">
              <div class="col-lg-8 mx-auto">
                <div class="modal-body">
                 
                      <h2 class="text-center"> <img class="img-fluid img-left"  src="./resources/thirdplace.PNG" alt=""> Final Design <img class="img-fluid img-right"  src="./resources/thirdplace.PNG" alt=""></h2> 
                      

                   <h3>Introduction</h3>
                    <p>The goal of this project was to build an intelligent physical system that can perceive, reason about, and act upon its environment. The system took the form of a maze-mapping robot that can: </p>

                    <ul style="list-style-type:circle">
                      <li>Start on a 660 Hz tone</li>
                      <li>Traverse a grid consisting of black lines</li>
                      <li>Detect and avoid walls</li>
                      <li>Detect and distinguish treasure of different frequencies (an IR beacon)</li>
                      <li>Display progress through the maze on a screen</li>
                      <li>Signal that the robot is finished visually on the screen and with a three-tone audio signal</li>
                    </ul>

                    <p> Details of the maze specifications and final competition guidelines can be found <a href="https://github.com/CEI-lab/ece3400">here</a> on the course webpage.

                    <p>Thus, our robot met all the criteria of an intelligent physical system.
                    <ul style="list-style-type:circle">
                      <li>First, it perceives its environment through an array of different sensors needed to navigate the maze, including microphones, infrared proximity sensors, reflectance sensors and phototransistors.</li>
                      <li>Second, it reasons about its environment through the code we’ve written and uploaded to the Arduino Uno microcontroller. This includes data processing using Fast Fourier Transforms, updating an internal map of its surroundings stored in a 2-D array, and deciding which location to move to based on a depth-first search algorithm.</li>
                      <li>Finally, it acts on it environment by moving through and mapping the maze.</li>
                    </ul>
                    <p> Here's a video of our robot completing a full sucessful run of a maze! </p>
                    <iframe class = text-center width="560" height="315" src="https://www.youtube.com/embed/MrBVSf_K_ng" frameborder="0" allowfullscreen></iframe><br>
    
      
        <p> 
      Here's some pictures of our completed robot! All the various parts have been labeled.
                    <div class = "row"> <div class = "col-md-4"> <img class = "img-fluid" src="./resources/front_bot.JPG" alt=""> </div>
                    <div class = "col-md-4"><img class="img-fluid" src="./resources/side_bot.JPG" alt=""> </div>
                    <div class="col-md-4"> <img class ="img-fluid" src="./resources/back_bot.JPG" alt=""> </div> </div>
      </p>

                   <h3>Physical Robot Design</h3>
                    <p>Our robot was approximately 16 cm tall, 16 cm wide (20 cm if you include the width added by the treasure sensors), and 19 cm long. Our chassis, wheels, ball caster, and all mounts were the default designs provided to us at the start of the semester (the cad and .stl files necessary to make them are available on the <a href="https://github.com/CEI-lab/ece3400">course/TA GitHub</a>). We used the standard servos made available to us (Parallax Continuous Rotation Servos). We added rubber tires to the wheels to increase traction. We spent the majority of time working on the electronic components of the project.</p>

                    <p>We had two separate power sources for our robot (united only by a common ground). A 9V battery powered our Arduino. We mounted it using velcro to some free real estate on our chassis. The Arduino 5V and 3V pins were then used to power much of the circuitry. All the sensors mounted on the PCB and protoboard were powered off of these pins (IR sensors, their corresponding amplifiers, microphone, and the Schmitt trigger). These pins can source at least a few hundred mA of current, and by our calculations we drew much less than that (cumulatively less than 20mA). We also powered our system off of a 5V power bank. We temporarily placed the power bank underneath the Arduino (raised on makeshift stilts). We built around it, and this became its final position on the robot. A USB cable fed the power to two power rails positioned on either side of the protoboard. While we did have header pins soldered onto these power rails, they proved to be an extremely ineffective variety that led to many loose wires and much frustration. We bypassed these headers by simply soldering the power lines of the line sensors, servos, and wall sensors. While this removed much of our ability to make changes to the robot, we did this at a very late stage in the process, so it did not end up being a problem. Rather, because there were two power rails, it allowed us to clean up wiring significantly.</p>

                    <p>As one can see from the images above, we had two additional boards for circuitry - a protoboard and a PCB. The protoboard had three 'systems' on it. It had a Schmitt Trigger, which converted the analog input from the junction line sensor into a digital signal (see the Milestone 4 page for a full description of the circuit). It also had a manual start button, which simply connected 3.3V to an input pin (with a resistor in series, of course) creating an active high button we could poll. Finally, it had screw terminals for the 5V power bank to connect to. These fed into a set of power rails on either side.</p>

                    <img class="img-fluid img-centered" src="./resources/top_bot.JPG" alt=""> <br>

                    <p>The PCB (printed circuit board) contained the circuitry for the IR sensor amplification (so that we could accurately detect treasures) and the microphone output circuit. The microphone output circuit is explained in lab 2 and the IR circuit in Milestone 2. We put two versions of the IR circuit on the board, so that we could have two treasure detection systems running at the same time, on either side of the robot. We were motivated to put these circuits on a PCB because we feared that they would be too fragile on a breadboard, and too difficult to build on a protoboard. The PCB ended up being extremely successful, and ensured the operation of all systems on it. The GitHub contains a folder which holds all relevant schematic files.</p>

                    <img class="img-fluid img-centered" src="./resources/pcb.JPG" alt=""> <br>


                   <h3>High-Level Control Algorithm</h3>
                    <p> The following diagrams illustrate our high-level algorithm for controlling the robot.</p>

                    <p> First, the robot waits for a start signal, either from the 660 Hz tone, or the manual start button: </p>
                    <img class="img-fluid img-centered" src="./resources/StartDetectLoop.png" alt=""> <br>

                    <p>Then, the robot began to move through and map the maze according to the following algorithm:</p>

                     <img class="img-fluid img-centered" src="./resources/arduinocode_dfs.png" alt=""> <br>

                   <h3>Movement</h3>
                    <p>Our final robot employed 3 sensors for line following and 1 sensor for junction detection. All 4 sensors were used in conjunction to ensure our robot could make proper turns. Our movement code, from line following to turning, ended up being something we worked to perfect over the course of the entire semester. When we began integrating turns into larger code like the DFS algorithm, we found ourselves having to continuously tune our movement code. Ultimately our line following code was exceptionally robust and was able to handle any mistakes in the robots movements and our turn code with the new junction detector was very reliable. We were very happy with our results. </p>
</p>

                    <h4>Line Following</h4>
                     <p>Our team decided to purchase a Polulu QTR-3RC Reflectance Sensor Array to aid in line following. Initially, we found our servos to be very tempermental. The right servo was far more sensitive to small changes in it's value than the left and the servos didn't always increase/decrease speed as we expected them to. This caused a lot of issues in our attempts at error correction through PID. Once we had played around with the servos enough to gain a better understanding of their quirks, we were able to have some semblance of control. However, our line sensors were still unreliable and the readings were very inconsistent. To alleviate some of our issues we decided to puchase the sensor array. This provided many benefits:
                    <ul style="list-style-type:circle">
                      <li>The convenience of a supplementary QTR sensor arduino library with different methods to allow us to calibrate our sensors and read values more accurately and easily</li>
                      <li>It uses 3 Digital pins, freeing up 3 Analog Pins. Analog pins are in high demand between wall, start sound, and treasure detection, so this sensor array alleviates the need for a mux or many schmitt triggers.</li>
                    </ul>
                    </p>
                    <p> The sensor array turned out to be exceptionally useful. We employed the use of the calibration method to ensure that our reading were always consistent and scaled appropriately from 0 to 1000 from white to black. We included a calibration in our final design such that every time we reset the robot, we would perform a 2 second calibration where we move all 3 sensors across the white posterboard and black tape so they know the full range of their readings. This greatly improved our line detection reliability. We also used a built-in method which returns the location of a black line relative to all 3 sensors. For example, with 3 sensors, our line location value can range from 0-2000 where 1000 means the black line in centered amongst the 3 sensors and the closer to 0 or 2000 the more left or right the line is respectively. We then implemented a PD control algorithm, calculating our error by comparing the current location of our line to the ideal value of 1000. We tried a variety of Kp and Kd values on an attempt to optimize our line-following correction. Ultimately, we realized our 2 servos required different error adjustment since their sensitivity levels varied so much. We increased all error adjustments on our left servo by a factor of 1.5 relative to the right servo and our line detection and following worked great! As a team that was behind on line following from milestone 1, this success was a great step in the right direction and our robust line-following ability ended up being one of our best strengths in our final implementation. </p>

                    <h4>Junction Detection and Turning</h4>
                    <p> At first, we thought we could implement junction detection and turns with our 3 line following sensors alone. While this is definitely plausible, the location of our line sensors made it difficult. The way our chassis was designed, our 3 line sensors were attached to the front of our robot. When we tried to implement turns with this setup, we could successfully turn the robot, however, because our robot detects junction that is directly in front of it, we couldn't ensure that the center of our robot would stay centered on the junction while turning. When we had to implement treasure detection so that the treasure sensors would line up exactly at the junction because of their limited range, this posed an issue. We considered 2 solutions:  
                      <ul style="list-style-type:circle">
                        <li>Moving the line sensors back so that they lined up with our servos at the axis of rotation, allowing the robot to stay centered on the junction. </li>
                        <li>Adding an additional sensor at the axis of rotation to detect junctions and implement/stop a turn only when the robot was centerd on a junction. </li>
                      </ul>
                    </p>The first solution would have required a new chassis to be printed. Thsi would mean we'd have to disconnect and move all of our circuitry and sensor attachments. The new location of our sensors would also require different PD values to ensure correct line detection. Given the amount of time this would take, we decided on the second solution. </p>
                    <p>We decided to add a 4th line sensor, a junction sensor, along the axis of roation underneath our bot. Seeing as how we still didn't have enough analog pins, we implemented a schmitt trigger for this line sensor. An oscilloscope screen depicting our functioning schmitt trigger is pictured below: </p>

                     <img class="img-fluid img-centered" src="./resources/trigger-wave.JPG" alt=""> <br>

                    <p> Once we had a functional junction sensor, we were able to improve our turns. Very simply put, our turns work by first detecting a junction on our junction sensor, so the axis of rotation of our bot was centered on the juntion. When the turn method is subsequently called (as determined by the high level DFS depending on the walls, etc.), the motor speeds are set to pre-determined Left and Right turn speeds. Determining appropriate turning speeds was another task which took a long time because of our finicky servos. They didnt't quite work as we expected but after much trial and error we found satisfactory values that implemented almost perfect turns so that wheel speeds were equal and opposite and the robot appeared to spin in place. Once the robot was turning in the correct direction, we implemented a small delay to ensure that all the line sensors would move past the initial straight line they were following. Then we would continue to spin the robot until the line sensors once again found a line, meaning the middle sensor saw black while the left and right sensors saw white. This meant that the robot had turned 90 degrees and had competed it's turn.</p>
                    <p> At the completion of a turn, we would also ensure that the juncion sensor was on black, which made sure that our robot was still centered on the junction. For example, occasionally our left turns would end up with the center of our robot slightly behind the junction, so the treasure sensors were not correctly aligned. This check would move the robot slightly forward until the junction sensor was on a junction. Overall on our turns, we had to find a good threshold for black vs white when trying to stop the robot from turning once it had found a line. We found if we were too specific in our requirements, the robot wouldn't be able to satisfy them all and would instead keep turning. Once we found a good middle ground, our turns were very reliable! We implemented 180 degree turns by doing 2 subsequent left turns. After a turn, the orientation of our bot wasn't always perfect, however our robust line following was able to handle the crooked bot and correct it's orientation as it moved forward from a junction. </p>
                   
                   <h3>Sensors</h3>
                    <p></p>

                    <h4>Wall Detection</h4>
      <p> At the very top level of our final algorithm is wall detection.  We started working with the distance sensors in Milestone two, first by collecting data from the long range and short range sensors.  We wired the sensors up to a simple circuit and wrote basic code in Arduino to display the values when a wall was placed varying distances away from the sensors.  After analyzing the data, we decided that because the long range sensors were a lot more unpredictable in determining how close a wall is within one half grid-space of the maze, we would use the short range sensors.  We looked at the graphs we collected of the values from the sensors when the wall was placed 10 - 20 cm away, and decided that our threshold sensor value would be 100.  That is to say, when the sensor outputted a number above 100, we would determine that there was a wall within one grid space of the robot. A graph of distance value outputted from the sesnor vs distance from one of our short-range sensors is shown below, along with the code that would drive the robot to determine whether or not there was a wall within one grid space of its right, front, or left sides.  </p>  
      <img class="img-fluid img-centered" src="./resources/Screen Shot 2017-09-23 at 3.56.28 PM.png" alt=""> <br>
      <code>
          if (distanceValue > 100) {<br>
           <ul>wall = true;<br>
             servoL.write(90);<br>
              servoR.write(90);<br>
              delay(500);</ul>
           }    <br>
      </code> <br>
        
      <p> As our design grew more complicated, and we started to integrate the DFS algorithm for traversing the maze, we realized just how important accuracy of wall detection really needed to be.  While watching the robot move through the grid, we noticed that sometimes the robot would not behave as we would expect, moving into places it had already been, ignoring main parts of the maze, and even running itself into walls.  After noticiing these strange behaviors, we decided we needed to take a second look at wall detection.  We collected more data from the robot, this time taking a careful look at each individual left, right, and middle sensors not simply as generic short-range distance sensors, but as individual pieces of hardware.  From this closer look, we were able to determine 3 different sensitivity values for each sensor that would help us more accurately predict when a wall was to the front, left, or right of the robot.  Once we added these updated values to our algorithm, our robot's movement through the maze significantly improved. </p>
      
                     <p></p>

                     <h4> DFS </h4>

                     <p> At the nucleus of our intelligent physical system is the depth-first-search (DFS) algorithm. The DFS is an algorithm for traversing nodes in some graph. The DFS controls the route the robot takes through the maze. At a very high level, the DFS essentially entails going as deep as possible, in terms of distance from the initial position, until it hits a dead end or cannot go to a new location. If it hits a dead end or cannot go to a new location, it will backtrack to the previous location. Here's a diagram that depicts how the DFS algorithm works:

                      <img class="img-fluid img-centered" src="./resources/dfs_diagram.jpg" alt=""> <br>

                      The DFS cannot begin until the robot acquires information about its surroundings. Once this is done, the DFS begins by marking the current location in the <code> maze </code> array as explored. After this, the DFS algorithm removes the current location from the <code> frontier </code>  set. This is done so that the robot doesn't end up confusing places it has already visited with places it hasn't already visited. After this step, the robot adds unvisited surroundings nodes to the <code> frontier </code>  set. This is done so that the robot knows that there are regions of the maze that it has not yet visited, and are accessible. Next, the algorithm checks if the <code> frontier </code>  set is empty. An empty <code> frontier </code>  set indicates that the robot has visited all reachable cells. If the <code> frontier </code> set is indeed empty, it initiates the code performed when the maze navigation is complete. If the <code> frontier </code>  is not empty (i.e. there are regions of the maze that the robot knows it can visit but hasn't visited yet), the robot will update its current position and <code> visited </code> stack. This step is at the crux of the algorithm. If the robot can move to a spot that it has never visited before, it will move to this spot and push its location to the <code> visited </code> stack. If all the spots it can go to have already been visited, it will pop from the <code> visited </code> stack and set move to this position. </p>

                      <p> This algorithm guarantees that the robot will be able to traverse all reachable cells from the initial position in which it is placed. However, this algorithm makes no guaranetees as to the efficiency of the route taken. </p> 



                    <h4>Fast Fourier Transform</h4>
                     <p>In order to extract frequency-domain information from the microphone and phototransistor sensors, we took a Fourier transform of the time-domain signal we were reading from the sensors. We utilized the <a href="http://wiki.openmusiclabs.com/wiki/ArduinoFFT">Fast Fourier Transform library</a> to efficiently analyze the data. The FFT algorithm returns an array where each element refers to the magnitude of the frequency component in that specific frequency bin. Thus, we needed to check the correct bin according to the frequency we wanted to detect. We decided to use a 128-point FFT because it was faster and used much less memory than the 256-point FFT, while still differentiating between the frequencies we were detecting.</p>

                    <h4>Microphone</h4>
                     <p>To detect a 660 Hz tone we used an electret microphone as pictured below:</p>

                     <img class="d-block mx-auto" src="./resources/Microphone.png" alt="" height="242" width="150"><br>

                     <p>By taking a FFT, we were able to distinguish the frequency content of the audio signal from the microphone. The following graph is a FFT of a 660 Hz tone.</p>

                     <img class="img-fluid img-centered" src="./resources/FFT_660.png" alt=""> <br>

                     <p>Thus, to implement start detection, we just needed to check if bin 10 is above a certain threshold. However, this simple implementation caused our robot to false start if it heard any signal with a large enough ~660 Hz component. To account for this, we took 30 FFTs in a row, and only start the robot if 20 of the 30 FFTs returned a magnitude above the threshold. While this helped make our start detection more immune to outside noise, it was not completely flawless because we did have a false start during the final competition when there was loud cheering. To make our start detection less sensitive, we could have taken more than 30 FFT samples because the start tones generally lasted for a long period of time.</p>

                    <h4>Treasure Detection</h4>
                     <p>Our robot had to be equipped with the ability to accurately detect modulating IR frequencies emitted by "treasures" on the maze walls at junctions. In order to improve the accuracy of the detection, we essentially take 30 samples of the signal coming from the treasure detection circuit, and determine the treasure identity from a vote of all 30 samples. Here's a diagram that depicts this process. 

                     <img class="img-fluid img-centered" src="./resources/treasuredetectiondiagram.png" alt=""> <br> 
                    The treasure detection querries the analog inputs and generates 30 FFTs and 30 frequency predictions for each input. Afterwards, the program votes on which frequency is dominant. In order for, say, the program to determine that a treasure is not next to it, the plurality of votes from both sensors must indicate that no treasure is nearby. For a 7/12/17 kHz frequency to be determined to be present, the plurality of votes from the left sensor must indicate a 7/12/17 kHz frequency and the plurality of votes from the right sensor must indicate there being no treasure/frequency, or vice-versa. If the vote yields conclusive results, then the robot detection code is terminated and the variable corresponding to the treasure frequency is set appropriately. If the vote is inconclusive (rarely happens), then the 30 samples are re-acquired and the vote is reconducted.

                     </p>

                   
                   <h3>Radio Communication</h3>

                   <img class="img-fluid img-centered" src="./resources/BaseStation.JPG" alt=""> <br>

                   <h4> Robot To Base Station </h4>
                   <p> In order for the robot to talk to the base station, we had to write code in Arduino that would synethesize information pertaining to the robot's current location and surroundings and send it to the Arduino base station. Here is a diagram depicting the transmission protocol: </p>

                   <img class="img-fluid img-centered" src="./resources/transmissionRobotDiagram.png" alt=""> <br>

                   The transmission begins by synthesizing each individual component into a string form. Once each component is formed into a String, it concatenates the Strings. Then, the String of length 16 is converted to an Arduino Word. Then, the program repeatedly tries to successfully send the packet to the base station until it sends successfully. 



                   <h3>Base Station to FPGA</h3>
       <p> Our base station served as the "middle man" that would allow our robot to communicate to our display.  We needed a way to encode and transmit data about the robot's position at any given time, as well as data about treasures, walls, and whether or not the robot was done with its navigation.  On the Verilog/ FPGA side, we knew that we would need 2 bytes of data to fully encapsulate all the necessary components.  We knew that we wouldn't be able to transmit all of this to the display at once, so we would need to break up data into two parts: one part would transmit data about the position of the robot, and the other part would transmit data about the walls and treasures.  To implement this, we reserved two bits for indicating whether or not the byte was relaying information about the walls and treasures, or if it was relaying information about position.  We also reserved two valid bits, that we could turn high and low incrememntally so the verilog would be able to update on the rising edge. All of the planning and consideration led us to our final two byte scheme, a diagram of which is shown below: </p>
      <img class="img-fluid img-centered" src="./resources/bitdiagram.jpg" alt=""> <br> 
      <p> We realized that the robot did not necessarily need to send all 16 bits of this data. For example, the bits corresponding to indication and valid were components strictly relevant to the base-station and FPGA, but we wanted our bytes to remain consistent to avoid confusion, and we thought that the extra few bits of information would not take long to transmit from the robot to the base-station, so we decided to have our robot send all 16 bits of data, where those four bits were essentially don't cares. </p>
      <p> Once the base station recieves the 16 bit word from the robot, it decodes it by converting into a string of length 16 with the same information. The code for this conversion is shown below: </p>
        <code>
        String disassembleWord(word data) { <br>
          String stringToReturn; <br>
         for (int i = 0; i < 16; i++) { <br>
           int bitIndex = 15 - i; <br>
            stringToReturn += String(bitRead(data, bitIndex)); <br>
          } <br>
          return stringToReturn; <br>
        } <br>
        </code> <br>
        <p> After that, we were able to look at the values of individual characters in the string and write highs or lows to the corresponding outputs.  The code block that writes information to the FPGA about walls and treasures is shown below: </p>
    <code>  digitalWrite(A5, LOW); // indication bit <br>
    if (dataString.charAt(9) == '1') { <br> // top wall
      digitalWrite(A4, HIGH); <br>
    } else {<br>
      digitalWrite(A4, LOW);<br>
    }<br>

    if (dataString.charAt(10) == '1') { // left wall <br>
      digitalWrite(7, HIGH);<br>
    } else {<br>
      digitalWrite(7, LOW);<br>
    }<br>
    if (dataString.charAt(11) == '1') { // bottom wall<br>
      digitalWrite(6, HIGH);<br>
    } else {<br>
      digitalWrite(6, LOW);<br>
    }<br>
    if (dataString.charAt(12) == '1') { // right wall<br>
      digitalWrite(5, HIGH);<br>
    } else {<br>
      digitalWrite(5, LOW);<br>
    }<br>
    if (dataString.charAt(13) == '0' && dataString.charAt(14) == '1') {<br>
      digitalWrite(4, LOW);<br>
      digitalWrite(3, HIGH);<br>
    }<br>
    else if (dataString.charAt(13) == '1' && dataString.charAt(14) == '0') {<br>
      digitalWrite(4, HIGH);<br>
      digitalWrite(3, LOW);<br>
    }<br>
    else if (dataString.charAt(13) == '1' && dataString.charAt(14) == '1') {<br>
      digitalWrite(4, HIGH);<br>
      digitalWrite(3, HIGH);<br>
    } else {<br>
      digitalWrite(4, LOW);<br>
      digitalWrite(3, LOW);<br>
    }<br>
      </code> <br>
        <p> These arduino outputs were wired to the FPGA, which looked at the indication bit, and updated the information about walls, treasures, and position.   The code for this is shown below:  </p>
        
                      <code> 
                   <br> always @ (posedge valid) begin <br> 
                      <ul> preX = robotX;<br>
                          preY = robotY;<br>
<br>
                          if (arduinoInput[6] == 1'b1) begin<br>
                            <ul>updateType = 1'b0;<br>
                            robotX = arduinoInput[5:4];<br>
                            robotY = arduinoInput[3:1];<br>
                            done = arduinoInput[0]; </ul><br>
                          end<br>
                          <br>if (arduinoInput[6] == 1'b0) begin<br>
                            <ul>updateType = 1'b1;<br>
                            walls = arduinoInput[5:2];<br>
                            treasure = arduinoInput[1:0];</ul><br>
                          end </ul><br>
                      end </code><br>
       <p> The final FPGA display did not end up being much different than the implementation seen in Milestone 4. The same overall structure applies--black lines represent walls, light pink squares are explored spaces, white squares are unexplored, a smaller magenta square in the middle of a square represents the current location of our robot, a small red mark on a square indicates a 7 Hz treasure, a small green mark indicates a 12 Hz treasure, and a small blue mark indicates a 17 Hz treasure. At the end, when our robot is done exploring the maze (or all that it was capable of accessing), the robot icon is turned black and three tones play on the speakers. Any squares that are still white at that point represent unreachable areas on the map. </p>

      <iframe width="560" height="315" src="https://www.youtube.com/embed/-Qsh83evmcE" frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen></iframe>

        <p>Our primary focus was providing better on-screen transitions so that the square that was supposed to symbolize our robot looked like it was smoothly traversing across the grid. At the beginning, because of the way our robot turns from junction-to-junction, two packets of information would convey the same location information back to the base-station, making the robot icon to blink in place on the screen. This made it a little harder to keep your eye on the robot, so we had the FPGA check that the new "current location" information was not the same as the previous location recorded in order to make sure that it wouldn't attempt to redraw (causing the blink) the robot in the same place. </p>

        <p> As you can see in the image below, there were still some kinks in our FPGA code. If you look closely, the monitor displays a small offset where the simulated walls don't quite meet. We had fixed this bug at one point, but upon switching to another monitor, were incapable of reproducing the same product. Besides the slight rightward shift, the FPGA also had small glitches, that were annoying though not detrimental to the overall real-time mapping of the maze. </p>


          <img class="img-fluid img-centered" src="./resources/fpgascreen.jpg" alt=""> <br>

        
  
                    

                   <h3>Results and Conclusions</h3>
                    <p>Our robot was remarkably successful in its operation. Despite missing the Milestone 4 requirements, our system was fully functional by the Friday before competition. The video above shows a complete run of the maze, with all functionality working, that was taken in lab several days before the competition. We were extremely pleased with how the robot turned out. Last minute testing revealed that our robot was fairly resilient.</p>

                    <p>Going into the competition, we had two known bugs. The first was that the wireless communication would occasionally drop a packet. As a result, very rarely (&lt;1% of all transmissions), we would get an empty white square. This could have been prevented by waiting for confirmation message from the second Arduino, but this made our robot significantly slower. The second was that very rarely, a fake wall would be detected - i.e. - the robot would pass an open square, and detect and display a wall there. This was extremely problematic, because it could completely ruin a run of a maze. Both of these issues, while serious, did not happen with much frequency, so we decided to live with them and restart the robot if either happened in competition.</p>

                    <p>Competition day was extremely exciting and satisfying. Several minutes before our first round, a terrible accident had occurred. Our robot, sitting on a table, had detected a 660Hz tone playing from a speaker several meters away and started, crashing to the ground. A quick inspection determined that the damage was not insignificant: Our ball caster mount had broke near where it was mounted to the robot. We ran up to the lab to get a replacement, but it was not necessary. We retightened the screw, which ran through both pieces, and reinforced the joint with much duct tape. A quick test revealed that the system still worked. Our first run was fairly successful: We completed the maze in 90 seconds, with one false start due the cheering and whooping that occurred, and missing one treasure. The missed treasure deduction was later removed because the treasure was improperly placed. Check out the video below.</p>

                    <iframe width="560" height="315" src="https://www.youtube.com/embed/r2DVtFhCniE" frameborder="0" allowfullscreen></iframe><br>

                    <p>The second round was much more successful. In order to combat the false start problem, we raised the threshold for the start detection slightly (from 120 units to 140). We finished the maze in 100 seconds (the fastest in our heat!), detecting all treasures and walls successfully. We moved on to the final round!!! We were extremely nervous, because from our observations we were the fourth fastest robot in the final. However, one robot that was faster than ours went off line, and required a reset. This lead us to a third place finish!!!!! We also won the 'Best Team Spirit' Award!</p>

                   <img class="img-fluid img-centered" src="./resources/TeamPhoto.JPG" alt=""> <br>

                    <p>We are extremely proud of our work, our robot, and our team. We'd like to thank Kirsten, Chris, and every TA that helped us over the course of the semester. Go Team One!</p>

                 <h2 class="text-center">We Did It!</h2>  

                 <img class="mx-auto d-block" src="./resources/bigthirdplace.png" alt="">


                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fa fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- Modal 1 -->
    <div class="portfolio-modal modal fade" id="portfolioModal1" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row text-left">
              <div class="col-lg-8 mx-auto">
                <div class="modal-body">
                  
<h2 class = "text-center">Lab 1</h2>

<h4 class = "text-left">Part 1: Modifying the Blink Sketch</h4>
<ul class = "list-unstyled">
<li>For this part of the lab, we made simple modifications to the preexisting code in order to work for an external LED. We declared a global variable `pin` in order to specify the external pin we wish to have blink.</li><br> 

<h4 class = "text-left"> Part 2: Outputing Analog Voltages</h4>

<li>For the second phase of the lab, we took advantage of the `analogRead` method in order to use the analog voltage values that were being controlled by the potentiometer. Here's our code:</li><br>
<code>
int sensorPin = A0;<br>
int voltageValue = 0;<br>
int delayTime = 500;<br> <br>

void setup() {<br>
  <ul>Serial.begin(9600);</ul>
}<br><br>

void loop() {<br>
  <ul>voltageValue = analogRead(sensorPin);<br>
  Serial.println(voltageValue);<br>
  delay(delayTime);</ul>
}
</code> <br>

<li>Here's a photo of the circuit:</li> <br>
<img class="img-fluid img-centered" src="./resources/6d352b7943044248b06bf93e79163291.jpeg" alt="">

<h4 class = "text-left">Part 3: Analog LED Output</h4>

<li>The third phase of this lab is very similar to the previous part. We used the `analogWrite` function in order to write analog PWM voltages to the LED. We mapped the input voltage to the output voltage written to the LED using the following mapping scheme. The maximum value (unknown units) for the voltage we were getting was 1023; the minimum value was 6. The maximum allowed input for analogWrite is 255, so we essentially made the analog output vary linearly between 0 and 255 for all allowed analog inputs from the potentiometer. For reference, the code has been included below:</li> <br>

<code>
int sensorPin = A0;<br>
int outputPin = 11;<br>
float voltageValue = 0;<br><br>


void setup() {<br>
  <ul>pinMode(outputPin, OUTPUT);<br>
  Serial.begin(9600);</ul>
}<br><br>

void loop() {<br>
  <ul>voltageValue = analogRead(sensorPin);<br>
  analogWrite(outputPin, 255 * (voltageValue-6)/1017);<br>
  Serial.println(voltageValue);<br>
  //Frequency of PWM is 490.2 Hz</ul>
}
</code> <br>

<li>Here's a photo of the circuit: </li><br>
<img class="img-fluid img-centered" src="./resources/a3c3be304c904540ab26eccacc50d2ea.jpeg" alt="">


<h4 class = "text-left"> Part 4: Parallax Servos </h4>

<li>For the final lab component, we actuated the angular velocity of the servos using the voltage read by the Arduino (controlled by series resistor and potentiometer). We utilized a similar mapping scheme as the previous part, except with different scaling to accomodate for the servo `write` function input. The Arduino code has been included below:</li> <br>

<code>
#include <Servo.h>; <br>
Servo servo;<br>
int outputPin = 11;<br>
int sensorPin = A0;<br>
float voltageValue;<<br><br>

void setup() {<br>
  <ul>// put your setup code here, to run once:<3>
  Serial.begin(9600);<br>
  pinMode(outputPin, OUTPUT);<br>
  servo.attach(outputPin);</ul>
}<br><br>

void loop() {<br>
  <ul>// put your main code here, to run repeatedly:<br>
  voltageValue = analogRead(sensorPin);<br>
  float servoSpeed = 180 * (voltageValue-1)/989;<br>
  Serial.println(servoSpeed);<br>
  servo.write(servoSpeed);</ul>
}</code> <br>

```

<li>Here's a photo of the circuit:</li>

<img class="img-fluid img-centered" src="./resources/2fc07050c8674d979eb9044ecb1724d5.jpeg" alt="">


<h4 class = "text-left"> Progress on Robot:</h4>

<li>This week we also began working on the basic functionality of the robot. We used what we learned in Lab 1 to implement robot movement. </li><br>

<li>We first built the robot chassis using the 3D-printed and laser-etched parts already sitting in the lab room. We used:</li>
  <ul>
<li>1 robot base (the large red platform in the image)</li>
<li> 2 servo mounts</li>
<li>2 continuous rotation servos</li>
<li> 2 wheels</li>
<li>2 rubber bands</li>
<li>1 Arduino Uno</li>
<li>1 battery holder (with 2 AA batteries)</li>
<li> 1 breadboard</li>
<li>Various wires, screws, nuts, and spacers</li>
</ul><br>

<li>The construction of the robot was a fairly simple, but time-consuming process. We modeled our prototype off of the existing robots sitting in the lab room. The Arduino sits on the top of the robot, and the servo mounts (and the accompanying servo-wheel pieces) sit below. See the images for more details. </li><br>
<img class="img-fluid img-centered" src="./resources/lab1robot1.jpg" alt=""> <br>
<img class="img-fluid img-centered" src="./resources/lab1robot2.jpg" alt=""> <br>

<li>Our power setup was somewhat less than ideal. Because the standard 5V battery packs were discharged (and according to the TAs, took a significant amount of time to charge), we relied on a battery holder with 2 AA batteries inside to power our servos. Because the batteries could not sit on the robot, we used a breadboard to wire up the servo power lines (as well as the servo control lines). We also used the standard Arduino power supply cable to power the Arduino. The wiring was a bit messy, and the breadboard sat apart from the robot. This meant that when we actually made the servos move, we had to be very careful. Cleaning up the wiring (perhaps by using a protoboard) is a priority for us.</li> <br>

<li>Once the robot was set up, we modified the code from Part 4 of the lab to control 2 servos. We programmed the servos to move in the same direction, so the robot spun in a little circle! This occurred because the servos are oriented in opposite directions on the actual robot chassis. Once we realized this error, we modified the code so that one servo was rotating in the opposite direction of the other. The arduino code has been included below:</li><br>

<code>
#include <Servo.h><br>
Servo servo1;<br>
Servo servo2;<br><br>
 
// the setup function runs once when you press reset or power the board<br>
void setup() {<br>
  <ul>Serial.begin(9600);<br>
  servo1.attach(9);<br>
  servo2.attach(11);</ul>
}<br><br>
 
// the loop function runs over and over again forever<br>
void loop() {<br>
  <ul>servo1.write(0);<br>
  servo2.write(180);<br>
  delay(5000);</ul>
}
</code> <br><br>
<li>Since the arduino was still being powered by a cable to our computer, we couldn't get a vide of the robot moving autonomously. We could see the wheels of the robot moving as expected, but the arduino power cable prevented the robot from traveling too far from the laptop we were using. We hope to improve on this setup and record a cool video of our robot next time!</li><br>

                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fa fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Modal 2 -->
    <div class="portfolio-modal modal fade" id="portfolioModal2" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row text-left">
              <div class="col-lg-8 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  
<h2 class = "text-center">Lab 2</h1>

<h4 class = "text-center">Optical Team -- IR Circuit</h4>
<p class = "text-center">Evan, Radhika and Michael</p>
<ul class = "list-unstyled">


<li>Materials used:</li>
  <ul>
    <li>breadboard</li>
    <li>wires</li>
    <li>phototransistor</li>
    <li>resistors</li>
    <li>capacitor</li>
    <li>Arduino Uno</li>
    <li>USB serial cable</li>
    <li>oscilloscope</li>
    <li>LM358 operational amplifier</li>
    <li>treasure</li>
  </ul> <br>

<li>For this component of the lab, we constructed a circuit that is able to detect electromagnetic radiation of infrared (IR) frequncy. A photo transistor was used to modulate the circuit in response to a 7 kHz pulsating IR light. The phototransistor works via an embedded bipolar junction transistor, which is able to pass current in response to incident electromagnetic radiation. The changing current causes voltage to drop across the serial resistor. We measured the voltage at the terminal of the resistor with an oscilloscope. The amplitude of the voltage recorded was around 100 mV. This voltage was directly connected to an analog pin of the Arduino Uno with a wire.</li><br>

<li>Below is a photograph of the oscilloscope depicting the sinusoidal voltage signal generated from the phototransistor. </li> <br>

<img class="img-fluid img-centered" src="./resources/lab2irscope.jpg" alt="">

<li>We've also included a photo of the circuit:</li> <br>

<img class="img-fluid img-centered" src="./resources/lab2ircircuit.jpg" alt="">

<li>We then used the standard `fft` library to process the voltage signal. The Arduino has built-in hardware capable of processing the signal using the ADC (analog-to-digital) converter, which performs better than the regular `analogRead` function for high frequency data.</li> <br>

<li>The data was then transformed into the frequency-domain using the `fft` library. FFT--or Fast Fourier Transform--is a method used by computers to efficiently convert time-domain data into the frequency domain. We utilized the `fft_adc_serial` script to output a serial stream of frequency data. The `fft` takes advantage of the analog-to-digital converter. Each serial line of output corresponds to the amplitude of the input signal at a frequency related to the relative index of the line output. Each index corresponds to an integer multiple of the bin frequency width, so index <em>i</em> corresponds to frequency <em>f<sub>w</sub>i</em>, where <em>f<sub>w</sub></em> is the bin frequency width. </li> <br>

<li>In order to make sense of the FFT data, we needed to figure out the bin frequency width. Using the data sheet, we deduced that the bin frequency width, <em>f<sub>w</sub></em>, is roughly 150 Hz. </li> <br>

<li>After gathering the FFT serial data, we plotted the data in MATLAB. Included below is a MATLAB plot we generated from the data:</li> <br>

<img class="img-fluid img-centered" src="./resources/fftir.png" alt="">

<li>Since the bin width is 150 Hz, and the pulsating frequency of the IR signal is  7 kHz, we should see high ampilitude around bin index 46. The MATLAB plot clearly shows this feature at around that index value, demonstrating that the Arduino can detect IR signals.</li><br>

<li>Our intelligent physical system will need to perform some action upon detecting the 7 kHz signal (in addition to other IR frequencies). An additional challenge is that this 7 kHz signal will likely have a low intensity due to the distance at which it is being transmitted to the phototransistor. To remedy these problems, we had to implement an analog circuit along with a high pass filter, in addition to writing scripts in Arduino that would perform some action upon detecting the desired IR frequency. </li> <br>

<li> The raw voltage signal being transmitted from the phototransistor is roughly ~100 mV peak-to-peak with some DC voltage, but this AC swing can be much lower depending on the treasure distance. In order to ensure that the voltage reading at the Arduino is detectable/high enough, we created a non-inverting operational amplifier (op-amp) with the LM358 amplifier. </li> <br>


<li>Since the raw output from the phototransistor had a non-trivial DC component, any gain would amplify the total voltage well beyond the rail voltage (5V) of the amplifier, creating an unusable signal. To mitigate this issue, we created a simple high-pass filter using a capacitor and a resistor to filter out low frequency (DC) signals. The lowest frequency capable of passing through the high-pass filter (commonly referred to as the cutoff frequency) is equal to the equation below:</li> <br>

<img class="img-fluid img-centered" src="./resources/cutoff_frequency.png" alt="">

<li>We selected an arbitrary capacitor and then calibrated the resistance of the resistor such that most low-frequency (DC) signals would be eliminated. Below is the circuit schematic:</li> <br>

<img class="img-fluid img-centered" src="./resources/fullcircuitschematic.png" alt="">


<li>Below is a photo of the full circuit:</li> <br>

<img class="img-fluid img-centered" src="./resources/ircircuit.JPG" alt="">


<li>Here are the values of the components we used:</li> 
  <ul>

    <li>R3 = 9.7 kΩ</li>
    <li>R4 = 47.9 kΩ</li>
    <li>R2 = 8 kΩ</li>
    <li>R1 = 1.78 kΩ </li>
    <li>C1 = 3.3 nF</li>
  </ul> <br>

<li>The gain of our amplifier was roughly 6 (Av= 1 + R4/R3) . That is, our input voltage would be multiplied by a factor of 6 at the output of the amplifier. </li>

<li>Here is the oscilloscope reading of the input voltage and output (amplified) voltage:</li>

<img class="img-fluid img-centered" src="./resources/rotatedirscope.JPG" alt="">

<li>The final step was to have the Arduino perform some action in response to detecting the frequency. </li> <br>

<li>To do this, we added `if` statements to the standard `fft_adc_serial` script that would read the amplitude from the FFT bin corresponding to 7 kHz frequency and then do a `digitalWrite` command:</li>

<br>
<code>
  if (fft_log_out[47]>75){ <br>
      <ul>digitalWrite(13, HIGH); </ul>
  } <br>
  else if (fft_log_out[47]<75){ <br>
      <ul>digitalWrite(13, LOW); </ul>
  }
</code>
<br><br>

<li>Pin 13 corresponds to an led output on the Arduino Uno. Below is a video of the Arduino Uno illuminating pin 13 in response to the 7 kHz signal. Note that the pin illuminates when the treasure is brought within ~6 in. of the transistor, but turns off once it is out of range. </li> <br>

<iframe width="560" height="315" src="https://www.youtube.com/embed/XL-vrNMunB4" frameborder="0" allowfullscreen></iframe><br>


<li>We will need to modify the circuit to include a band pass filter in order to better detect multiple discrete frequencies (multiple treasures). </li><br>



<h4 class = "text-center">Acoustic Team:</h4>
<p class = "text-center">TJ, Frannie, and Katherine</p>
<ul class = "list-unstyled">

<li>Materials used:</li>
  <ul> 
    <li>Electret microphone</li>
    <li>1 microfarad capacitor</li>
    <li>300 Ohm resistors</li>
    <li>3k Ohm resistor</li>
    <li>Arduino Uno</li>
    <li>USB serial cable</li>
    <li>oscilloscope </li>
    <li>tone generating application</li>
  </ul><br>
<li>In this part of the lab, we built a microphone circuit and wrote code so that our Arduino would be able to detect a tone of 660 Hz, the frequency that signals the robot to start navigating the maze.</li><br>
 
<h5 class = "text-left">Testing:</h5>

<li>Before we got to lab, we went onto the Open Music Lab’s website and downloaded the FFT library.  We needed a Fast Fourier Transform algorithm to detect specific frequencies using a microphone. A Fourier transform decomposes a signal into the frequencies that make it up. The Fast Fourier Transform (FFT) is a way to compute a Fourier transform in O(n log(n)) time instead of O(n^2) time, by recursively breaking down a discrete Fourier transform (DFT) into much smaller DFTs.</li> <br>

<li>Fast Fourier Transform essentially performs a discrete time fourier transform (DTFT) in a time-efficient manner. The formula for DTFT is:</li> <br>

<img class="img-fluid img-centered" src="./resources/FT_algorithm.svg" alt="">

<li><em>x<sub>n</sub></em> is the value at index <em>n</em> of the array containing time-domain data (of length N), and <em>X<sub>k</sub></em>< is the value at index <em>k</em> of the frequency-domain data. The complex valued frequency domain data encodes both the phase and amplitude of the constituent signal at a specific frequency. </li> <br>

<li>We opened the example script from the FFT library named fft_adc_serial, and tested the code using an oscilloscope and function generator with parameters of 660 Hz, 3.3V/2 Vpp, and a 0.825V offset.  We then recorded the data using the Arduino’s Serial Monitor, and plotted the results using excel.  Graphs from two subsequent trials are shown below: </li> <br>

<img class="img-fluid img-centered" src="./resources/lab2_acoustic_data1.png" alt="">


<img class="img-fluid img-centered" src="./resources/lab2_acoustic_data2.png" alt="">


<li>Our peak voltage for every trial we ran occurred at the 5th data point or "bin".</li> <br>

<li>To compute the frequency width of each bin, we consulted the ADC section of the ATmega328 datasheet. We found that the last 3 bits of the ADC Control and Status Register (ADCSRA) determines the division factor between the system clock frequency and the input clock to the ADC. In the fft_adc_serial code, ADCSRA was written 0xe5, making the division factor = 32.</li> <br>

<li>Thus, we calculated the sampling frequency:</li><br>

<li>ADC sampling frequency = 16 MHz (system clock frequency) / 32 (division factor) / 13 (conversion time) = 38 kHz</li><br>

<li>Finally, the bin frequency width was calculated as follows:</li><br>

<li>Bin width = 38 kHz (sampling frequency) / 256 samples = 150 Hz / sample</li><br>

<li>Therefore, bin 5 contains the range of frequencies 600 - 750 Hz, which matches our data.</li><br>


<h5 class = "text-left">Building the circuit:</h5>

<li>After we got this initial data, we started building our microphone circuit.  The figure below shows the schematic of the circuit we went off from the course website.</li> <br>
<img class="img-fluid img-centered" src="./resources/lab2_acoustic_data3.png" alt="">


<li>And here's what our microphone circuit looked like: </li><br>
<img class="img-fluid img-centered" src="./resources/lab2_acoustic_data4.png" alt="">

<li>Once we built the circuit, we checked to see if it was working as expected.  We found a free online tone generator as shown below.  We then played the tone off a computer next to the circuit and observed the results using an oscilloscope. Our general set-up can be seen in this video below: </li> <br>

<iframe width="560" height="315" src="https://www.youtube.com/embed/V_nuNBzZ2WA" frameborder="0" allowfullscreen></iframe><br>

<li>The oscilloscope showed that it was taking in data from the acoustics in the room, and generating a wave of frequency 660 Hz when the tone was played next to the circuit, as shown in the photo of the oscilloscope screen below.</li><br>
<img class="img-fluid img-centered" src="./resources/lab2_acoustic_data5.png" alt="">


<li>From there, we fed the microphone output to the Arduino, and in the loop function we checked for a peak in bin 5.</li><br>
<code>
//detects input on bin 5 and performs start function<br>
if (fft_log_out[4] > 120) {<br>
  <ul>start();</ul>
}
</code> <br>

<li>To visually demonstrate the Arduino's ability to detect the start signal, we had it light up an LED once the microphone detected it. We created a start function which would typically begin line detection, make the robot's wheels subsequently turn, and so on. </li> <br>

<code>
//This function will "start" the robot and perform any functions necessary <br>
for operation. Right now it turns on an LED. <br>
// <br>
void start() {<br>
  <ul>digitalWrite(13, HIGH);</ul>
}
</code> <br>

<li>Below is a video of the arduino LED responding to a 660 Hz signal: </li>

<iframe width="560" height="315" src="https://www.youtube.com/embed/AGRt7vsQew4" frameborder="0" allowfullscreen></iframe><br>


<h5 class = "text-left"> Distinguishing between 585 Hz and 735 Hz:</h5>

<li>Now that the Arduino could detect a 660 Hz tone, we wanted to determine if it could distinguish between a 585 Hz and 735 Hz tone. We set the oscilloscope to these frequencies and took the FFT using the previous fft_adc_serial code. However, there was an immediate issue -- 585 Hz and 660 Hz were both in bin 5:</li><br>
<img class="img-fluid img-centered" src="./resources/FFT32" alt="">


<li>In order to fix this issue, we had to decrease the bin size by changing the division factor. To do this, we changed the last 3 bits of ADCSRA to 111. This corresponds to a division factor of 128. Now, the three tones were located in distinct bins.</li><br>
<img class="img-fluid img-centered" src="./resources/FFT128.png" alt="">

<li>Using our previous equation with the new prescaler, we calculated the bin width to be 37.5 Hz and 660 Hz to be located in the 17th bin. However, the 660 Hz tone was repeatedly located in bin 19. We weren't able to determine the cause of this discrepancy. In any case, we updated the code to detect for a peak in bin 19.</li><br>
<code>
//detects input on bin 19 and performs start function<br>
if (fft_log_out[4] > 120) {<br>
  start();<br>
}
</code><br>

<li>Since the oscilloscope input worked, we also wanted to try an audio input. We played the 585 Hz tone, then the 735 Hz tone, and finally the 660 Hz tone which causes the LED to light up:</li><br>

<iframe width="560" height="315" src="https://www.youtube.com/embed/532djUzTYos" frameborder="0" allowfullscreen></iframe><br>

<h5 class = "text-left">Amplifier Circuit</h5>

<li>We realize that in the future, the tone may not be as loud as it was when it was played off a computer, and so we started building a simple Non-inverting Op Amp circuit to amplify the signal from the microphone.  The schematic we were going off is shown in a picture below: </li><br>
<img class="img-fluid img-centered" src="./resources/lab2_acoustic_data6.png" alt="">

<li>http://www.electronics-tutorials.ws/opamp/opamp15.gif</li> <br>

<li>We did not implement this amplifier in this part of the lab, but we have built the amplifier and are ready to use it if we discover that it becomes necessary down the line. </li>   <br>

                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fa fa-times"></i>
                    Close Page</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Modal 3 -->
    <div class="portfolio-modal modal fade" id="portfolioModal3" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row text-left">
              <div class="col-lg-8 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-center">Lab 3</h2>
                  <h4 class="text-center">Graphics Team</h4>
                  <p class="text-center">Radhika, Katherine, and Evan</p>
                  <h5 class = "text-left">Introduction</h5/> <br>
                  <ui class = "list-unstyled"> 

                  <li>For this component of the lab, we were tasked with demonstrating the functionality of the DE0-nano field programmable gate array (FPGA) in interfacing with a VGA serial monitor. Specifically, we had to write HDL code that would interact with the VGA driver. The VGA driver--which requests a pixel color for each pixel on the screen--handled the direct interfacing with the VGA. The output pins of the FPGA were hooked up to an adapter, to which the VGA cable of the monitor was connected.</li>
                  <br>
                  <li><h6 class="text-left" >Materials used:<h6/> </li>

                  <ul> 

                    <li>Arduino Uno/li>
                    <li>DE0-Nano FPGA</li>
                    <li>Breadboard</li>
                    <li>Resistors</li>
                    <li>VGA cabled</li>
                    <li> VGA monitor</li>
                    <li>VGA-FPGA adapter</li>
                    <li>Wires</li>

                  </ul>
                  <li>
                  <h5 class ='text-left' >FPGA-VGA Interface</h5> </li><br>

                  <li>The adapter that connects the FPGA output to the VPA cable is a DAC converter. A DAC converter converts a digital input to an analog output. In other words, the FGPA encodes the 3-channel colors as multi-bit digital binary values, and then the adapter converts these multi-bit values into 1 continuous voltage value. In our case, the VGA supports a maximum 1v input for each color channel. Therefore, the voltage value for each channel is computed by converting the 2-3 bit values (with 3.3v for each `HIGH` bit) for each color channel into 1 analog voltage that can be between 0v and 1v. </li><br>

<li>Below is a circuit diagram of the DAC:</li><br>
<img class="img-fluid img-centered" src="./resources/dacconverter.png" alt=""> <br>


<li>One can solve for the voltage at the `Red` node (`Vred`). Vred = 0.141*R[2] + 0.0684*R[1] + 0.0321*R[0]. Notice that the "weights" for each bit vary by powers of two, with the MSB having twice the weight as the 1st bit, and the 0th (LSB) bit having 1/4 of the weight as a MSB. In order words, the converter is adding up the bits and weighting each one accordingly in order to generate 1 final voltage value. The bins are also weighted such that if all bits (R[2], R[1], and R[0]) are pulled high (3.3v), the voltage at the output can be supported by the monitor (it comes out to ~0.8v).<li><br>

<li>A similar analysis yields the analog voltage at the `Green` node. </li><br>

<li>For the blue node, the voltage `Vblue` comes out to be: Vblue = 0.1456*B[1] + 0.07096*B[0]. Notice that the weight for B[1] is twice that of B[0] in order to ensure that the analog voltage represents the digital value. </li><br>

<li>Another way to think about this converter is by noticing that the resistor values for bits that are weighted more strongly are lower (in fact, the resistor values vary by powers of 2 in order to correspond to voltage weightings of powers of 2). The low-impedance connection between significant bits and the output ensures that this bit will have more influence over the voltage at the output node than bits that are seperated by large resistors. </li><br>

<li>The color (red, green, blue) intensity for any given pixel will be proportional to the analog voltage value for that given color channel. So if all the bits for a given channel are `HIGH`, the analog voltage will be at its highest, and the intensity of that color will be maximized.  </li><br>


<li><h5 class = "text-left">Part 1: Coloring the entire screen</h5><br>

<li>For the first part of this lab, we simply wanted to write the same color value to each pixel on the display. For this, we needed a simple `assign` statement (i.e. `assign PIXEL_COLOR = 8'd300`). </li><br>

<li> <h5 class ='text-left' >Part 2: Coloring a grid</h5></li><br>

<li>For the second part of the lab, we wanted to have the FPGA write a colored 2x2 grid to the display. We divided this task into two part: a) mapping the raw pixel coordinates to a quadrant on the 2x2 grid, and b) given a quadrant, output what the color should be. </li><br>

<li>In order to compute what quadrant of the 2x2 (or outside the grid) a given pixel location corresponded to, we created a new module called `GRID_SELECTOR`. Essentially, `GRID_SELECTOR` divides the pixel coordinates by 128 in order to calculate the grid location. We achieve this division by using a bitshift. We also made the grid width a power of 2 in order to enable us to use this grid assignment method. We made it so that all pixels which fall outside the grid are given a value of 2 for the grid index. Below is our code for this module:</li><br>

<code>
module GRID_SELECTOR(<br>
CLOCK_50,<br>
PIXEL_COORD_X,<br>
PIXEL_COORD_Y,<br>
GRID_X,<br>
GRID_Y);<br><br>


input CLOCK_50;<br>
input wire [9:0] PIXEL_COORD_X;<br>
input wire [9:0] PIXEL_COORD_Y;<br>
output reg [3:0] GRID_X;<br>
output reg [3:0] GRID_Y;<br><br>




always @ (*) begin<br>
 <ul> GRID_X = PIXEL_COORD_X >>>7;<br>
  GRID_Y = PIXEL_COORD_Y >>>7<br>
  if (GRID_X>4'd1) begin<br>
    <ul>GRID_X = 4'd2;</ul>
  end<br>
  if (GRID_Y>4'd1) begin<br>
    <ul>GRID_Y = 4'd2;</ul>
  end</ul>
end<br><br>

  
endmodule

</code> <br><br>

<li>Within the main module (`DE0_NANO.v`), we instantiated this module and connected it to all the relevant wires. </li><br>

<li>We then created a register memory block that would store all the colors for the grid, with indices corresponding to the `GRID_X` and `GRID_Y` outputs of `GRID_SELECTOR`. Below is the code for the memory array:</li><br>

<code>
reg[7:0] grid4[2:0] [2:0];<br><br>

always @(*) begin<br>
  <ul>grid[0][0] = 8'd50;<br>
  grid[1][0] = 8'd100;<br>
  grid[0][1] = 8'd150;<br>
  grid[1][1] = 8'd200;<br>
  grid[2][0] = 8'd0;<br>
  grid[2][1] = 8'd0;<br>
  grid[2][2] = 8'd0;<br>
  grid[0][2] = 8'd0;<br>
  grid[1][2] = 8'd0;</ul>
end
</code><br><br>

<li> Finally, in order to assign the pixel color value, we perform the following assignment: `assign PIXEL_COLOR = grid[GRID_X][GRID_Y]`. </li><br>

<li> <h5 class = 'text-left' >Part 3: Rudimentary Arduino-FPGA Interface</h5></li><br>

<li>For the final component of the graphics portion of the lab, we were tasked with demonstrating that we can use an Arduino to communicate with the FPGA in order to display a certain graphic.  </li><br>

<li>We wrote an Arduino script that repeatedly counts to 3 in binary, with a 1/2 second delay between each iteration:</li><br>

<code>
int delayTime = 500; //ms; <br><br>

void setup() {<br>

  <ul>pinMode(8, OUTPUT);<br>
  pinMode(9, OUTPUT);</ul>
}<br><br>

void loop() {<br>
  <Ul>for (int i = 0; i<4; i++){ <br>
    <ul>if (i==0){ <br>
      <ul>digitalWrite(9, LOW);<br>
      digitalWrite(8, LOW);</ul>
    }<br>
    else if (i==1){<br>
      <ul>digitalWrite(9, LOW);<br>
      digitalWrite(8, HIGH);</ul>
    }<br>
    else if (i==2){<br>
      <ul>digitalWrite(9, HIGH);<br>
      digitalWrite(8, LOW);</ul>
    }<br>
    else{<br>
      <ul>digitalWrite(9, HIGH);<br>
      digitalWrite(8, HIGH);</ul>
    }<br>
    delay(delayTime);</ul>
  }</ul>

}
</code><br><br>

<li>The 2 bit Arduino output "data" then had to be transmitted to the FPGA. Since the Arduino outputs at 5v and the FPGA handles 3.3v, we implemented a simple voltage divider to pull down the voltage. We've included a circuit schematic:</li><br>
<img class="img-fluid img-centered" src="./resources/fgpa_arduino_schem.png" alt=""> <br>



<li>Notice that the voltage that is inputted to the FPGA is equal to the Arduino output pin voltage multiplied by 17.7/(17.7+9.89) =  0.64. When the Arduino voltage equals 5v (`HIGH`), then the voltage inputted to the FPGA (ports 33 and 31) equals roughly 3.2v, which is a permittable value for the FPGA. </li><br>

<li>The goal was to have each distinct binary valued input correspond to a distinct grid to be outputted to the display. The display should, therefore, change grid layouts every 1/2 second. </li><br>

<li>We made minor modifications to the code we previously had in order to allow for these changes. </li><br>

<li>Firstly, we instatiated 4 new memory arrays, corresponding to the 4 different kinds of grids that would be displayed.</li><br>

<code>
reg[7:0] grid1[2:0] [2:0];<br><br>

always @(*) begin<br>
   <ul>grid1[0][0] = 8'b11111111;<br>
   grid1[1][0] = 8'd300;<br>
   grid1[0][1] = 8'd300;<br>
   grid1[1][1] = 8'd300;<br>
   grid1[2][0] = 8'd00;<br>
   grid1[2][1] = 8'd00;<br>
   grid1[2][2] = 8'd00;<br>
   grid1[0][2] = 8'd00;<br>
   grid1[1][2] = 8'd00;</ul>
end<br><br>


reg[7:0] grid2[2:0] [2:0];<br><br>

always @(*) begin<br>
  <ul> grid2[0][0] = 8'd300;<br>
   grid2[1][0] = 8'b11111111;<br>
   grid2[0][1] = 8'd300;<br>
   grid2[1][1] = 8'd300;<br>
   grid2[2][0] = 8'd0;<br>
   grid2[2][1] = 8'd0;<br>
   grid2[2][2] = 8'd0;<br>
   grid2[0][2] = 8'd0;<br>
   grid2[1][2] = 8'd0;</ul>
end<br><br>


reg[7:0] grid3[2:0] [2:0];<br><br>

always @(*) begin<br>
   <ul>grid3[0][0] = 8'd300;<br>
   grid3[1][0] = 8'd300;<br>
   grid3[0][1] = 8'b11111111;<br>
   grid3[1][1] = 8'd300;<br>
   grid3[2][0] = 8'd0;<br>
   grid3[2][1] = 8'd0;<br>
   grid3[2][2] = 8'd0;<br>
   grid3[0][2] = 8'd0;<br>
   grid3[1][2] = 8'd0;</ul>
end<br><br>

reg[7:0] grid4[2:0] [2:0];<br><br>

always @(*) begin<br>
   <ul>grid4[0][0] = 8'd300;<br>
   grid4[1][0] = 8'd300;<br>
   grid4[0][1] = 8'd300;<br>
   grid4[1][1] = 8'b11111111;<br>
   grid4[2][0] = 8'd0;<br>
   grid4[2][1] = 8'd0;<br>
   grid4[2][2] = 8'd0;<br>
   grid4[0][2] = 8'd0;<br>
   grid4[1][2] = 8'd0;</ul>
end<br>
</code><br>

<li>Next, we added an `always` block that would set the `PIXEL_COLOR` depending on the value of the pins `GPIO_0_D[33]` and `GPIO_0_D[31]` (i.e. the output from the Arduino). Note that for this part, we instantiated the `GRID_SELECTOR` module in order to compute the grid coordinate (`GRID_X` and `GRID_Y`) that the pixel coordinate corresponds to. </li><br>

<code>
always @(*) begin<br>
  <ul>if (GPIO_0_D[33]==1'd0 && GPIO_0_D[31] == 1'd0) begin<br>
    <ul>PIXEL_COLOR = grid1[GRID_X][GRID_Y];</ul>
  end<br>
  if (GPIO_0_D[33]==1'd0 && GPIO_0_D[31] == 1'd1) begin<br>
    <ul>PIXEL_COLOR = grid2[GRID_X][GRID_Y];</ul>
  end<br>
  if (GPIO_0_D[33]==1'd1 && GPIO_0_D[31] == 1'd0) begin<br>
    <ul>PIXEL_COLOR = grid3[GRID_X][GRID_Y];</ul>
  end<br>
  if (GPIO_0_D[33]==1'd1 && GPIO_0_D[31] == 1'd1) begin<br>
    <ul>PIXEL_COLOR = grid4[GRID_X][GRID_Y];</ul>
  end</ul>
end<br>
</code><br>

<li>We've included a video demonstration:</li><br>

<iframe width="560" height="315" src="https://www.youtube.com/embed/bsqfBa_z_XE" frameborder="0" allowfullscreen></iframe><br>

<li> <h5 class= 'text-left' >Future Graphics Plans </h5> </li><br>

<li>Since our current implementation of the grid is just the bare bones that was asked for in lab 3, we also planned out how we would draw out a more complex grid that mapped where our robot was, what part of the maze was already traversed, what was still unexplored, etc. </li><br>

<li>In our folder of final code, we have implemented a state machine that controls the robots movement, so if the robot must move up, down, left, or right in the maze, its wheels are directed accordingly. The current state of the robot will be communicated from the arduino to the fpga, as well as information of whether or not there is a wall on the left, right, or in front of the robot. This information will only be sent once it enters a "At a Junction" state so that the FPGA won't constantly be getting new, unnecessary updates. </li><br>

<li>This will give the FPGA the necessary amount of information to draw the bot's movements in real time. Here is a representation of what we would want our final robot mapping to look like using the real RBG values from the pseudo-code: </li><br>
<img class="img-fluid img-centered" src="./resources/grid.png" alt=""> <br>


<li>Some pseudo-code for this implementation would roughly look like: </li><br>

<code>
unexplored = 8'b11111111; <br>
walls = 8'b0; <br>
explored = 8'b11110111;      //pink<br>
bot = 8'b11100011;           //magenta<br>
treasures = 8'b11011100;     //yellow<br><br>

robot_position  = 2'd20;   // this is the starting grid number <br><br>

  
//capture the past position before movement before updating<br>
//the new robot position by marking it explored. <br>
gridcolor[robot position] = explored;  <br><br>

if robot is moving up: <br>
   <ul>robot_Y -= 1;  </ul>
if robot is moving down: <br>
   <ul>robot_Y += 1; </ul>
if robot is moving left: <br>
   <ul>robot_X -= 1; </ul>
if robot is moving right: <br>
   <ul>robot_X += 1;</ul>

update grid to show new robot position; <br>
update grid to show previous robot position has been explored; <br>
</code><br>

<li> <h4 class = 'text-center' >Acoustic Team</h4> </li>
<li> <p class = 'text-center'>Michael, TJ, and Frannie</p></li>

<li> <h5 calss = 'text-left'> Introduction</h5> </li>

<li>The goal of the Acoustic Team was to generate a short tune from the FPGA to be played over a speaker. This tune will be played when the robot finishes mapping the maze.</li><br>

<li> <h6 class='text-left'> Materials used:</h6></li>
<ul>

<li>FPGA DEO-Nano</li>
<li>8-bit R2R DAC</li>
<li>Stereo phone jack socket</li>
<li>Lab speaker</li>
</ul>


<li> <h5 class = 'text-left'> Part 1: Generating a square wave </h5> </li>

<li>A square wave was the simplest wave to generate, since we only needed to toggle one GPIO output on and off at our desired frequency. In order to generate the correct frequency, we created a clock divider parameter that divides the system clock of 25 MHz by 440 Hz. This provides the number of cycles that the FPGA needs to wait before toggling the GPIO pin. We needed to divide the clock divider by an additional factor of 2, so the pin would toggle both on and off in the desired number of cycles. The following code creates a simple counter that will toggle the GPIO pin once it counts through the number of cycles provided by CLKDIVIDER_440.
</li><br>

<li> <h6 class = 'text-left' >Square wave generation:</h6> </li>
<code>
//localparam<br>
localparam CLKDIVIDER_440 = 25000000 / 440 / 2;<br><br>

//sound variables<br>
reg square_440;<br>
assign GPIO_0_D[1] = square_440;<br>
reg [15:0] counter;<br><br>

always @ (posedge CLOCK_25) begin<br>
  <ul>if (counter == 0) begin<br>
    <ul>counter <= CLKDIVIDER_440 - 1; //reset the clock<br>
    square_440 <= ~square_440; //toggle the square pulse</ul>
  end<br>
  else begin<br>
    <ul>counter <= counter - 1;<br>
    square_440 <= square_440;</ul>
  end</ul>
end<br>
</code><br>

<li>Then, we attached the GPIO pin 1 to the oscilliscope and speakers to see and hear the square wave. </li><br>

<iframe width="560" height="315" src="https://www.youtube.com/embed/dw-YT_o7A1I" frameborder="0" allowfullscreen></iframe><br><br>

<li> <h5 class = 'text-left' > Part 2: Generating a sine wave</h5></li>

<li>To generate a sine wave, we used our square wave code, but made it substantially more complex. First, we needed to have a way to store and read out a sine wave (as opposed to calculating the sine values in real time). We did this by creating a ROM module using a Verilog template. We then ported in a sin table (which we created in MATLAB). On every positive edge of the clock, the module finds the relevant entry in the sin table that corresponds to the inputted address value. </li>

<li> <h6 class = 'text-left' > 8-bit sine function with values 0-255</h6> </li>

<img class="img-fluid img-centered" src="./resources/lab3_8bitsin.png" alt=""> <br>


<li> <h6 class = 'text-left' > Sin ROM Module:</h6> </li>
<code>
module sin_rom(<br>
  <ul>input [7:0] addr,<br>
  input clk, <br>
  output reg [7:0] q <br>
);<br><br>

  // Declare the ROM variable<br>
  reg [7:0] sine[255:0];<br><br>

  initial<br>
  begin<br>
    <ul>sine[0]<= 8'd127;<br>
    sine[1]<= 8'd130;<br>
    /// everything in between...<br>
    sine[255]<= 8'd124;</ul>
  end<br><br>

  always @ (posedge clk) begin<br>
    <ul>q <= sine[addr];</ul>
  end</ul>

endmodule<br>
</code><br>

<li>In main, we connect the module to the registers that we have created. We create a sine wave at a specific frequency using a rudimentary direct digital synthesis (DDS) method. We increment through the sine table everytime a counter decrements to zero. Since we use a 25 MHz clock, we need to go through the sine table 400 times to get an output frequency of 400 Hz. Moreover, the sine table is 256 entries long. Hence, our formula for our counter is Clock frequency/Desired Frequency/Number of entries in the table, or in this particular case, 25,000,000/400/256. </li><br>

<li> <h6 class = 'texy-left' >In Main:</h6></li>
<code>
localparam CLKDIVIDER_A_SIN = 25000000 / 400 / 256; //400 Hz<br>
reg [15:0] counter;<br>
<br>

always @ (posedge CLOCK_25) begin<br>
  <ul>if (counter == 0) begin<br>
    <ul>counter <= CLKDIVIDER_A_SIN - 1;<br>
    if (DAC >= 255) begin<br>
     <ul> DAC <= 0;</ul>
    end<br>
    else begin<br>
     <ul> DAC <=  DAC + 1;</ul>
    end</ul>
  end<br>
  else begin<br>
   <ul> counter <= counter - 1;</ul>
  end</ul>
end
</code><br><br>

<li>To convert the digital sine wave to an analog signal for the speakers we used a R2R Digital to Analog Converter. </li>
<img class="img-fluid img-centered" src="./resources/lab3_r2rdac.png" alt=""> <br>


<li>We connected the 8 bit output register of GPIO pins to pins 1-8 on the DAC. Then, the analog signal from pin 16 of the DAC was connected to our speakers. This produced a perfect sine wave, as one can observe in the below video.</li><br>

<iframe width="560" height="315" src="https://www.youtube.com/embed/TQKGTA-fIVY" frameborder="0" allowfullscreen></iframe><br><br>

<li> <h5 class = 'text-left' > Part 3: Generating Three Tones</h5></li><br>

<li>To generate the three tone signal, we worked off of our sine production code above. This time, instead of just having one clock divider, we created three (one for each tone we wanted to play). We created a simple FSM to switch between frequencies. The only change we had to make to the code which accesses the ROM was to simply make the counter reset to different values depending on the state. The FSM switches between states once per second, creating a pleasant incrementing of tones. You can hear this in the video below.</li>

<li>Note that this program simply plays the three tones in a loop, starting immediately. It would be fairly simple to hook this up to an one bit input signal from the Arduino (as the VGA team did above).</li><br>

<code>
 always @ (posedge CLOCK_25) begin<br>
   <ul> if (reset) begin<br>
      <ul>freq_state <= 2'b00;<br>
      freq_counter <= 25'b0;</ul>
    end<br>
    if (freq_counter == ONE_SEC) begin<br>
      <ul>freq_counter <= 25'b0;<br>
      freq_state <= freq_state + 2'b1;<br>
      if (freq_state == 2'b11) begin<br>
        <ul>freq_state <= 2'b00;</ul>
      end</ul>
    end<br>
    else begin  <br>
      <ul>freq_state <= freq_state;<br>
      freq_counter <= freq_counter + 25'b1;</ul>
    end // always @ (posedge CLOCK_25)</ul>
 end<br>
<br>

localparam CLKDIVIDER_A_SIN = 25000000 / 400 / 256; //400 Hz<br>
localparam CLKDIVIDER_B_SIN = 25000000 / 800 / 256; //800 Hz<br>
localparam CLKDIVIDER_C_SIN = 25000000 / 600 / 256; //600 Hz<br>
reg [15:0] counter;<br>

<br>
always @ (posedge CLOCK_25) begin<br>
  <ul>if (counter == 0) begin<br>
    <ul>if (freq_state == 0) begin<br>
      <ul>counter <= CLKDIVIDER_A_SIN - 1;</ul>
    end<br>
    if (freq_state == 1) begin<br>
      <ul>counter <= CLKDIVIDER_B_SIN - 1;</ul>
    end<br>
    if (freq_state == 2) begin<br>
      <ul>counter <= CLKDIVIDER_C_SIN - 1;</ul>
    end<br>
    if (DAC >= 255) begin<br>
      <ul>DAC <= 0;</ul>
    end<br>
    else begin<br>
      <ul>DAC <=  DAC + 1;</ul>
    end</ul>
  end<br>
  else begin<br>
    <ul>counter <= counter - 1;</ul>
  end</ul>
end

</code><br><br>

<iframe width="560" height="315" src="https://www.youtube.com/embed/FSzmDpvT8Bo" frameborder="0" allowfullscreen></iframe><br>

                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fa fa-times"></i>
                    Close Page</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Modal 4 -->
    <div class="portfolio-modal modal fade" id="portfolioModal4" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row text-left">
              <div class="col-lg-8 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-center">Lab 4</h2>
                  <h4 class = 'text-center'>Radio Team</h4>
                  <p class = 'text-center'> 
Radhika, Katherine and Evan </p>

<h5>Introduction </h5><br>
<p>For the radio subteam of this lab, our goal was to communicate information between two arduinos through radio communication using two transceivers. We wanted to send simulated maze data from one arduino, which was set up as the transmitter, to another arduino, which was setup as a reciever. We also wanted to observe the range of the radio communication with different power/speed settings and look how many packets were successfully transmitted. </p><br>

<h5> Materials Used </h5>
<ul class = list-unstyled> 
  <ul><li>2 Nordic nRF24L01+ transceivers</li>
      <li>2 Arduino Unos (one was shared with the other sub-team)</li>
      <li>2 USB A/B cables</li>
      <li>2 radio breakout boards with headers</li>
  <ul><br>

<h5> Getting Started with the RF24 Transceivers</h5><br>
<p>As directed in the lab, first, we downloaded the RF24 arduino library. Then, to begin with simple tests of the transceivers, we used the 'Getting Started' code that was provided to us in the lab as opposed to the example code that came with the arduino library. Before we could begin, we had to adjust the identifier numbers for our two pipes using the formula 2(3D + N) + X where D is the day of our lab, N is our team number, and X was 0 and 1 for each of our 2 radios. Our calculated values happened to be 2 and 3,  the same as the ones in the sample code, as shown below:</p><br>

<code>
// Radio pipe addresses for the 2 nodes to communicate.<br>
const uint64_t pipes[2] = { 0x0000000002LL, 0x0000000003LL };
</code> <br><br>
<p>We first tested the sample code that was provided to us. We set up one arduino to be the transmitter by typing 'T' into the serial monitor of that arduino. The other arduino automatically became a reciever. The sample code was written to sent the time at which the data was being sent to the reciever. If the data was successfully sent, the transmitter then waits on a confirmation from the reciever. If the data wasn't sent successfully, the code tries to send the data again in 1 second. The code has a 200ms timeout value, so if the receiver hasn't confirmed that it has recieved the data in 200 ms, the code prints out a corresponding statement. If the receiver does confirm before timeout, the calculated round-trip delay time is printed out.  This is reflected in the following code:</p> <br>

<code>
    unsigned long time = millis();<br>
    printf("Now sending %lu...",time);<br>
    bool ok = radio.write( &time, sizeof(unsigned long) );<br>
<br>
    if (ok)<br>
       <ul>printf("ok...");</ul> <br>
    else<br>
       <ul>printf("failed.\n\r");</ul><br>
<br>
    <ul>radio.startListening();</ul><br>
<br>
// Wait here until we get a response, or timeout (200ms)<br>
    unsigned long started_waiting_at = millis();<br>
    bool timeout = false;<br>
    while ( ! radio.available() && ! timeout )<br>
      <ul>if (millis() - started_waiting_at > 200 )</ul><br>
        <ul>timeout = true;</ul></ul><br>
<br>
    // Describe the results<br>
    if ( timeout )<br>
    {<br>
      <ul>printf("Failed, response timed out.\n\r");</ul><br>
    }<br>
    else<br>
    {<br>
      // Grab the response, compare, and send to debugging spew<br>
      <ul>unsigned long got_time;</ul><br>
      <ul>radio.read( &got_time, sizeof(unsigned long) );</ul><br>
<br>
      // Spew it<br>
      printf("Got response %lu, round-trip delay: %lu\n\r",got_time,millis()-got_time);<br>
    }<br>
<br>
    // Try again 1s later<br>
    delay(1000);<br>
  }
</code><br><br>

<p>We tried different ranges for sending and receiving data. We didn't see a major drop in successful transmissions until we were almost in 2 separate rooms, so we believe the range of the radio communication is more than enough for our applications.</p>

<p>In the next steps, we modified the data we were sending between arduinos to reflect simulated maze data.
</p>

<h5>Sending full maze coordinates and maze updates with wireless communication</h5><br>

<p>To send the full maze coordinates, we altered the code to send a 5x5 array of unsigned chars. When sending and receiving transmissions, the arduino needs to be told what size packet it will be sending or receiving, so the key is to explicitly state what the maze size was when reading and writing data. </p><br>

<h6> So for sending and receiving a 5x5 array: </h6> <br>

<code>
unsigned char maze[5][5];<br>
// different maze values were randomly assigned and sent <br>
<br>
//sending <br>
bool ok = radio.write( &maze, sizeof(unsigned char)*25);<br>
//receiving <br>
bool done = radio.read( &maze, sizeof(unsigned char)*25);
</code><br><br>

<p>We noticed that when we increased the packet size, more packets of information were being dropped or taking too long to transmit, so we also played around with higher data rates and power levels. This yielded less dropped packets of information that transmitted faster, but we tried to err on the side of less power consumption. </p><br>

<code>
// set the power<br>
// RF24_PA_MIN=-18dBm, RF24_PA_LOW=-12dBm, RF24_PA_MED=-6dBM, and RF24_PA_HIGH=0dBm.<br>
radio.setPALevel(RF24_PA_MED);<br>
//RF24_250KBPS for 250kbs, RF24_1MBPS for 1Mbps, or RF24_2MBPS for 2Mbps<br>
radio.setDataRate(RF24_2MBPS);
</code><br><br>

<p>Here is a video of one arduino sending the entire maze to another: </p><br>

<iframe width="560" height="315" src="https://www.youtube.com/embed/y53XXv9cR8I" frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen></iframe>

<h6> For sending and receiving maze updates via individual coordinate points: </h6>
<p>When sending maze updates, one arduino sent a 1x3 array of unsigned chars--the first two chars being the maze coordinates, and the third being new information that corresponded with that data point. The second arduino had a 5x5 maze array initialized on it so that the correct coordinate could be updated to reflect the incoming information as it was received. </p><br>

<code>
//random coordinate and data values were assigned<br>
unsigned char updates[3]; <br>
updates[0] = x;<br>
updates[1] = y;<br>
updates[2] = data;<br>
<br>
//sending individual maze updates<br>
bool ok = radio.write( &updates, sizeof(unsigned char)*3);<br>
<br>
//receiving and updating internal memory of maze <br>
done = radio.read( &updates, sizeof(unsigned char)*3 );<br>
maze[updates[0]][updates[1]]=updates[2];<br>
</code><br>

<p>Here is a video of the maze updates being sent from one Arduino to another: </p><br>

<iframe width="560" height="315" src="https://www.youtube.com/embed/_tgkwoed0Dw" frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen></iframe>


<h5> Sending information from base station to FPGA </h5>

<p>For the final part of the lab, we had to create a system for sending maze information from the Arduino base station to the FPGA. Since the robot was not yet operational, and we had already demonstrated that we can communicate wirelessly between the Arduinos, we generated test robot coordinate data to simulate the robot traversing the maze. Since we were able to demonstrate communication between the Arduinos, and from the Arduino to the base station, it will be relatively straightforward to link all of these devices together. Note that we did not demonstrate the communication of treasure and wall data from the Arduino to the FPGA. We have established a preliminary protocol for transmitting this data, but have not yet demonstrated this in practice. </p><br>

<p>Here is the Arduino code we wrote for this component of the lab (each part will be explained)</p><br>

<code>
int delayTime = 500; //ms;<br>
int setupTime = 50; //ms;<br>
String inputSignals[32] = {<br>
                        <ul><ul><ul><ul><ul><ul><ul>"00000", "01000", "10000", "11000",<br>
                        "00001", "01001","10001", "11001",<br>
                        "00010",  "01010", "10010", "11010",<br>
                        "00011", "01011", "10011", "11011",<br>
                        "00100", "01100", "10100", "11100",<br>
                        "00101", "01101","10101", "11101", <br>
                        "00110", "01110", "10110", "11110",<br>
                        "00111", "01111", "10111", "11111",};<br><br>    
                      </ul></ul></ul></ul></ul></ul></ul>
void generateClock(){<br>
  <br>
}<br>
<br>
                        
void setup() {<br>
  <ul>Serial.begin(9600);<br>
  pinMode(7,OUTPUT);<br>
  pinMode(6,OUTPUT);<br>
  pinMode(5,OUTPUT);<br>
  pinMode(4,OUTPUT);<br>
  pinMode(3,OUTPUT);<br>
  pinMode(2,OUTPUT);</ul>
}<br>
<br>
void loop() {<br>
  <ul>
  for (int i = 0; i<32; i++){<br>
    <ul>String signalWord = inputSignals[i];<br>
    sendWord(signalWord);<br>
    delay(delayTime);   </ul>
  }</ul>
}<br>

<br>
void sendWord(String signalWord){<br>
  <ul>digitalWrite(2, LOW);<br>
  delay(setupTime);<br>
  writeWord(signalWord);<br>
  delay(setupTime);<br>
  digitalWrite(2, HIGH);</ul>
}<br>
<br>
void writeWord(String signalWord){<br>
  <ul>for (int i = 0; i<5; i++){<br>
    <ul>if (signalWord.charAt(i) == '0'){<br>
     <ul> digitalWrite(7-i, LOW);</ul>
    }<br>
    else{<br>
      <ul>digitalWrite(7-i, HIGH);</ul>
    }</ul>
  }</ul>      
}
</code><br><br>

<p>As discussed, the maze coordinate are encoded in a 5 bit word. In the Arduino code, we hard coded all 20 maze coordinates that the robot could possibly reach. This can be seen when we instantiate the `inputSignals` array. </p> <br>

<p>Since the FPGA reads this word on the rising edge of a clock, we had to create a 1-bit psuedo-clock signal in Arduino that is sychronized to change when we are ready to read the data. This is done in the `sendWord` method. Pin 2 corresponds to our "clock". We write a `LOW` value to the clock pin, and then wait `setupTime` amount of milliseconds before proceeding to actually write the coordinates to pins 7-3. We wait `setupTime` milliseconds before flipping the clock to a `HIGH` signal. Our thinking was that there is some propagation delay in the circuit. 50 milliseconds is plenty of time for the signal to set up, and for the FPGA to sample the correct value. If we didn't clock our signal, then we would run into issues sampling the signal when it is transitioning between values. </p> <br>

<p>The `writeWord` method is relatively straightforwards. It simply iterates through the word string, and then writes the values to the appropriate pin.</p> <br> 

<p>The output pins corresponding to the coordinate data and clock (digital pins 7-2) were connected to a voltage divider array in order to be sent to the FPGA (to be discussed in next section).</p> <br>



<h4 class = 'text-center'> FPGA Team</h4>
<p class = 'text-center' >TJ, Frannie, Michael</p> <br>

<h5>Introduction</h5> <br>

<p>For our sub-team, the goal of this lab was to recieve packets of information from the Arduino, and then use this information to update the VGA monitor using the FPGA. In order to accomplish this, we first built off of our team's work from Lab 3.</p><br>

<h6> Materials used:</h6>
<ul> <li> FPGA DE0-Nano</li>
<li>VGA-FPGA adapter</li>
<li>VGA cable and monitor</li> </ul>

<h5> Drawing a 4x5 grid</h5> <br>

<p>Changing our grid size was a fairly simple process, but did require some troubleshooting. First we updated the line `reg[7:0] grid1[2:0] [2:0]` to `reg[7:0] grid1[3:0] [4:0]` in our main module. We then assigned a color to each register in grid1 to create a checkerboard pattern. </p><br>

<p>When we uploaded the code to the FPGA, the squares were too large to view the full grid.  Thus, we changed the always block in our `GridSelector` module to the following:</p><br>

<code>
always @ (*) begin<br>
  <ul>GRID_X = PIXEL_COORD_X / 96;<br>
  GRID_Y = PIXEL_COORD_Y / 96;<</ul>
end
</code><br><br>

<p>Instead of bitshifting by 7 bits (dividing by 128 as before), we decided to divide by 96, since the height of the monitor is 480 pixels. 480 pixels / 5 squares = 96 pixels / square.</p><br>

<p>The squares were now all visible, but the grid would only display 4x4. After reviewing our code for a while, we realized we hadn't updated the registers `GRID_X` and `GRID_Y` to hold enough bits. We changed both of these to 4 bit registers and the grid was now 4x5!</p><br>

<h5> Changing color based on location</h5>

<p>Next, we needed to be able to update the grid to show the current location of the robot, as well as visited locations. To do this, we needed to rework the code from last lab, which had 4 different maps stored in memory. Rather than have each possible map stored in memory, we decided to update the map dynamically.</p> <br>

<p>To accomplish this, we created the following state machine:</p> <br>

<code>
reg[7:0] grid1[3:0][4:0];<br>
reg[7:0] currentGrid;<br>
   <br>
//state machine <br>
always @(posedge CLOCK_25) begin<br>
  <ul>if (GRID_X > 3) begin //colors squares that aren't in the 4x5 grid black (unreachable)<br>
    <ul>PIXEL_COLOR <= black;</ul>
  end<br>
  else begin<br>
  <ul>currentGrid <= grid1[GRID_X][GRID_Y];<br>
    if (currentGrid == 0) begin //if no input, color current square white (unvisited)<br>
      <ul>PIXEL_COLOR <= white;</ul>
    end<br>
    if (currentGrid[0] == 1) begin //if LSB is 1, color current square pink (visited)<br>
      <ul>PIXEL_COLOR <= pink;</ul>
    end</ul>
  end</ul>
end
</code><br><br>

<p>We then created a quick test to determine whether our implementation could receive inputs over time, update the grid and remember previous locations.</p> <br>

<p>We created two registers to encode x and y locations, and used the one second timer to update x and y. Then the square in the grid at location (x,y) was assigned `8'b1` which corresponded to a visited square in our FSM.</p> <br>

<code>
reg[2:0] x;<br>
reg[2:0] y;<br>
<br>
if (led_counter == ONE_SEC) begin<br> 
  <ul>led_state   <= ~led_state;<br>
  led_counter <= 25'b0;<br>
  if (y==3'b100) begin // you're at the bottom of the grid<br>
    <ul>y<= 3'b0;<br>
    x<=x+3'b001;</ul>
  end<br>
  else begin<br>
    <ul>y <= y + 3'b1;</ul>
  end <br>
  grid1[x][y] <= 8'b1;</ul>
end
</code><br><br>

 <p>Here is a video of this incrementation: </p> <br>

<iframe width="560" height="315" src="https://www.youtube.com/embed/JUII_ee_oFA" frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen></iframe>

<h5> FPGA Communication with Arduino</h5><br>

<p>With our 'state machine' working properly, it was easy to quickly assign different states to a grid tile and have a record of visited tiles. Our last step was to get the two halves of our assignment working together. We coordinated with the Arduino half of the team to make a protocol for robot position. In this case, we used the simplest possible communication scheme: A 5 bit array, with the first 2 bits representing x position, and the latter 3 representing y position. </p><br>

<p>Our FPGA was hooked up directly to the Arduino by a set of 6 wires (5 data bits, one valid bit). This setup took a frustrating amount of time, because the DE0 Nano datasheet's pinout diagram for GPIO-1 is unintuitive (to put it lightly). Once our pins were indeed hooked up correctly (this took a lot of oscilloscope debugging on our part), we worked on properly interpreting messages from the Arduino.</p><br>

<p>We used an independent module for the reading of data from the Arduino, called inputReader:</p><br>

<code>
 module inputReader(<br>
valid,<br>
arduinoInput,<br>
robotX,<br>
robotY,<br>
preX,<br>
preY);<br>
<br>
input valid;<br>
input [4:0] arduinoInput;<br>
output reg [1:0] robotX;<br>
output reg [2:0] robotY;<br>
<br>
output reg [1:0] preX;<br>
output reg [2:0] preY;<br>
<br>
always @ (posedge valid) begin<br>
  <ul>preX = robotX;<br>
  preY = robotY;<br>
  robotX = arduinoInput[4:3];<br>
  robotY = arduinoInput[2:0];</ul>
end<br>
<br>
endmodule
</code><br><br>
 
<p>We initially struggled to get data to correctly update (our screen update schema was simple - put the robot on the tile the Arduino sent, record all past tiles sent as visited, and make the rest unvisited). We observed that in general, the tiles were flipping to visited in the order we expected, but not at a constant rate. Certain tiles would change colors two at a time. This signaled to us that the FPGA was not reading the data correctly. Because our inputReader module was reading data whenever the valid bit was high, the FPGA was capturing incorrect grid values that occurred when the output bits from the Arduino were flipping. We altered both the Arduino and the FPGA code, to capture Arduino data only on the pos edge of the valid bit, thereby preventing our error.</p><br>

<p>We were able to successfully communicate information wirelessly from one Arduino to another, then display it on a screen using the FPGA. See the below video:
</p><br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/t0cLDFkS9FU" frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen></iframe>
 

                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fa fa-times"></i>
                    Close Page</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Modal 5 -->
    <div class="portfolio-modal modal fade" id="portfolioModal5" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row text-left">
              <div class="col-lg-8 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-center">Milestone 1</h2>
                  
<p>The goal of this milestone was to implement line following and program our robot to drive in a figure eight.</p>

<h4 class = 'text-left'> Hardware Modifications </h4> 

<p>We began by attaching the light sensors to the bottom of the robot. We used the line sensors provided, and began with three sensors. After seeing what other groups approached the problem with, we were uncertain of the viability of the three sensor design. However, having two sensors on either side of the line worked very well, because any time one went over the tape, we could immediately tell the robot was off course. In fact, we could likely remove the middle sensor and retain all functionality.</p>

<img class="img-fluid img-centered" src="./resources/sensorposition.png" alt=""> <br>


<p>We had some issues with getting consistent readings from the line sensors, so our first solution was to put the line sensors closer to the ground. We did this by switching out the wheels. This made our line readings significantly more consistent. The value of the middle sensor (reading the black tape) was typically over 900, while the outer sensors read between 100 and 300 on the white board.</p>

<p>We ran into significant hardware problems as we continued working on our project. When the robot was programmed to go straight, it would continuously veer to the left. This behavior suggests an improper servo calibration, but setting both servos to 90 resulted in no movement (so the servos must have been properly calibrated). We puzzled over this problem for several hours, switching out several servos and adjusting our code to unevenly power one servo more than the other. Probing the PWM signals at the Arduino output pins revealed that they were behaving as expected. Re-doing the wiring ended up fixing the problem. Likely, one signal connection was loose and sent an odd PWM signal to the servo.
</p>
<a href="http://www.youtube.com/watch?feature=player_embedded&v=Cvb9fMoiSzk
" target="_blank"><img src="http://img.youtube.com/vi/Cvb9fMoiSzk/0.jpg" 
alt="IMAGE ALT TEXT HERE" width="240" height="180" border="10" /></a>

<h4 class = 'text-left'> Software Implementation </h4>

<p>Our line detection algorithm was fairly simple. We observed that the sensors measured over 800 units on black tape and under 300 units (typically under 150) on the white board. We noted that if the robot moved off the tape in either direction, one of the outer sensors would be over black tape. We then could adjust wheel speeds and turn back onto the correct path. We could detect junctions when all three sensors were over the black tape.</p>

<p>Because we primarily tested later in the day, where light was lower, we set the black/white threshold at 400 units - this high margin ensured that we would not get any false positives - i.e., the robot would not shift unexpectedly. </p>

<p>Our line detection mechanism proved to be very robust. Whenever it was tested, it could accurately detect robot position relative to the line. 
</p>
<p>The primary challenge we faced was implementing the actual motion correction. We initially adjusted the speed of each servo by 1 to 2 units. We could not figure out why line correction was not working. The serial output told us that the robot was detecting position correctly, and that it was in fact changing the PWM signal. We hypothesized that it was in fact a servo issue - and while there was a servo hardware problem (see above) - this was not the primary issue. After several hours of testing, we finally pushed the correction servo power up significantly. One servo would move fowards at +45 (relative to 90) and the other would move at -45 (relative to 90). This gave us immediate and real results. We successfully implemented line correction!</p>

<code>
  if(line[2]>400){<br>
    <ul>rightSpeed = 45;<br>
    Serial.println("LEFT");<br>
    leftSpeed = 180 ;</ul>
  }<br>
  else if(line[0]>400){<br>
    <ul>leftSpeed =135;<br>
    rightSpeed = 0;<br>
    Serial.println("RIGHT");</ul>
  }<br>
  else if (line[0]<400 && line[2]<400){<br>
    <ul>Serial.println("STRAIGHT");<br>
    leftSpeed = 135;<br>
    rightSpeed = 45;</ul>
  }<br>
</code><br>

<p>To get the robot to turn at a junction, we specified the conditions under which the robot should continue to turn. We set the servos' speed to turn once the sensors detect a junction. Most of our code directs the robot based on whether the sensors detect that the robot is at a junction, on the line, to the left of line, or to the right of the line, but turning must be address differently. For example, as the robot turns left, the sensors (which are all currently located at the front of the bot) will first report that the robot is on the line, then left of the line, then for a period of time it will not be able to detect the line at all, then right of the line, and finally back on the line. </p>

<p>Thus, we implemented code that broke from the primary loop that directs the robot based on position in reference to the line, allowing the robot to continue to turn after it turns away from the junction. Since the robot begins and ends a turn directly on the line, one of two boolean requirements must be satisified in order for the robot to continue to turn: it must either have not passed the line it originally began on, or the robot isn't straight on the line yet. This is roughly implemented as shown below: </p>

<code>
  boolean straight = (line[0]<400 && line[1]>400 && line[2]<400);<br>
  boolean passed = false; <br>
  <br>
  if (leftWheel == leftTurn | leftWheel == rightTurn){<br>
    <ul>if {!straight | !passed) {<br>
      <ul>if (line[1]<400) { <br>
        <ul>passed = true; </ul> 
      }<br>
      break; </ul>
    }<br>
    passed = false; </ul>
  }<br>
</code><br>
<br>

<p>Here is the video of our robot doing a figure eight:</p> 

<a href="http://www.youtube.com/watch?feature=player_embedded&v=9BDlo4FiO3k
" target="_blank"><img src="http://img.youtube.com/vi/9BDlo4FiO3k/0.jpg" 
alt="IMAGE ALT TEXT HERE" width="240" height="180" border="10" /></a> <br>

                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fa fa-times"></i>
                    Close Page</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Modal 6 -->
    <div class="portfolio-modal modal fade" id="portfolioModal6" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row text-left">
              <div class="col-lg-8 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-center">Milestone 2</h2>
                  <h4 class = 'text-left'>Treasure Frequency Detection</h4>

<p>Materials used:</p>
<ul class='list-unstyled'>
  <ul> <li>
          breadboard </li>
        <li>wires </li>
        <li>phototransistor</li>
        <li>resistors </li>
        <li>capacitor</li>
        <li>Arduino Uno</li>
        <li>USB serial cable</li>
        <li>oscilloscope</li>
        <li>LM 358 operational amplifier</li>
        <li>treasure</li>
  </ul> </ul>


<h5 class='text-left'>Analog circuit</h5>

<p>We constructed an analog circuit and wrote Arduino code that detects specific frequencies. </p>

<p>The first stage of implementation was creating an analog circuit that would feed time-domain voltage data to the Arduino Uno. The raw voltage output from the phototransistor upon receiving incident IR radiation has a significant DC component and a relatively small voltage swing. Our goal was to have the Arduino recieve a voltage input between 0 and 5 volts, with large voltage swing. Simply feeding the phototransistor voltage through a noninverting amplifier would amplify the DC component, and render the output signal unusable. Thus, we had to essentially create a high-pass filter at the op-amp input, and then add a DC bias signal to the op-amp output to ensure that the voltage stays within the 0-5v range. We achieved this by constructing the following circuit:</p>

<img class="img-fluid img-centered" src="./resources/milestone2ircircuit.png" alt=""> <br>


<p>C1 and R2 function as a high-filter to remove the input DC. The 2.5V DC source before R2 is intended to DC-bias the output votlage so that the Arduino can properly read the signal. The theoretical gain of the circuit is roughly 5.5K (1 + R3/R4), though the demonstrated gain is much lower. Note that the actual circuit embedded on the robot will use a voltage divider to implement the 2.5V DC source, not an actual DC voltage source.</p> 

<h5 class = 'text=left'> Arduino code</h5>

<p>When developing the Arduino code to detect frequencies, we wanted to ensure that we had robust code that can detect variable frequencies. We also wanted to reduce false-positive and false-negatives.</p> 

<p>The code we developed first generates an array containing the amplitudes of the time-domain signal at frequencies related to the bin index. Afterwards, we call 3 functions that check to see if the given array encodes a 7 kHz, 12 kHz, or 17 kHz signal. Each of the functions for each frequency first computes the "expected bin" where the highest ampitude should be observed. The theory is that if a signal is indeed a 7 kHz, 12 kHz, or 17 kHz signal, then the FFT should have a peak at those frequencies. However, given the imprecision of treasure frequency, combined with the nonlinearities of the circuit, there could be small discrepancies in where the max peak for a given periodic is observed versus where it should be. To address this issue, the function, `detectedFrequency` finds the maximum value within a predefined `peakIndexWidth` of the expected peak. From inspecting the graphs of different signals, we deduced that the maximum amplitude always falls within ~5 bins of where it is expected to be (so the default value for `peakIndexWidth` equals 5). The function iterates through all the FFT values in the array that are within `peakIndexWidth` from the expected max bin. It finds the maximum value contained in this window of bins. The function then checks to see if this maximum value exceeds an absolute threshold, in order to ensure that random noise signals don't produce false positives. If the maximum value fails to exceed an absolute threshold, the function returns `false`, indicating that input signal does not encode a specific frequency. Next, the function checks to see if there are no other bins which contain a value as high as the computed maximum value in the bin window. We don't count bins less than 30, since these correspond to strong DC signals, which are always contained in the input. If the function finds other bins that have values which exceed the value around the expected peak, then the function returns `false`, indicating that the signal is not a periodid signal with the specified frequency. If the input FFT array passes all these checks, then we determine that the signal is a periodic signal of the specified frequency and return `true`. A `true` return value prompts the program to print the frequency value that it has detected. </p>

<p>We have included the code for this program below:</p>

<code>
/*<br>
fft_adc_serial.pde<br>
guest openmusiclabs.com 7.7.14<br>
example sketch for testing the fft library.<br>
it takes in data on ADC0 (Analog0) and processes them<br>
with the fft. the data is sent out over the serial<br>
port at 115.2kb.<br>
*/<br>
<br>
#define LOG_OUT 1 // use the log output function<br>
#define FFT_N 256 // set to 256 point fft<br>
#include "printf.h"<br>
<br>
long clockFreq = 16E6;<br>
int divisionFactor = 32;<br>
int conversionTime = 13;<br>
int numSamples = 256;<br>
float samplingFrequency = ((clockFreq/((float)divisionFactor))/conversionTime);<br>
float binWidth = samplingFrequency/numSamples;<br>
<br>
#include <FFT.h> // include the library<br>
<br>
void setup() {<br>
  <ul>Serial.begin(115200); // use the serial port<br>
  TIMSK0 = 0; // turn off timer0 for lower jitter<br>
  ADCSRA = 0xe5; // set the adc to free running mode<br>
  ADMUX = 0x40; // use adc0<br>
  DIDR0 = 0x01; // turn off the digital input for adc0<br>
  pinMode(13, OUTPUT);<br>
  printf_begin();</ul>
}<br>
<br>

boolean detectedFrequency(float freqToDetect, char fftArray[]){<br>
  int peakIndexWidth = 5;<br>
  int absoluteMinThreshold = 80;<br>
  int centralBinIndex = int ((float)freqToDetect)/((float)binWidth);<br>
  int maximumMag = -1;<br>
  for (int i = centralBinIndex-peakIndexWidth; i<= centralBinIndex+peakIndexWidth; i++){<br>
    <ul>if (abs((int)fftArray[i])>maximumMag){<br>
      <ul>maximumMag = abs((int)fftArray[i]);</ul>
    }</ul>
  }<br>
  if (maximumMag<(absoluteMinThreshold){<br>
    <ul>return false;</ul>
  }<br>
  <br>
  for (int i = 30; i<centralBinIndex-peakIndexWidth; i++){<br>
    <ul>if (abs((int)fftArray[i])>= maximumMag){<br>
      <ul>return false;</ul></ul>
    }<br>
  }<br>
  for (int i = centralBinIndex+peakIndexWidth+1; i<256; i++){<br>
    <ul>if (abs((int)fftArray[i])>= maximumMag){<br>
      <ul>return false;</ul>
    }</ul>
  }<br>
<br>
  return true;<br>
<br>
}<br>
<br>

void loop() { <br>
  <ul>while(1) { // reduces jitter<br>
   <ul> cli();  // UDRE interrupt slows this way down on arduino1.0<br>
    for (int i = 0 ; i < 512 ; i += 2) { // save 256 samples<br>
      <ul>while(!(ADCSRA & 0x10)); // wait for adc to be ready<br>
      ADCSRA = 0xf5; // restart adc<br>
      byte m = ADCL; // fetch adc data<br>
      byte j = ADCH;<br>
      int k = (j << 8) | m; // form into an int<br>
      k -= 0x0200; // form into a signed int<br>
      k <<= 6; // form into a 16b signed int<br>
      fft_input[i] = k; // put real data into even bins<br>
      fft_input[i+1] = 0; // set odd bins to 0</ul><br>
    }<br>
    fft_window(); // window the data for better frequency response<br>
    fft_reorder(); // reorder the data before doing the fft<br>
    fft_run(); // process the data in the fft<br>
    fft_mag_log(); // take the output of the fft<br>
    sei();<br>
  <br>
    if (detectedFrequency(7E3, fft_log_out)){<br>
     <ul>Serial.print("7kHz \n");</ul>
<br>
     
    }<br>
     if (detectedFrequency(12E3, fft_log_out)){<br>
     <ul>Serial.print("12kHz \n");</ul>
     <br>
    }<br>
<br>
   if (detectedFrequency(17E3, fft_log_out)){<br>
     <ul>Serial.print("17kHz \n");</ul>
    }</ul>
  }</ul>
}
</code> <br><br>

<p>There's a lot of boilerplate code from the FFT libtary. The function we implemented was `detectedFrequency`. We also added the `if` statements at the end of the `loop` method. </p>

<p>Here's a video of Evan demonstrating the functionality of the circuit and Arduino code:
</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/w5iABs7IJ5A" frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen></iframe> <br>


<h4 class='text-left'>Distance Sensing</h4>

<p>Materials used:</p>
<ul class = 'text-unstyled'> <ul>
  <li> breadboard </li>
<li>wires</li>
<li>long distance sensor</li>
<li>short distance sensor</li>
<li>Arduino Uno</li><li> USB serial cable</li> </ul></ul>

<p>For this milestone, we implemented distance sensing.  We had two sensor options:  long range and short range.  
We at first decided that we wanted to try to use a combination of both sensors, as the short range would detect 
walls up close and tell the robot to turn to avoid collision, and the long range would allow for faster mapping.  </p>
 
<p>We tested the short range sensor first.  We wired up a simple circuit consisting of the distance sensor and the
Arduino and wrote simple code to display the values outputted from the distance sensor when the block of wood 
was located at different distances away.  We recorded data for the short range sensor when the block of wood was 
located in 5 cm intervals from 5 cm to 35 cm away, within the range of the specifications of the sensor we found 
online.  We found that the specifications for the short range sensor online were consistent with the data we 
recorded, a graph of which is shown below.</p>
<img class="img-fluid img-centered" src="./resources/Screen Shot 2017-09-23 at 3.56.28 PM.png" alt=""> <br>

 
<p>realized that the sensors were transmitting a signal in a wide cone and were therefore detecting objects around 
the room that were not relevant.  This is the data we got from two subsequent trials for the long range sensors.</p> 
<img class="img-fluid img-centered" src="./resources/Screen Shot 2017-09-23 at 3.56.33 PM.png" alt=""> <br>

<img class="img-fluid img-centered" src="./resources/Screen Shot 2017-09-23 at 3.56.47 PM.png" alt=""> <br>


 
 
<p>We decided that because the long range sensors were more unpredictable, and because we thought the short range 
sensors would be able to more accurately predict when the robot was approaching a wall, we would implement
wall detection using short range sensors. </p>
<p>Our code for this is shown below: 
 </p>
<code>
    if (distanceValue > 100) {<br>
      <ul>wall = true;<br>
      servoL.write(90);<br>
      servoR.write(90);<br>
      delay(500);</ul>
    }    <br>
<code><br>
<p>Here is a brief video of the robot with the integrated distance sensor. As it approaches the wall, it turns at the closest junction. </p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/Q4XXFkIMMbo" frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen></iframe> <br>

                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fa fa-times"></i>
                    Close Page</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>


    <!-- Milestone 3 -->
    <div class="portfolio-modal modal fade" id="portfolioModal10" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row text-left text-dark">
              <div class="col-lg-8 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-center">Milestone 3</h2>
                    <h3> Maze Simulation </h3>
                      <p>
                      For this part of the lab, we wanted to prototype the maze navigation algorithm that would later be implemented on the robot. In Java, we implemented a Depth-First-Search (DFS) algorithm for navigating through the maze. We chose a DFS algorithm for a couple reasons. Firstly, we know that it is possible to traverse all reachable parts of the maze with a DFS algorithm. Also, we figured that a DFS, in comparison to a breadth-first search, would require the least amount of "back-tracking". Our simulation results confirmed that the DFS does an efficient job at traversing the maze.  </p>
                      <p>
                      At a very basic level, a DFS essentially entails traversing as far as possible down unexplored parts of the maze until a dead end is reached, and then backtracking to the previous junction and exploring more unexplored regions of the maze. The implementation required some mechanism for keeping track of unexplored areas, as well as previously-traveled nodes to which to travel should the robot reach a dead end or a node in which every adjacent and reachable node has been visited. 
                      </p>
                      <p>
                      There are a couple of ways to implement this kind of algorithm. A recursive, tree-based approach can implement a DFS. The downside to this approach is that it is not an intuitive way of representing the maze, especially since the 2-d rectangular maze lends itself better to an array-based representation. The upside to this node is that it is quite easy to represent adjacent and reachable nodes, and the recursive structure of the maze lends itself well to a DFS algorithm.  
                      </p>
                      <p>
                      Another way to implement a DFS is with a 2-d array to represent the maze, and additional data structures to keep track of unexplored areas and areas the robot has visited. The advantage of this system is a more intuitive way of representing the maze (which also integrates quite well with other aspects of the project). The downside is that we have to store these additional data structures, as well as implement them. In the end, we chose to implement an array-based DFS algorithm. 
                      </p>
                      <p>
                      To keep track of previously visited nodes, we chose to utilize a Stack data structure. Recall that a stack allows for "pushing" items to the "top" of the stack, and then extracting elements in a last-in, first-out (LIFO) manner. This is precisely what we need for our algorithm, since we will need to return to the last visited node should the robot hit a dead end of simply not have any more unvisited nodes in its immediate surroundings. The ideal implementation of a stack allows for amortized constant time element extraction and appending. This is achieved in the Java implementation of a stack. 
                      </p>
                      <p>
                      To keep track of unexplored regions of the maze, we utilize a Set data structure. Recall that a set stores unique elements in an unordered fashion, and allows the user to check for set containment, remove items from the set, and add items to the set. This is ideal for keeping track of unexplored regions of the maze, since we only need to store 1 copy of each unexplored region, the underlying indexing of the unexplored regiion within the set is unimportant, and we need to constantly check the set for containment, as well as perform removals and add elements. The ideal implementation of a stack allows for amortized constant execution of all these tasks (via a Hash function). This is achieved in the Java implemention. 
                      </p>
                      <p>
                      To actually store the maze, we utitlized a two dimensional Java array. Java arrays—like arrays in most languages—allow for constant time element access, removal, and updating (via indexing). This makes it very efficient at representing the maze. Note that in a tree structure, we would not be able to access an arbitrary maze coordinate in constant time, since we would need to traverse through the tree. In addition to keeping track of regions of the maze that can be occupied by the robot, the array also had to keep track of all possible locations of walls. This meant that the size of the 2d array would not be 4x5 (corresponding to the dimensions of the maze), but 7x9, in order to account for possible locations of walls. Note that the odd index values correspond to possible locations of walls, with values at these locations corresponding to the presence or non-presence of a possible wall. Additionally, locations in the maze array for which both coordinates are odd do not represent actual robot locations or potential wall locations in the maze -- these are extraneous elements that will be ignored. 
                      </p>
                      <p>
                      For the DFS simulation, we needed to somehow represent what the "actual" maze looked like. We did this by creating an <code> actualMaze </code> array of equal dimensions that encoded the actual maze that the robot would be traversing. In order to maintain the integrity of the simulation, the algorithm is only able to view adjacent elements (walls or nonwalls/open spaces) in this maze (with respect to the current position of the robot).  
                      </p>
                      <p>
                      Here's a high-level representation of the DFS algorithm. Note that the implementation of these functions can be viewed in Github repository. 
                      </p>
                      <code>
                      public class MazeNavigator {<br>
                      <ul>
                        String[][] actualMaze = new String[7][9];<br>
                        String[][] maze = new String[7][9];<br>
                        int[] currPos = new int[2];<br>
                        HashSet<String> frontierSet= new HashSet<String>(); <br>
                        Deque<int[]> visitedStack = new ArrayDeque<int[]>(); <br>
                        JFrame frame = new JFrame(); <br>
                        MazeDrawer oldMaze;
                          <br>
                          <br>
                        public MazeNavigator() throws InterruptedException {<br>
                        <ul>
                          resetMaze();<br>
                          initializeCurrentPosition();<br>
                          frontierSet.add(Arrays.toString(currPos));<br>
                          initializeActualMaze();<br>
                          visitedStack.push(currPos);<br>
                          createJFrame();<br>
                          displayActualMaze();<br>
                          while (!frontierSet.isEmpty()){<br>
                          <ul>
                            updateJFrame();<br>
                            Thread.sleep(500);<br>
                            maze[currPos[0]][currPos[1]] = "Explored"; <br>
                            removeCurrentPosFromFrontier();<br>
                            ArrayList<int[]> reachableCells = getReachableCellsAndAddWalls(); <br>
                            addUnvisitedSurroundingNodesToFrontier(reachableCells); <br>
                            updateCurrPosAndVisitedSet(reachableCells); <br>
                            if (!frontierSet.isEmpty()){ <br>
                            <ul>
                              reachableCells = getReachableCellsAndAddWalls(); <br>
                              addUnvisitedSurroundingNodesToFrontier(reachableCells); <br>
                              updateJFrame(); <br>
                              </ul>
                            }<br>
<br>
</ul>
                          }<br>
                          printDone();<br>
                        </ul>
                      }<br>
                      </code>

                      <p>
                      The class begins by instantiating the two arrays that will be used to represent the maze as it actually is (<code> actualMaze</code>), and the maze as the robot currently sees it (<code> maze </code>). We then create an <code> int </code> array to store the current position of the robot. Next, we instantiate the <code> frontierSet </code> and <code> visitedStack </code> to keep track of the frontier (unvisited) nodes and visited nodes, respectively. Two additional objects are instantiated to be used in the Java Gui. The graphics implementation will not be comprehensively discussed in this report, but the code can be viewed on Github.  </p>

                      <p>
                      Inside the instance method, we call the <code> resetMaze() </code> to reset the maze that the robot will populate with data as it travels through the maze. Next, the <code> initializeCurrentPosition() </code> is called, which assigns the initial location of the robot. The current position is added to  <code> frontierSet </code>. Note that equality for arrays is determined not by the values at each cell, but by the object reference. Due to this, we cannot simply store arrays of current location in the HashSet, since we need the HashSet to recognize two distinct arrays with the same elements as equivalent. We didn't feel like creating a new object to store the current location, and overriding the equals method, so we instead just converted the array to String form. The String literals can be properly checked for equality, so that two arrays with the same element values—which Java by default views as distinct—would be viewed as equivalent when represented as Strings. We also need to initialize the array that represents the actual maze. Inside this method body, the user can define an arbitrary maze for the robot to navigate. We then add the current position to the <code> visitedStack </code>. Note that we don't need to convert to a String form since we never need to check for equality among members of the Stack (we just need to add to the top, and remove from the top of the stack). The <code> displayActualMaze() </code> method is called, which displays the current maze contents to the GUI. 
                      </p>
                      <p>
                      The DFS is continually run so long as the robot knows that there are nodes that have been unvisited. This is what the <code> while </code> loop condition essentially entails. So while there are still unvisited nodes, we first update the GUI (<code> updateJFrame() </code>). Since we want to see the robot "traverse" the maze, we add a time delay of 500 milliseconds. We have chosen to store information about different maze locations as Strings, though this can be an Enum or another object. In Arduino, we will end up using Chars, as this is a lightweight data structure.  We update the current location to be "Explored" to reflect the fact that the robot has visited this spot. Next, we remove the current position from the <code> frontierSet </code>. Next, we generate a list of cells that are reachable from the current location. The robot finds all walls that are immediately adjacent to it and writes wall values to its maze array, and if there's no wall in a possible wall location, adds the open cell on the other side of the nonexistent wall spot to an array of reachable cells to be returned.  The code then adds unvisited surrounding nodes to the <code> frontierSet </code>. Afterwards, the program finds where it should move next and updates <code> visitedStack </code>, as needed. This method is at the crux of the DFS. Essentially, if it finds a reachable node in its immediate surroundings that hasn't been visited yet, it will move to this node. If all the reachable nodes have been visited (or if there aren't any reachable nodes), it pops from <code> visitedStack </code> and moves to this node. The final <code> if </code> statement only applies if the robot finishes traversing the maze (there are no more nodes in <code> frontierSet </code>). If the robot has reached all the reachable nodes in the maze, then it takes note of the walls in its surroundings, and writes this to the maze array. Finally, the <code> printDone </code> method is called, which prints "DONE" to the GUI to signify that the maze traversal is complete. 

                      <h4> Implementing this algorithm in Arduino </h4>

                      <p>
                      There are important considerations to keep in mind as we implement this algorithm in Arduino. Most importantly, we have severe memory restrictions in Arduino. We won't have the luxury of using memory-intensive objects to store maze data. This means that instead of using Strings and integers, which take several bytes to encode, we will likely just use Char's, which are encoded in 1 byte. We will also have to deal with the fact that Arduino doesn't come with Stacks or Set data structures, so we will have to either import an external library that implements these objects, or create our own implementation. Another thing to keep in mind is how the robot will detect its surroundings. It won't simply check values in an array. Instead, it will only be able to tell if there's a wall right next to it. We will have to create a system for translating the presence of walls next to the robot into coordinates in the maze. </p>

                      <h4> Video of simulation </h4>
                      <iframe width="560" height="315" src="https://www.youtube.com/embed/hnOv52taBwk" frameborder="0" allowfullscreen></iframe> <br>

                  <h3>Physical Implementation</h3>
                    <p>Moving out of the realm of simulation, our team needed to put in a lot of work to properly get our robot 
                    to navigate the maze. First, we had to install our new line sensors and reimplement line sensing and turning.
                    Next, we had to install and calibrate our wall sensors. Finally, we had to integrate the entire system and 
                    implement a high-level state machine to control the robot and navigate the maze. </p>

                    <h4>Lines!</h4>
                    <p>Anyone who has followed our group closely has certainly understood that we have had our fair share of 
                    struggles implementing line following. Our line sensors have always seemed a bit wonky, and our servos never
                    seemed to move in a sensible fashion. We implemented fairly hacky, non-resilient solutions to the line 
                    following/turning milestones. We decided that a solid way to move forward would be to buy a 'better' line 
                    sensor online. We turned to the Pololu QTR-3RC Reflectance Sensor Array. This particular device presented 
                    a better alternative to our existing sensors in a variety of ways: First, it integrated three sensors in one 
                    board, perfectly positioned to follow the black tape; second, it used digital connections, reducing the 
                    burden on our analog pins; third, it had an existing Arduino library. We settled on final PID control values of KP = 0.1 and KD = 0.3</p>

                    <p>Because of the aforementioned library, integrating our existing line sensing code was extremely simple. 
                    We replaced our simple analog reads with the library's sensor read methods. We also used Pololu's calibration
                    and PID control code to augment our line following. We continued using our funky servo calibration values
                    for turning. It was a straightforward and successful process, that lead to a consistent line following and turning process.</p>

                    <h4>Wall Sensing</h4>
                    <p>This was mainly just a physical task. We basically dissassembled our robot fully in order to mount two more line sensors. We took this opportunity to clean up wiring and make our robot more visually appealing. We had a bit of an issue getting wall sensing to work properly, but it turns out that we just needed to redo our soldering. Check out this photo!</p>

                    <img class="img-fluid img-centered" src="./resources/robotm3.jpg" alt=""> <br>

                    <h4>Integration</h4>
                    <p>Since this was a complicated milestone, we spent a lot of time organizing our code, preparing for integration. Beginning this milestone, our code for each module (wall detection, line sensing, treasure detection, etc.) were all in separate files. We now have a structure for our final robot code. We created a high level finite state machine, which identifies which state the robot is in (between junctions, at a junction, just starting out). Each state corresponds to different behaviors and interfaces between different modules. Here is the basic state machine:</p>
                    <code>
                    //JUNCTION state: detects walls and treasures, chooses next direction to move<br>
                    if (state == JUNCTION) {<br>
                    <br>
                      stop();<br>
                      detectWalls();<br>
                    <br>
                      if (!wallRight){<br>
                          turnRight();<br>
                          stop();<br>
                      }<br>
                      else if (!wallLeft) {<br>
                          turnLeft();<br>
                          stop();<br>
                      }<br>
                      else if (wallRight && wallMid && wallLeft) {<br>
                        turnRight();<br>
                        stop():<br>
                        turnRight();<br>
                        stop();<br>
                      }<br>
                      else {<br>
                          turnRight();<br>
                          stop();<br>
                      }<br>
                      state = BETWEEN;<br>
                    }<br>
                    //BETWEEN state: follows a line until it reaches the next junction<br>
                    if (state == BETWEEN) {<br>
                      <ul>Serial.println("BETWEEN");<br>
                      position = qtrrc.readLine(sensors);<br>
                      error = position - 1000;<br>
                      junction();<br>
                      if (isJunction) {<br>
                        <ul>state == JUNCTION;</ul>
                      }<br>
                      else  {<br>
                      <ul>goStraight();</ul>
                      }<br>
                    }<br>
                    </ul>
                    //DONE state: robot has completed task<br>
                    //TODO<br>
                    }<br>
                  </code><br>

                  <p>Before we implemented maze following, we spent time unit testing and making sure that the robot could move and navigate and detect walls (essentially reimplementing milestones 1 and 2). This proved to be a much more difficult task then first expected.</p>

                  <p>The first major integration challenge we faced was ensuring that line following continued to work. When we added all of the different code blocks together, there was a sudden change to the quality of our line following. Suddenly, the robot began to oscillate around the line much more - most worryingly, changing our PID control variables impacted it even more negatively. We hypothesized that this behavior was caused not by suboptimal PID control values, but by a multitude of print statements and excess code which delayed the PID control algorithm. As a result, the PWM control signal was updated less frequently and the robot moved jerkily. When we removed the majority of our prints statements, line following went back to working well.</p>

                  <p>Second, we struggled to implement wall sensing. Our first issue was that the wires from the IR sensor were stranded, and Michael's soldering job simply wasn't good enough (Michael is writing this, by the way). Once he (I) resoldered it, two out of the three sensors worked perfectly. However, a third sensor simply was not working, and we could not identify a hardware issue. After consulting with a TA, we commented out all FFT related code, and the wall sensor began to work. We believe that the FFT code has some sort of dependancy on the analog pin the wall sensor was on. We plan to resolve this issue once we need to.</p>

                  <p>Our third (extremely frustrating) issue was that of turning. The FSM was written on the assumption that the robot would stop at a junction - do measurements - and then turn. However our turning code did not operate in that manner: It instead detected a junction, moved forward more, then turned. This implementation was developed based on a lot of trial and error, and had the most consistent turn behavior. We had to reconcile these two turning implementations in order to get our robot to navigate the maze. You can look at the FSM code above to see our current implementation. We decided to have the junction state represent a true junction. At that point the robot pauses, detects walls around it, and then moves away. However, in order to make turning work, it moves forward first, then makes the turn. Each of the movement functions have a built in delay. This ensures that turns happen correctly.</p>

                  <p>Here is our robot using all of the above to move through a maze:</p>

                 <iframe width="560" height="315" src="https://www.youtube.com/embed/PQX7i8MVRpo" frameborder="0" allowfullscreen></iframe>

                  <p>As you could tell by the cheering in the background, this was the tenth time the robot succeeded its navigation in a row.</p>
                  <p>In order to fix the inconsistencies in the above turning behavior, we changed our robot and our algorithm. We added an additional line sensor, mounted beneath the rest of the robot. We attached it directly to an analog pin (we anticipate making a Schmitt trigger so that we can move it to a digital pin). We altered the junction detection code so that a junction was detected once the back sensor hit the tape. We then altered the turning code so that a turn ended once the back sensor hit the black tape again. This created a much more robust turning behavior.</p>

                  <code>
                  if (state == BETWEEN) {<br>
                  while(analogRead(A0)>700 && sameJunct){ <br>
                        goStraight();<br>
                      }<br>
                      sameJunct = false;<br>
                      digitalWrite(13, LOW);<br>
                      <br>
                      position = qtrrc.readLine(sensors);<br>
                      junkSensor = analogRead(A0);<br>
                      <br>
                      error = position - 1000;<br>
                      junction();<br>
                      if (isJunction) {<br>
                        state = JUNCTION;<br>
                        digitalWrite(13, HIGH);<br>
                      }<br>
                      else  {<br>
                        goStraight();<br>
                      }<br>
                    }<br>
                  </code>
                  
                  <p>After implementing the above, and playing around with our servo turn values a bit more, we created a robust turning and wall detection implementation. Here's a video of this implementation:</p>
                  

                  <iframe width="560" height="315" src="https://www.youtube.com/embed/NQ4lBzG8pRw" frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen></iframe>

                  <p>We still need to work out some kinks with left turns, but we are able to navigate the maze! In the future, we will work to implement a more comprehensive maze mapping behavior, which we did not do in this iteration.</p>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fa fa-times"></i>
                    Close Page</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Milestone 4 -->
    <div class="portfolio-modal modal fade" id="portfolioModal11" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row text-left text-dark">
              <div class="col-lg-8 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-center">Milestone 4</h2>
                  <h3>Robot Rebuilding & Physical updates</h3>
                    <p>Much of our time working on this milestone was spent making substantial changes to the robot's wiring and structure. We identified a multitude of needs that needed to be addressed through hardware, including:</p>
                      <ul>-poor power supply connections;</ul>
                      <ul>-an analog line sensor which had to move to a digital pin;</ul>
                      <ul>-a fail-safe start button;</ul>
                      <ul>-wiring up our IR phototransistors and their amplifiers; and </ul>
                      <ul>-wiring up our microphone.</ul>

                    <p>We began dealing with these issues by working on a new protoboard. This protoboard would include a new set of power rails, as well as a manual start button and a Schmitt trigger for the back line sensor. We designed the Schmitt trigger to go high at 4V, and go low and 3V, thus making it easy for us to read whether the line sensor was over white or black (see the schematic below). Our manual reset button is just a button wired between 5V and a digital input pin with a pull-down resistor to ground. We put two power rails on either side of the protoboard for ease of wiring. This ended up being a huge issue, because we used some pretty terrible header pins. In order to actually get stable connections, we needed to solder the connections. See below for pictures of the protoboard and the Schmitt trigger diagram.</p>

                    <img class="img-fluid img-centered" src="./resources/schmitt_trigger.png" alt=""> <br>
                    <p>R1=10kΩ, R2=50kΩ, R3=25kΩ, R4=50kΩ</p>

                    <img class="img-fluid img-centered" src="./resources/trigger-wave.JPG" alt=""> <br>

                    <p>The functioning Schmitt trigger output</p>

                    <img class="img-fluid img-centered" src="./resources/protoboard.JPG" alt=""> <br>

                    <p>We decided to put our treasure detection and microphone circuitry on a PCB. We used the schematics developed in Lab 2 and Milestone 3 for the microphone and IR sensors respectively. We assigned pin A0 to the microphone, A1 to be the right IR sensor, and A2 to the left IR sensor. The PCB came out really well, as you can see the schematic and final product below.</p>

                     

                
                    <img class="img-fluid img-centered" src="./resources/pcb.JPG" alt=""> <br>

                    <p> During this whole process, we made sweeping changes to our robot and its wiring, ultimately making it cleaner and easier to work with. See the below image:</p>

                    <img class="img-fluid img-centered" src="./resources/robotm4.JPG" alt=""> <br>


                  <h4> Start Detection </h4>

                  <p>
                  Since we already had all the hardware components attached, we decided to implement start detection on the robot. First, we worked on the manual start with a button. Our first issue was that the button would write "HIGH" frequently when the button was not actually pressed. However, once we grounded the button correctly with a pull-down resistor, this problem was remedied. Next, we tried implementing the FFT to detect the 660 Hz signal. In order to take up less memory, we changed the FFT from a 256-point FFT to a 128-point FFT. With the lower number of samples, we were still able to accurately detect a 660 Hz tone by checking the 10th bin on the FFT. We created two functions called <code> detectButton()</code> and <code>detectStart()</code>, which when called, checks the button and the microphone respectively, and returns true only if the button is pressed or the 660 Hz tone is being played.
                  </p>
                  <p>
                  Finally, we implemented our <code> detectButton() </code> and <code> detectStart()</code> code with the rest of our DFS. While, the button code integrated relatively easily, we had trouble including the microphone code due to the nature of the FFT process. There were two problematic lines of code in our FFT algorithm. We were writing <code>TIMSK0 = 0</code> which turns off timer0 for lower jitter and <code>ADMUX = 0x40</code> which uses <code>adc0</code>. This caused problems with our delays, which were dependent on the timer, and our wall sensing which needed the analog-to-digital converter. In order to resolve this issue, we saved the settings for these registers in a local variable at the beginning of the FFT algorithm, then wrote to the registers in the regular fashion. Then, after the FFT was calculated, we wrote back the saved register settings so it did not interfere with the rest of the code. Once this was fixed, we were able to implement start detection by using the following while loop at the beginning of our code:
                  </p>
                  <code>
<pre>
 &nbsp;<font color="#434f54">//start on 660 Hz Tone OR Button Press</font>
 &nbsp;&nbsp;<font color="#5e6d03">while</font><font color="#000000">(</font><font color="#434f54">!</font><font color="#000000">startDFS</font><font color="#000000">)</font> <font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000">set_motors</font><font color="#000000">(</font><font color="#000000">90</font><font color="#434f54">,</font><font color="#000000">90</font><font color="#000000">)</font><font color="#000000">;</font>
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#d35400">delay</font><font color="#000000">(</font><font color="#000000">25</font><font color="#000000">)</font><font color="#000000">;</font>
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000">startDFS</font> <font color="#434f54">=</font> <font color="#000000">detectStart</font><font color="#000000">(</font><font color="#000000">)</font><font color="#000000">;</font>
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000">startDFS</font> <font color="#434f54">|=</font> <font color="#000000">detectButton</font><font color="#000000">(</font><font color="#000000">)</font><font color="#000000">;</font>
 &nbsp;<font color="#000000">}</font>

</pre>
        </code>


                   <h4> Treasure Detection  </h4>


                  <p>
                  In a previous lab, our group was able to demonstrate that an analog circuit could be built, in addition to Arduino code, which would be able to detect different frequency treasures. In this lab, we took this a step further by demonstrating that this functionality can be achieved on our PCB, with multiple IR sensors, and within the framework of the existing Arduino code. One of the first challenges we faced was generating two FFTs—corresponding to the two photoresistors circuits mounted on the robot—and then deciding what treasure is present given the spectrum of both signals. We decided that in order to improve accuracy, we would take 30 frequency samples. In other words, each time the robot wanted to determine if a treasure was present in its vicinity, it would have to generate 30 unique FFTs for each IR sensor, corresponding to 30 time-domain samples of the input data for each sensor. We would identify the dominant frequency present in each sample in the same manner as in a previous lab. However, instead of simply returning what the frequency detected in a single voltage sample is, we would look at the frequencies that were most frequently represented among the 30 spectra. The Arduino code would determine that no treasure was in its immediate vicinity if no dominant IR frequency was dected for both sensors. The Arduino code would determine that a 7 kHz signal was present if one of the sensors detected a 7 Khz signal for most of its samples, and the other one detected no frequency for one of its samples, or vice-versa. A similar process was employed for 12 kHz and 17 Khz signals. This procedure ensures more reliable detection, with fewer false positives and false negatives. 
                  <br />
                                    <br />

                  Below is a video of the robot detecting frequencies. Although it is hard to read the serial messages, the integers 0,1,2,3 are printed out corresponding to no treasure, 7 kHz treasure, 12 kHz treasure, and 17 kHz treasure, respectively:
                  <br />
                  </p>
                  <iframe width="560" height="315" src="https://www.youtube.com/embed/OME9VeLte6U" frameborder="0" allowfullscreen></iframe>
                  <br />
                  <br />

               

                  <h4>DFS Integration</h4>

                    <p> We had already developed a working  DFS algorithm in Java. There were a couple of important tasks that we had to take care of in order to have the robot perform the DFS. Firstly, we needed to keep track of the orientation of the robot with respect to the coordinate system of the array. This is important because we need some way to map relative wall values to actual elements in the array. Secondly, we needed to utilize data structures that are present in the standard Java SDK but not in Arduino. Fortunately, we were able to implement these functionalities. <p>

                    <p> One of the ways in which we kept track of orientation involved adding a module called <code> generateNewDirection</code>.  This module takes in two <code>char</code> inputs: one representing the current orientation of the robot, and one representing the displacement direction. Using these two inputs, this module would output the resultant direction. This was particularly useful in translating relative wall data from the robot into array indices, which was also used in determining reachable cells for a given robot location. Below is code that we developed that would achieve this functionality: </p>
                    
                      <code>
                   <pre>
<font color="#00979c">char</font> <font color="#000000">generateNewDirection</font><font color="#000000">(</font><font color="#00979c">char</font> <font color="#000000">currOrientation</font><font color="#434f54">,</font> <font color="#00979c">char</font> <font color="#000000">displacementOrientation</font><font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;<font color="#434f54">//go north</font>
 &nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">(</font><font color="#000000">currOrientation</font><font color="#434f54">==</font><font color="#000000">North</font> <font color="#434f54">&&</font> <font color="#000000">displacementOrientation</font><font color="#434f54">==</font><font color="#000000">Straight</font><font color="#000000">)</font> <font color="#434f54">||</font> <font color="#434f54">//facing north, looking in front </font>
 &nbsp;<font color="#000000">(</font><font color="#000000">currOrientation</font><font color="#434f54">==</font><font color="#000000">East</font> <font color="#434f54">&&</font> <font color="#000000">displacementOrientation</font><font color="#434f54">==</font><font color="#000000">Left</font><font color="#000000">)</font> <font color="#434f54">||</font> <font color="#434f54">//facing east, looking left</font>
 &nbsp;<font color="#000000">(</font><font color="#000000">currOrientation</font><font color="#434f54">==</font><font color="#000000">South</font> <font color="#434f54">&&</font> <font color="#000000">displacementOrientation</font><font color="#434f54">==</font><font color="#000000">Backwards</font><font color="#000000">)</font> <font color="#434f54">||</font> <font color="#434f54">// facing south, looking behind</font>
 &nbsp;<font color="#000000">(</font><font color="#000000">currOrientation</font><font color="#434f54">==</font><font color="#000000">West</font> <font color="#434f54">&&</font> <font color="#000000">displacementOrientation</font><font color="#434f54">==</font><font color="#000000">Right</font><font color="#000000">)</font><font color="#000000">)</font><font color="#000000">{</font> <font color="#434f54">// facing west, looking right</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">return</font> <font color="#000000">North</font><font color="#000000">;</font>
 &nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#434f54">//go east</font>
 &nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">(</font><font color="#000000">currOrientation</font><font color="#434f54">==</font><font color="#000000">North</font> <font color="#434f54">&&</font> <font color="#000000">displacementOrientation</font><font color="#434f54">==</font><font color="#000000">Right</font><font color="#000000">)</font> <font color="#434f54">||</font> <font color="#434f54">//facing north, looking right</font>
 &nbsp;<font color="#000000">(</font><font color="#000000">currOrientation</font><font color="#434f54">==</font><font color="#000000">East</font> <font color="#434f54">&&</font> <font color="#000000">displacementOrientation</font><font color="#434f54">==</font><font color="#000000">Straight</font><font color="#000000">)</font> <font color="#434f54">||</font> <font color="#434f54">//facing east, looking in front</font>
 &nbsp;<font color="#000000">(</font><font color="#000000">currOrientation</font><font color="#434f54">==</font><font color="#000000">South</font> <font color="#434f54">&&</font> <font color="#000000">displacementOrientation</font><font color="#434f54">==</font><font color="#000000">Left</font><font color="#000000">)</font> <font color="#434f54">||</font> <font color="#434f54">// facing south, looking left</font>
 &nbsp;<font color="#000000">(</font><font color="#000000">currOrientation</font><font color="#434f54">==</font><font color="#000000">West</font> <font color="#434f54">&&</font> <font color="#000000">displacementOrientation</font><font color="#434f54">==</font><font color="#000000">Backwards</font><font color="#000000">)</font><font color="#000000">)</font><font color="#000000">{</font> <font color="#434f54">//facing west, looking behind</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">return</font> <font color="#000000">East</font><font color="#000000">;</font>
 &nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#434f54">//go south</font>
 &nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">(</font><font color="#000000">currOrientation</font><font color="#434f54">==</font><font color="#000000">North</font> <font color="#434f54">&&</font> <font color="#000000">displacementOrientation</font><font color="#434f54">==</font><font color="#000000">Backwards</font><font color="#000000">)</font> <font color="#434f54">||</font> <font color="#434f54">//facing north, looking behind</font>
 &nbsp;<font color="#000000">(</font><font color="#000000">currOrientation</font><font color="#434f54">==</font><font color="#000000">East</font> <font color="#434f54">&&</font> <font color="#000000">displacementOrientation</font><font color="#434f54">==</font><font color="#000000">Right</font><font color="#000000">)</font> <font color="#434f54">||</font> <font color="#434f54">//facing east, looking right</font>
 &nbsp;<font color="#000000">(</font><font color="#000000">currOrientation</font><font color="#434f54">==</font><font color="#000000">South</font> <font color="#434f54">&&</font> <font color="#000000">displacementOrientation</font><font color="#434f54">==</font><font color="#000000">Straight</font><font color="#000000">)</font> <font color="#434f54">||</font> <font color="#434f54">// facing south, looking in front</font>
 &nbsp;<font color="#000000">(</font><font color="#000000">currOrientation</font><font color="#434f54">==</font><font color="#000000">West</font> <font color="#434f54">&&</font> <font color="#000000">displacementOrientation</font><font color="#434f54">==</font><font color="#000000">Left</font><font color="#000000">)</font><font color="#000000">)</font><font color="#000000">{</font> <font color="#434f54">// facing west, looking left</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">return</font> <font color="#000000">South</font><font color="#000000">;</font>
 &nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#434f54">//go west</font>
 &nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">(</font><font color="#000000">currOrientation</font><font color="#434f54">==</font><font color="#000000">North</font> <font color="#434f54">&&</font> <font color="#000000">displacementOrientation</font><font color="#434f54">==</font><font color="#000000">Left</font><font color="#000000">)</font> <font color="#434f54">||</font> <font color="#434f54">//facing north, looking left</font>
 &nbsp;<font color="#000000">(</font><font color="#000000">currOrientation</font><font color="#434f54">==</font><font color="#000000">East</font> <font color="#434f54">&&</font> <font color="#000000">displacementOrientation</font><font color="#434f54">==</font><font color="#000000">Backwards</font><font color="#000000">)</font> <font color="#434f54">||</font> <font color="#434f54">//facing east, looking behind</font>
 &nbsp;<font color="#000000">(</font><font color="#000000">currOrientation</font><font color="#434f54">==</font><font color="#000000">South</font> <font color="#434f54">&&</font> <font color="#000000">displacementOrientation</font><font color="#434f54">==</font><font color="#000000">Right</font><font color="#000000">)</font> <font color="#434f54">||</font> <font color="#434f54">// facing south, looking right</font>
 &nbsp;<font color="#000000">(</font><font color="#000000">currOrientation</font><font color="#434f54">==</font><font color="#000000">West</font> <font color="#434f54">&&</font> <font color="#000000">displacementOrientation</font><font color="#434f54">==</font><font color="#000000">Straight</font><font color="#000000">)</font><font color="#000000">)</font><font color="#000000">{</font> <font color="#434f54">// facing west, looking in fornt</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">return</font> <font color="#000000">West</font><font color="#000000">;</font>
 &nbsp;<font color="#000000">}</font> 
 &nbsp;
<font color="#000000">}</font>

</pre>
                        
                    </code>
                      
        <p> We also had to calculate directions when deciding where the robot should turn after it updates its position in the array. To do this, we simply find the difference between the robots current position (the position the robot is being moved to) and the robots previous position. We use these values, in conjunction with the current orientation of the robot, to generate the next move the robot should make.</p>

        <code>
<pre>
<font color="#00979c">void</font> <font color="#000000">updateMove</font><font color="#000000">(</font><font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;
 &nbsp;<font color="#00979c">int</font> <font color="#000000">dx</font> <font color="#434f54">=</font> <font color="#000000">(</font><font color="#00979c">int</font><font color="#000000">)</font><font color="#000000">currPos</font><font color="#000000">[</font><font color="#000000">0</font><font color="#000000">]</font> <font color="#434f54">-</font> <font color="#000000">(</font><font color="#00979c">int</font><font color="#000000">)</font><font color="#000000">prevPos</font><font color="#000000">[</font><font color="#000000">0</font><font color="#000000">]</font><font color="#000000">;</font>
 &nbsp;<font color="#00979c">int</font> <font color="#000000">dy</font> <font color="#434f54">=</font> <font color="#000000">(</font><font color="#00979c">int</font><font color="#000000">)</font><font color="#000000">currPos</font><font color="#000000">[</font><font color="#000000">1</font><font color="#000000">]</font> <font color="#434f54">-</font> <font color="#000000">(</font><font color="#00979c">int</font><font color="#000000">)</font><font color="#000000">prevPos</font><font color="#000000">[</font><font color="#000000">1</font><font color="#000000">]</font><font color="#000000">;</font>
 &nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">(</font><font color="#000000">dx</font> <font color="#434f54">==</font> <font color="#000000">2</font> <font color="#434f54">&&</font> <font color="#000000">currentOrientation</font><font color="#434f54">==</font><font color="#000000">East</font><font color="#000000">)</font> <font color="#434f54">//displace east, facing east</font>
 &nbsp;&nbsp;&nbsp;&nbsp;<font color="#434f54">||</font> <font color="#000000">(</font><font color="#000000">dy</font> <font color="#434f54">==</font> <font color="#434f54">-</font><font color="#000000">2</font> <font color="#434f54">&&</font> <font color="#000000">currentOrientation</font><font color="#434f54">==</font><font color="#000000">North</font><font color="#000000">)</font> <font color="#434f54">//displace north, facing north</font>
 &nbsp;&nbsp;&nbsp;&nbsp;<font color="#434f54">||</font> <font color="#000000">(</font><font color="#000000">dx</font> <font color="#434f54">==</font> <font color="#434f54">-</font><font color="#000000">2</font> <font color="#434f54">&&</font> <font color="#000000">currentOrientation</font><font color="#434f54">==</font><font color="#000000">West</font><font color="#000000">)</font> <font color="#434f54">//displace west, facing west</font>
 &nbsp;&nbsp;&nbsp;&nbsp;<font color="#434f54">||</font> <font color="#000000">(</font><font color="#000000">dy</font> <font color="#434f54">==</font> <font color="#000000">2</font> <font color="#434f54">&&</font> <font color="#000000">currentOrientation</font><font color="#434f54">==</font><font color="#000000">South</font><font color="#000000">)</font><font color="#000000">)</font><font color="#000000">{</font> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#434f54">//displace south, facing south</font>
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000">moveToPerform</font> <font color="#434f54">=</font> <font color="#000000">Straight</font><font color="#000000">;</font>
 &nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#5e6d03">else</font> <font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">(</font><font color="#000000">dy</font> <font color="#434f54">==</font> <font color="#000000">2</font> &nbsp;<font color="#434f54">&&</font> <font color="#000000">currentOrientation</font><font color="#434f54">==</font><font color="#000000">East</font><font color="#000000">)</font> <font color="#434f54">//displace south, facing east</font>
 &nbsp;&nbsp;&nbsp;&nbsp;<font color="#434f54">||</font> <font color="#000000">(</font><font color="#000000">dx</font> <font color="#434f54">==</font> <font color="#434f54">-</font><font color="#000000">2</font> <font color="#434f54">&&</font> <font color="#000000">currentOrientation</font><font color="#434f54">==</font><font color="#000000">South</font><font color="#000000">)</font> <font color="#434f54">//displace west, facing south</font>
 &nbsp;&nbsp;&nbsp;&nbsp;<font color="#434f54">||</font> <font color="#000000">(</font><font color="#000000">dy</font> <font color="#434f54">==</font> <font color="#434f54">-</font><font color="#000000">2</font> <font color="#434f54">&&</font> <font color="#000000">currentOrientation</font><font color="#434f54">==</font><font color="#000000">West</font><font color="#000000">)</font> <font color="#434f54">//displace north, facing west</font>
 &nbsp;&nbsp;&nbsp;&nbsp;<font color="#434f54">||</font> <font color="#000000">(</font><font color="#000000">dx</font> <font color="#434f54">==</font> <font color="#000000">2</font> <font color="#434f54">&&</font> <font color="#000000">currentOrientation</font><font color="#434f54">==</font><font color="#000000">North</font><font color="#000000">)</font><font color="#000000">)</font> <font color="#434f54">//displace east, facing north</font>
 &nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000">moveToPerform</font> <font color="#434f54">=</font> <font color="#000000">Right</font><font color="#000000">;</font>
 &nbsp;<font color="#000000">}</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">else</font> <font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">(</font><font color="#000000">dy</font> <font color="#434f54">==</font> <font color="#000000">2</font> &nbsp;<font color="#434f54">&&</font> <font color="#000000">currentOrientation</font><font color="#434f54">==</font><font color="#000000">North</font><font color="#000000">)</font> <font color="#434f54">//displace south, facing north</font>
 &nbsp;&nbsp;&nbsp;&nbsp;<font color="#434f54">||</font> <font color="#000000">(</font><font color="#000000">dx</font> <font color="#434f54">==</font> <font color="#434f54">-</font><font color="#000000">2</font> <font color="#434f54">&&</font> <font color="#000000">currentOrientation</font><font color="#434f54">==</font><font color="#000000">East</font><font color="#000000">)</font> <font color="#434f54">//displace west, facing east</font>
 &nbsp;&nbsp;&nbsp;&nbsp;<font color="#434f54">||</font> <font color="#000000">(</font><font color="#000000">dy</font> <font color="#434f54">==</font> <font color="#434f54">-</font><font color="#000000">2</font> <font color="#434f54">&&</font> <font color="#000000">currentOrientation</font><font color="#434f54">==</font><font color="#000000">South</font><font color="#000000">)</font> <font color="#434f54">//displace north, facing south</font>
 &nbsp;&nbsp;&nbsp;&nbsp;<font color="#434f54">||</font> <font color="#000000">(</font><font color="#000000">dx</font> <font color="#434f54">==</font> <font color="#000000">2</font> <font color="#434f54">&&</font> <font color="#000000">currentOrientation</font><font color="#434f54">==</font><font color="#000000">West</font><font color="#000000">)</font><font color="#000000">)</font> <font color="#434f54">//displace east, facing west</font>
 &nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000">moveToPerform</font> <font color="#434f54">=</font> <font color="#000000">Backwards</font><font color="#000000">;</font>
 &nbsp;<font color="#000000">}</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">else</font> <font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">dy</font> <font color="#434f54">==</font><font color="#000000">0</font> <font color="#434f54">&&</font> <font color="#000000">dx</font> <font color="#434f54">==</font> <font color="#000000">0</font><font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000">moveToPerform</font> <font color="#434f54">=</font> <font color="#000000">Stop</font><font color="#000000">;</font>
 &nbsp;&nbsp;&nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#5e6d03">else</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;<font color="#000000">moveToPerform</font> <font color="#434f54">=</font> <font color="#000000">Left</font><font color="#000000">;</font>
 &nbsp;<font color="#000000">}</font>

 &nbsp;

 &nbsp;

 &nbsp;
<font color="#000000">}</font>

</pre>
        </code> 

<p> The second major order of business was to create data structures that would have the functionality of a set and stack. For the stack, we simply imported an external stack library (https://playground.arduino.cc/Code/StackArray). For the set data structure, we created a 1 dimensional array of 20 elements that can handle all 20 possible elements that could theoretically be added to the frontier set. We were able to map the 2d indices of the reachable cells to integers from 1-20 (see code below). In this array, each element represents a single reachable cell. If a reachable cell is in the frontier set, the value corresponding to this cell in the array would be set to 1. If the cell is not in the frontier set, the value corresponding to this cell in the array would be set to 0. Below are the helper functions we created:</p>

<code>
<pre>
 <font color="#00979c">boolean</font> <font color="#000000">containsFrontier</font><font color="#000000">(</font><font color="#00979c">char</font> <font color="#000000">coordinate</font><font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">frontier</font><font color="#000000">[</font><font color="#000000">coordinate</font><font color="#434f54">-</font><font color="#000000">1</font><font color="#000000">]</font> <font color="#434f54">==</font><font color="#000000">1</font><font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">return</font> <font color="#00979c">true</font><font color="#000000">;</font>
 &nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#5e6d03">return</font> <font color="#00979c">false</font><font color="#000000">;</font>
 <font color="#000000">}</font>

 <font color="#00979c">void</font> <font color="#000000">addToFrontier</font><font color="#000000">(</font><font color="#00979c">char</font> <font color="#000000">coordinate</font><font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#434f54">!</font><font color="#000000">containsFrontier</font><font color="#000000">(</font><font color="#000000">coordinate</font><font color="#000000">)</font><font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;<font color="#000000">frontier</font><font color="#000000">[</font><font color="#000000">coordinate</font><font color="#434f54">-</font><font color="#000000">1</font><font color="#000000">]</font> <font color="#434f54">=</font> <font color="#000000">1</font><font color="#000000">;</font>
 &nbsp;<font color="#000000">}</font>
 <font color="#000000">}</font>

 <font color="#00979c">void</font> <font color="#000000">removeFromFrontier</font><font color="#000000">(</font><font color="#00979c">char</font> <font color="#000000">coordinate</font><font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;<font color="#000000">frontier</font><font color="#000000">[</font><font color="#000000">coordinate</font><font color="#434f54">-</font><font color="#000000">1</font><font color="#000000">]</font> <font color="#434f54">=</font> <font color="#000000">0</font><font color="#000000">;</font>
 <font color="#000000">}</font>

<font color="#00979c">boolean</font> <font color="#000000">frontierIsEmpty</font><font color="#000000">(</font><font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;<font color="#5e6d03">for</font> <font color="#000000">(</font><font color="#00979c">int</font> <font color="#000000">i</font> <font color="#434f54">=</font> <font color="#000000">0</font><font color="#000000">;</font> <font color="#000000">i</font><font color="#434f54">&lt;</font><font color="#000000">20</font><font color="#000000">;</font> <font color="#000000">i</font><font color="#434f54">++</font><font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">frontier</font><font color="#000000">[</font><font color="#000000">i</font><font color="#000000">]</font> <font color="#434f54">==</font> <font color="#000000">1</font><font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#5e6d03">return</font> <font color="#00979c">false</font><font color="#000000">;</font>
 &nbsp;&nbsp;&nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#5e6d03">return</font> <font color="#00979c">true</font><font color="#000000">;</font>
<font color="#000000">}</font>

</pre>
</code>

<p>Here is how we map the 2d coordinates in the array corresponding to reachable cells to integers numbered 1-20, which are stored in the set:</p>
<code>
 
<pre>
 <font color="#00979c">char</font> <font color="#000000">convertCoordsToChar</font><font color="#000000">(</font><font color="#00979c">char</font> <font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">]</font><font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">0</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">1</font> <font color="#434f54">&&</font> <font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">1</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">1</font><font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">return</font> <font color="#000000">(</font><font color="#00979c">char</font><font color="#000000">)</font> <font color="#000000">1</font><font color="#000000">;</font> 
 &nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">0</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">3</font> <font color="#434f54">&&</font> <font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">1</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">1</font> <font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">return</font> <font color="#000000">(</font><font color="#00979c">char</font><font color="#000000">)</font> <font color="#000000">2</font><font color="#000000">;</font> 
 &nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">0</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">5</font> <font color="#434f54">&&</font> <font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">1</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">1</font> <font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">return</font> <font color="#000000">(</font><font color="#00979c">char</font><font color="#000000">)</font> <font color="#000000">3</font><font color="#000000">;</font> 
 &nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">0</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">7</font> <font color="#434f54">&&</font> <font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">1</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">1</font> <font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">return</font> <font color="#000000">(</font><font color="#00979c">char</font><font color="#000000">)</font> <font color="#000000">4</font><font color="#000000">;</font> 
 &nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">0</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">1</font> <font color="#434f54">&&</font> <font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">1</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">3</font> <font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">return</font> <font color="#000000">(</font><font color="#00979c">char</font><font color="#000000">)</font> <font color="#000000">5</font><font color="#000000">;</font> 
 &nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">0</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">3</font> <font color="#434f54">&&</font> <font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">1</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">3</font> <font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">return</font> <font color="#000000">(</font><font color="#00979c">char</font><font color="#000000">)</font> <font color="#000000">6</font><font color="#000000">;</font> 
 &nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">0</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">5</font> <font color="#434f54">&&</font> <font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">1</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">3</font> <font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">return</font> <font color="#000000">(</font><font color="#00979c">char</font><font color="#000000">)</font> <font color="#000000">7</font><font color="#000000">;</font> 
 &nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">0</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">7</font> <font color="#434f54">&&</font> <font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">1</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">3</font> <font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">return</font> <font color="#000000">(</font><font color="#00979c">char</font><font color="#000000">)</font> <font color="#000000">8</font><font color="#000000">;</font> 
 &nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">0</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">1</font> <font color="#434f54">&&</font> <font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">1</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">5</font> <font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">return</font> <font color="#000000">(</font><font color="#00979c">char</font><font color="#000000">)</font> <font color="#000000">9</font><font color="#000000">;</font> 
 &nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">0</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">3</font> <font color="#434f54">&&</font> <font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">1</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">5</font> <font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">return</font> <font color="#000000">(</font><font color="#00979c">char</font><font color="#000000">)</font> <font color="#000000">10</font><font color="#000000">;</font> 
 &nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">0</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">5</font> <font color="#434f54">&&</font> <font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">1</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">5</font> <font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">return</font> <font color="#000000">(</font><font color="#00979c">char</font><font color="#000000">)</font> <font color="#000000">11</font><font color="#000000">;</font> 
 &nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">0</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">7</font> <font color="#434f54">&&</font> <font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">1</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">5</font> <font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">return</font> <font color="#000000">(</font><font color="#00979c">char</font><font color="#000000">)</font> <font color="#000000">12</font><font color="#000000">;</font> 
 &nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">0</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">1</font> <font color="#434f54">&&</font> <font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">1</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">7</font> <font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">return</font> <font color="#000000">(</font><font color="#00979c">char</font><font color="#000000">)</font> <font color="#000000">13</font><font color="#000000">;</font> 
 &nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">0</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">3</font> <font color="#434f54">&&</font> <font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">1</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">7</font> <font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">return</font> <font color="#000000">(</font><font color="#00979c">char</font><font color="#000000">)</font> <font color="#000000">14</font><font color="#000000">;</font> 
 &nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">0</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">5</font> <font color="#434f54">&&</font> <font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">1</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">7</font> <font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">return</font> <font color="#000000">(</font><font color="#00979c">char</font><font color="#000000">)</font> <font color="#000000">15</font><font color="#000000">;</font> 
 &nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">0</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">7</font> <font color="#434f54">&&</font> <font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">1</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">7</font> <font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">return</font> <font color="#000000">(</font><font color="#00979c">char</font><font color="#000000">)</font> <font color="#000000">16</font><font color="#000000">;</font> 
 &nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">0</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">1</font> <font color="#434f54">&&</font> <font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">1</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">9</font> <font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">return</font> <font color="#000000">(</font><font color="#00979c">char</font><font color="#000000">)</font> <font color="#000000">17</font><font color="#000000">;</font> 
 &nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">0</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">3</font> <font color="#434f54">&&</font> <font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">1</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">9</font> <font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">return</font> <font color="#000000">(</font><font color="#00979c">char</font><font color="#000000">)</font> <font color="#000000">18</font><font color="#000000">;</font> 
 &nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">0</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">5</font> <font color="#434f54">&&</font> <font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">1</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">9</font> <font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">return</font> <font color="#000000">(</font><font color="#00979c">char</font><font color="#000000">)</font> <font color="#000000">19</font><font color="#000000">;</font> 
 &nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">0</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">7</font> <font color="#434f54">&&</font> <font color="#000000">coodinateArray</font><font color="#000000">[</font><font color="#000000">1</font><font color="#000000">]</font><font color="#434f54">==</font><font color="#000000">9</font> <font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">return</font> <font color="#000000">(</font><font color="#00979c">char</font><font color="#000000">)</font> <font color="#000000">20</font><font color="#000000">;</font> 
 &nbsp;<font color="#000000">}</font>
 <font color="#000000">}</font>

</pre>
                    </code>

                    <p> Note that this set data structure has constant time element retrieval, removal, and addition. It also takes constant time to check if the set is empty. This is excellent from a performance standpoint. </p>

<p> In simulation, we never had to worry about physically moving the robot from one cell to another. However, this is a critical consideration on the actual robot. As discussed earlier, we have developed a method for determining a move to make given a new current position. We have written 4 methods that perform the 4 primitive manuevers possible on the robot: moving forwards, going backwards, moving left, and moving right. Each one of these manuevers was represented by a function. Going forwards entailed going from the current junction to the next junction directly in front of the robot. Going backwards entailed first making a U-Turn, and then going to the next junction over. Going left and right involved performing a left/right turn, and then going to the next junction. At each junction, the DFS code was queried, which would generate the next move for the robot to make.  While at a junction, we also had to communicate to the Arduino base-station critical information about the robot's position and surroundings. We also had to engage the treasure and wall sensors. If the robot moves to a cell in which it completes the maze traversal, it must stop moving and communicate to the base station that it has completed the traversal. All these considerations are easily understandable from the main <code>loop</code> code, which we've included below</p>
<code>
<pre>
<font color="#00979c">void</font> <font color="#5e6d03">loop</font><font color="#000000">(</font><font color="#000000">)</font><font color="#000000">{</font>

 &nbsp;<font color="#434f54">//start on 660 Hz Tone OR Button Press</font>
 &nbsp;&nbsp;<font color="#5e6d03">while</font><font color="#000000">(</font><font color="#434f54">!</font><font color="#000000">startDFS</font><font color="#000000">)</font> <font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000">set_motors</font><font color="#000000">(</font><font color="#000000">90</font><font color="#434f54">,</font><font color="#000000">90</font><font color="#000000">)</font><font color="#000000">;</font>
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#d35400">delay</font><font color="#000000">(</font><font color="#000000">25</font><font color="#000000">)</font><font color="#000000">;</font>
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000">startDFS</font> <font color="#434f54">=</font> <font color="#000000">detectStart</font><font color="#000000">(</font><font color="#000000">)</font><font color="#000000">;</font>
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000">startDFS</font> <font color="#434f54">|=</font> <font color="#000000">detectButton</font><font color="#000000">(</font><font color="#000000">)</font><font color="#000000">;</font>
 &nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#434f54">//turns light on to tell that we started</font>
 &nbsp;<font color="#d35400">digitalWrite</font><font color="#000000">(</font><font color="#000000">13</font><font color="#434f54">,</font> <font color="#00979c">HIGH</font><font color="#000000">)</font><font color="#000000">;</font>
 &nbsp;<font color="#000000">set_motors</font><font color="#000000">(</font><font color="#000000">90</font><font color="#434f54">,</font><font color="#000000">90</font><font color="#000000">)</font><font color="#000000">;</font>
 &nbsp;<font color="#d35400">delay</font><font color="#000000">(</font><font color="#000000">500</font><font color="#000000">)</font><font color="#000000">;</font>
 &nbsp;<font color="#d35400">digitalWrite</font><font color="#000000">(</font><font color="#000000">13</font><font color="#434f54">,</font> <font color="#00979c">LOW</font><font color="#000000">)</font><font color="#000000">;</font>
 &nbsp;&nbsp;<font color="#000000">initializeCurrPos</font><font color="#000000">(</font><font color="#000000">)</font><font color="#000000">;</font>

 &nbsp;<font color="#000000">prevPos</font><font color="#000000">[</font><font color="#000000">0</font><font color="#000000">]</font> <font color="#434f54">=</font> <font color="#000000">currPos</font><font color="#000000">[</font><font color="#000000">0</font><font color="#000000">]</font><font color="#000000">;</font>
 &nbsp;<font color="#000000">prevPos</font><font color="#000000">[</font><font color="#000000">1</font><font color="#000000">]</font> <font color="#434f54">=</font> <font color="#000000">currPos</font><font color="#000000">[</font><font color="#000000">1</font><font color="#000000">]</font><font color="#000000">;</font>
 &nbsp;<font color="#000000">resetMaze</font><font color="#000000">(</font><font color="#000000">)</font><font color="#000000">;</font>
 &nbsp;<font color="#000000">initializeOrientation</font><font color="#000000">(</font><font color="#000000">)</font><font color="#000000">;</font>
 &nbsp;<font color="#000000">addToFrontier</font><font color="#000000">(</font><font color="#000000">convertCoordsToChar</font><font color="#000000">(</font><font color="#000000">currPos</font><font color="#000000">)</font><font color="#000000">)</font><font color="#000000">;</font>
 &nbsp;<font color="#000000">visitedStack</font><font color="#434f54">.</font><font color="#d35400">push</font><font color="#000000">(</font><font color="#000000">convertCoordsToChar</font><font color="#000000">(</font><font color="#000000">currPos</font><font color="#000000">)</font><font color="#000000">)</font><font color="#000000">;</font> &nbsp;

 &nbsp;<font color="#5e6d03">while</font> <font color="#000000">(</font><font color="#00979c">true</font><font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;<font color="#000000">detectWalls</font><font color="#000000">(</font><font color="#000000">)</font><font color="#000000">;</font>
 &nbsp;&nbsp;&nbsp;<font color="#000000">detectTreasures</font><font color="#000000">(</font><font color="#000000">)</font><font color="#000000">;</font>
 &nbsp;&nbsp;&nbsp;<font color="#000000">maze</font><font color="#000000">[</font><font color="#000000">currPos</font><font color="#000000">[</font><font color="#000000">0</font><font color="#000000">]</font><font color="#000000">]</font><font color="#000000">[</font><font color="#000000">currPos</font><font color="#000000">[</font><font color="#000000">1</font><font color="#000000">]</font><font color="#000000">]</font> <font color="#434f54">=</font> <font color="#000000">Explored</font><font color="#000000">;</font>
 &nbsp;&nbsp;&nbsp;<font color="#000000">removeFromFrontier</font><font color="#000000">(</font><font color="#000000">convertCoordsToChar</font><font color="#000000">(</font><font color="#000000">currPos</font><font color="#000000">)</font><font color="#000000">)</font><font color="#000000">;</font>
 &nbsp;&nbsp;&nbsp;<font color="#000000">addWallsToMaze</font><font color="#000000">(</font><font color="#000000">)</font><font color="#000000">;</font>
 &nbsp;&nbsp;&nbsp;<font color="#000000">getReachableCells</font><font color="#000000">(</font><font color="#000000">)</font><font color="#000000">;</font>
 &nbsp;&nbsp;&nbsp;<font color="#000000">addUnvisitedSurroundingNodesToFrontier</font><font color="#000000">(</font><font color="#000000">)</font><font color="#000000">;</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">if</font> <font color="#000000">(</font><font color="#000000">frontierIsEmpty</font><font color="#000000">(</font><font color="#000000">)</font><font color="#000000">)</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000">doneWithNavigation</font><font color="#000000">(</font><font color="#000000">)</font><font color="#000000">;</font>
 &nbsp;&nbsp;&nbsp;<font color="#000000">}</font>
 &nbsp;&nbsp;&nbsp;<font color="#5e6d03">else</font><font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000">recordAndTransmitData</font><font color="#000000">(</font><font color="#000000">)</font><font color="#000000">;</font> 
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000">updateCurrPosAndVisitedSet</font><font color="#000000">(</font><font color="#000000">)</font><font color="#000000">;</font>
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000">updateMove</font><font color="#000000">(</font><font color="#000000">)</font><font color="#000000">;</font>
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000">performMove</font><font color="#000000">(</font><font color="#000000">)</font><font color="#000000">;</font>
 &nbsp;&nbsp;&nbsp;<font color="#000000">}</font>

 &nbsp;<font color="#000000">}</font>

<font color="#000000">}</font>

</pre>
</code>

<p> Note how the code is executed. The first task that is performed is checking if the 660 Hz has been recieved. If it has been recieved, then the maze traversal can begin. As in simulation, the DFS algorithm begins by first initializing the current position. Unlike in simulation, we had to keep track of the previous position for the purpose of deciding how to move the robot. Inside the <code> while </code> loop, the robot detects walls and treasures. The current position is marked as Explored, and the current position is removed from the frontier set. Walls are added to the maze array, reachable cells are recorded, and then unvisited surrounding nodes are added to the frontier (to see how all these functions are implemented, check out the DFS module). If the frontier is empty (the robot finishes traversing the maze), the <code> doneWithNavigation()</code> method is called. This method sets the <code> done </code> variable to 1 (for communication to base station), and initiates the wireless data transfer to the base station. If the maze is not finished being traversed, then the robot initiates a wireless data transfer to the base station, updates the current position and visited set, decides on a move to take, and then calls the <code> performMove </code> to physically execute the move. <p>
                  
                


              






                  <h3>Verilog & Wireless Communication Updates</h3>

                  <h4> Robot transmission to base station </h4>

                  <p>
                    The robot transmits maze information to the base station in between moves. We decided that it would be most efficient to send the data in the form of a <code> word </code>. An Arduino <code>word</code> is a 16-bit data structure (see the next section for how we decided to encode the maze data within this <code>word</code>. We essentially just send over a concatenation of the two bytes that the Arduino will transmit to the FPGA). 16 bits is enough bits to encode all the information we send to the base station. We chose a compact data structure for wireless transmission since this will ensure greater reliability, as opposed to sending over many bytes of data. The only downside to this method was that it involved greater work on the part of the Arduino on the robot, since it had to assemble the <code>word</code> that is being sent over. To do this, we first assembled a <code>String</code> representing the <code>word</code>.This made it easy to concatenate strings representing different components of the data, and then convert it to a <code> word </code>. 
                  </p>

                  
                  <h4> Arduino and FPGA base station </h4>

                  <p> Implementing the base station was a culmination of work done over multiple different lab sessions. To  receive radio transmissions from the robot, we connected a tranceiver to the Arduino on the robot, as well as to an Arduino that outputs the received information to the FPGA to simulate via physical connections. </p> 

                  

                  <p> The base station arduino recieves a 16 bit <code> word </code> from the robot that describes the current position of the robot, as well as data about any adjacent walls and treasures.  The base station takes this word, and converts it into a string of length 16 with the same information.  The code for this conversion is shown below: </p>
                  <code>
                    
<pre>

<font color="#00979c">String</font> <font color="#000000">disassembleWord</font><font color="#000000">(</font><font color="#00979c">word</font> <font color="#000000">data</font><font color="#000000">)</font> <font color="#000000">{</font>
 &nbsp;<font color="#00979c">String</font> <font color="#000000">stringToReturn</font><font color="#000000">;</font>
 &nbsp;<font color="#5e6d03">for</font> <font color="#000000">(</font><font color="#00979c">int</font> <font color="#000000">i</font> <font color="#434f54">=</font> <font color="#000000">0</font><font color="#000000">;</font> <font color="#000000">i</font> <font color="#434f54">&lt;</font> <font color="#000000">16</font><font color="#000000">;</font> <font color="#000000">i</font><font color="#434f54">++</font><font color="#000000">)</font> <font color="#000000">{</font>
 &nbsp;&nbsp;&nbsp;<font color="#00979c">int</font> <font color="#000000">bitIndex</font> <font color="#434f54">=</font> <font color="#000000">15</font> <font color="#434f54">-</font> <font color="#000000">i</font><font color="#000000">;</font>
 &nbsp;&nbsp;&nbsp;<font color="#000000">stringToReturn</font> <font color="#434f54">+=</font> <font color="#00979c">String</font><font color="#000000">(</font><font color="#d35400">bitRead</font><font color="#000000">(</font><font color="#000000">data</font><font color="#434f54">,</font> <font color="#000000">bitIndex</font><font color="#000000">)</font><font color="#000000">)</font><font color="#000000">;</font>
 &nbsp;<font color="#000000">}</font>
 &nbsp;<font color="#5e6d03">return</font> <font color="#000000">stringToReturn</font><font color="#000000">;</font>
<font color="#000000">}</font>

</pre>
                         </code>
                    <p> We then decode the information from this string and write the data to output pins that will communicate with the FPGA.  To do this, we made an indication bit that would be zero when we were communicating information about walls and treasures, and one when we were communicating information about the position of the robot.  In our arduino code, we wrote this indication bit high, and sent out a byte of data about the position of the robot.  We then set a valid bit low and then high after a delay to give time for all our inputs to change before verilog updated the inputs on the FPGA on the rising edge of this valid bit.  We did the same thing for the walls and treasures, setting indication bit low, sending the relevant data from the string, and then setting valid low and high after a delay. Below is a diagram of how the byte is organized. Also note that the word being sent from the robot to the base station is essentially the concatenation of these bytes together. </p>

                  


                  <img class="img-fluid img-centered" src="./resources/bitdiagram.jpg" alt=""> <br>
                      <code> 
                   <br> always @ (posedge valid) begin <br> 
                      <ul> preX = robotX;<br>
                          preY = robotY;<br>
<br>
                          if (arduinoInput[6] == 1'b1) begin<br>
                            <ul>updateType = 1'b0;<br>
                            robotX = arduinoInput[5:4];<br>
                            robotY = arduinoInput[3:1];<br>
                            done = arduinoInput[0]; </ul><br>
                          end<br>
                          <br>if (arduinoInput[6] == 1'b0) begin<br>
                            <ul>updateType = 1'b1;<br>
                            walls = arduinoInput[5:2];<br>
                            treasure = arduinoInput[1:0];</ul><br>
                          end </ul><br>
                      end </code><br>



                  <p> From there, the FPGA has to update the grid based on changes in input. If new location information comes in, the coordinate specified in the transmitted byte must have its color updated to reflect the movement of the robot. At reset, every coordinate is assigned an 8'b0 to represent that no updates from the robot have been received yet. The FPGA has been programmed to store the information in each coordinate of the grid in this manner: 

                  <img class="img-fluid img-centered" src="./resources/verilogdiagram.jpg" alt=""> <br>

                  <code>
                     always @ (posedge CLOCK_25) begin <br>
<br>
                        <ul> grid1[preX][preY] = grid1[preX][preY] & 8'b11111101;<br>
<br>
                        if (updateType == 1'b0) begin         // if location update<br>
<br>
                          <ul> grid1[botX][botY] = grid1[botX][botY] & 8'b11111100;<br>
                          grid1[botX][botY] = grid1[botX][botY] | currPos; </ul><br>
<br>
                        end else begin                        // if wall/treasure update<br>
                          <ul>grid1[botX][botY] = {wall,tres,currPos};</ul><br>
<br>
                        end </ul><br>
                     end<br>

                  </code><br>

                  <p> Our grids are 96x96 square pixels so to draw walls, treasures, explored grids, and the robot icon appropriately, when changing the pixel color, we not only have to pay attention to the appropriate bit but also the position of the pixel we're changing. For example, to draw walls, we restrict the bounds of the wall that is drawn to be only 4 pixels wide. 

                    <code> 
                        if (PIXEL_COORD_X<=(10'd4+(GRID_X*10'd96)) && PIXEL_COORD_X>=(GRID_X*10'd96) && currentGrid[6] == 1'b1) begin  //right wall <br>
                            <ul>PIXEL_COLOR <= black;</ul> <br>
                          end else 
                    </code> <br> <br> 

                    <p> These are the colors we chose to represent the various items in our display: </p> 
                      <code> 
                       localparam white = 8'b11111111; //unexplored<br>
                       localparam black = 8'b0; //walls<br>
                       localparam pink = 8'b11110011; //explored<br>
                       localparam magenta = 8'b11100011; //botbotbot<br>
                       localparam red = 8'b11100000;  // 7kHz treasure Freq (2'b01)<br>
                       localparam blue = 8'b00110011; //12kHz treasure Freq (2'b10)<br>
                       localparam green = 8'b01010001; // 17 kHZ treasure Freq (2'b11) </code><br>
                    <br>

                    <p> And here's a video of what the functionality looks like in action: </p> 

                    <iframe width="560" height="315" src="https://www.youtube.com/embed/3TE-e3mRpMw" frameborder="0" allowfullscreen></iframe>

                 
</br>
</br>

 <h4> Milestone 4 Reflections </h4>

 <p>
Although we weren't able to integrate all necessary parts for Milestone 4, we came very close! The robot is easily able to traverse a maze and signal when it finishes. The treasure detection works as intended. The robot is able to send accurate maze data to the base station. The robot is also able to respond to the starting tone. Given time constraints, we weren't able to completely finish the FPGA/Base Station side of the code and integrate all the components for the milestone, though we came very close and are confident that we will be able to complete this portion of the project by the competition. Here's a video of our robot successfully traversing a maze and stopping when it's done. </p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/17Ptt6pHfHU" frameborder="0" allowfullscreen></iframe>




                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fa fa-times"></i>
                    Close Page</button>

                   

                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Modal 7 -->
    <div class="portfolio-modal modal fade" id="portfolioModal7" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row text-center">
              <div class="col-lg-8 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-uppercase">Behold, in All Its Glory</h2>
                  <p class="item-intro text-muted">The Cold-Blooded Killer</p>
                  
<a href="http://blingee.com/blingee/view/136540304-robot-blingee" target="_blank" title="robot blingee"><img alt="robot blingee" border="0" height="400" src="http://image.blingee.com/images19/content/output/000/000/000/823/871526592_1575243.gif" title="robot blingee" width="228" /></a>


                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
<!--meeting minutes modal--> 
    <div class="portfolio-modal modal fade" id="portfolioModal8" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row text-left text-dark">
              <div class="col-lg-8 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
<h2 class="text-uppercase">Minutes</h2>

<h3 class="text-uppercase">9/1 Meeting</h3>
<ul class="list-unstyled">
  <li>11:15 Upson 349</li>
  <li>Present: All</li>
  <li>Absent: None<li>
<ul>
<li>Meeting begins with pleasantries and small talk.</li>
<li>Evan discusses adding everyone to Github.</li>
<li>Turns out issue is with Cornell’s github enterprises system.</li>
<li>Evan adds everyone’s personal accounts..</li>
<li>Everyone sends Evan headshots to add to the website.</li>
<li>Begin writing the contract.</li>
<li>Various discussions about elements of the contract, etc (see contract for more details).</li>
<li>Contract signed.</li>
<li>We talk about adding more pages to the website..</li>
<li>Michael will add robot stuff to the lab1 page.</li>
<li>How to submit? Email to kirsten?</li>
</ul>
<li>MEETING ADJOURNED at 12:06PM</li>
</ul>

<h3 class="text-uppercase">9/8 Meeting</h3>
<ul class ="list-unstyled">
  <li>12:05PM Duffield </li>
  <li>Present: All</li>
  <li>Absent: None </li>
</ul>
  <li>The team discusses how nice the weather is</li>
  <li>We check everyone can update the website</li>
  <li>Discussion of lab 1 scoring</li>
  <li>Goals for the week?</li>
  <li>Basically get Lab 2 up and running</li>
  <li>Line following is scary and needs to be done</li>
  <li>Will need to implement FFT stuff</li>
</ul>
  <p> MEETING ADJOURNED at 1:00PM </p>

<h3 class="text-uppercase">9/15 Meeting</h3>
<ul class ="list-unstyled">
  <li>11:15 Kimball B11</li>
  <li>Present: All</li>
  <li>Absent: Radhika, due to illness.  We hope she feels better soon :( </li>
<ul>
<li>We discuss the work we have done on our individual subteams and deliberate on how to tackle the rest of the objectives related to lab 2 and milestone 1. </li>

<li>Optical team realizes they have not made the modifications necessary to make the Arduino light an LED in response to incident IR light, so we discuss when we can meet to work on that objective.
The robotics team explains that our robot is able to stop at junctions with extreme accuracy, but it is having trouble following a line.  We figure the reason the robot is having this trouble is because the servos that run the two wheels are not operating at the same speed.  The robotics team adds that the robot is having trouble moving forward in a straight line even when it is not attempting to follow a line, which further confirms our hypothesis. </li>
</ul>
<li>MEETING ADJOURNED at 12:06PM</li>
</ul>

<h3 class="text-uppercase">9/22 Meeting</h3>
<ul class ="list-unstyled">
  <li>12:09PM Duffield </li>
  <li>Present: All</li>
  <li>Absent: None </li>
</ul>
  <li>As individuals trickle into our meeting we discuss everyone's breakfasts</li>
  <li>TJ ate some chickpeas</li>
  <li>Progress on line sensing and turning is slow and unsteady</li>
  <li>Radhika and Katherine report that we're not sure what the issue is</li>
  <li>FFT stuff seems pretty great</li>
  <li>We finished lab 2 this week - made progress on milestone 1</li>
  <li>Discuss what we need to do in milestone 2</li>
  <li>Need to implement treasure sensing</li>
  <li>We are on track for this - evan/tj take lead</li>
  <li>Wall sensing stuff - need to implement - Frannie/Mike</li>
  <li>Radhika/Katherine will do more line stuff</li>
</ul>
  <p> MEETING ADJOURNED at 1:07PM </p>


<h3 class="text-uppercase">9/29 Meeting</h3>
<ul class="list-unstyled">
  <li>11:20AM, Hollister B11 </li>
  <li>Present: Evan, TJ, Frannie, Radhika, Katherine, Michael</li>
  <li>Absent: None </li>

<li>1. Discussed buying new IR sensor that uses digital pins </li>
  <ul>
    <li>Pros: </li>
      <ul>
        <li>only uses one digital pin, rather than 3-4 analog pins </li>
        <li>Makes line following easier</li>
      </ul>
    <Li>Cons: </li>
      <ul>
        <li>Costs go towards our budget </li>
      </ul>
    <li> Radhika will email Kirstin to try to buy part</li>
  </ul>
  <li>2. Explained Finite State Machine</li>
    <ul>
      <li>Need a method where the input is a Direction enum, and it will turn and follow a line until the next junction. </li>
    </ul>
  <li>3. Chose teams for lab 3 </li>
    <ul>

    <li>Acoustic team: TJ, Michael, Frannie</li>
    <li>Graphics team: Katherine, Radhika, Evan</li>
  </ul>


  <li>MEETING ADJOURNED at 12:05 PM</li>
</ul>

<h3 class="text-uppercase">10/6 Meeting</h3>
<ul class ="list-unstyled">
  <li>11:17 AM Duffield </li>
  <li>Present: All</li>
  <li>Absent: None </li>
<ul>
  <li> Michael sang a spontaneous (but deeply sarcastic) ode to FPGA's. TJ joined in, much to Michael's chagrin (he prefers to do his musical work alone).</li>
  <li> Michael gets offered a record deal. He flies to Los Angeles to record his single, "FPGA into My Heart." The single flops since the general public has no idea what an FPGA is. He re-joins us at our meeting--humbled but a bit jaded. </li>
  <li> Lab 3 is progressing well. Evan, Radhika, and Katherine will write up what they have so far for the FPGA visual team soon. </li> 
  <li> Michael, Frannie, and TJ are coordinating their schedules to go in for extra lab hours. </li> 
  <li> Katherine stares at a squirrel eating scavenged crumbs for an inordinate amount of time. </li></ul>
  <li> MEETING ADJOURNED at 12:10PM </li> 
  </ul>


  <h3 class="text-uppercase">10/13 Meeting</h3>
<ul class ="list-unstyled">
  <li>12:07 PM Duffield </li>
  <li>Present: All</li>
  <li>Absent: None </li>
<ul>
  <li> We greet each other and ask each other the time-old, generic post-break question: "how was ur break?" The customary response, "good," is given in exchange. </li>
  <li> OUR LINE SENSORS ARE HERE AND KATHERINE AND RADHIKA ARE SLOWLY BUT SURELY MAKING THE BOT A LITTLE LESS DUMB WITH EACH PASSING DAY. The boy will be expected to follow lines soon. Updates to come. </li>
  <li> Evan Kravitz went in to extra lab hours while others were away during fall break and made headway with the FPGA display! Thanks Evan! </li> 
  <li> We are continuing with Lab 3 machinations on Monday. </li> 
  <li> Halloween is soon. Autumn looms over us, filling us with nostalgia for simpler times. A somber mood sets in. </li> </ul>
  <li> MEETING ADJOURNED at 1:02PM </li> 
        </ul>

<h3 class="text-uppercase">10/20 Meeting</h3>

<ul class = "list-unstyled">

<li>11:20 AM, Hollister B11 </li>

<li>Present: Evan, TJ, Frannie, Radhika, Katherine, Michael </li>

<li>Absent: None</li>
 

<li>1. Lab today </li>
  <ul>
    <li>Working to combine the VGA and wireless communication teams</li>
    <li>Working to combine the VGA and wireless communication teams</li>
    <li>Need to do integration part, update maze part</li>
    <li>Idea is to send 2 8-bit arrays</li>
  </ul>
<li>2. Milestone 3 due Monday Oct 30th </li>
  <ul>
    <li>Need: </li>
    <ul>
      <li>Working algorithm that explores maze </li>
      <li>Indication that robot is done </li>
      <li>In real life and in simulation </li>
    </ul>
    <li> To do: </li>
      <ul>
        <li>Line sensing, following and turning - Katherine and Radhika </li>
        <li>Editing chassis and wall sensors - Michael, Frannie</li>
      </ul>
  </ul>
  <li>3. Future work </li>
    <ul>
      <li> PCB stuff - Michael, TJ, Katherine </li>
      <li> Algorithm - Radhika, Frannie </li>
      <li> Update website - Katherine, Evan </li>
    </ul>


<li>Motion to Adjourn: TJ</li>
<li> </li>
<li>Seconded: Evan</li>
<li>  </li>
<li>MEETING ADJOURNED at 12:05 PM</li>

<h3 class="text-uppercase">10/27 Meeting</h3>

<ul class = "list-unstyled">
<li>10/27 Meeting</li>
<li>Present: Everyone</li>

<ul>
<li>Progress on milestone 3?</li>
<li>Evan has basically finished simulation</li>
<li>It’s in Java - need to port</li>
<li>Line sensing done!!! Back on track</li>
<li>Need to implement cornering</li>
<li>Wall sensors mounting will be easy</li>
<li>Katherine making mad progress on website - looks great</li>
<li>Mike is doing some PCB stuff! Should be done after Monday</li>
<li>Seems like no urgency</li>

</ul>

<h3 class="text-uppercase">11/3 Meeting</h3>

<ul class = "list-unstyled">

<li>Present: Everyone (Franny virtually! Good luck on interviews!!!)</li>

<ul>
<li>Discussion of fortunes/fortunetellers</li>
<li>When are lab orders? Friday afternoon, Sat evening, Sun afternoon</li>
<li>What do we have to do?</li>
<li>Fully migrate code to arduino</li>
<li>Mount wall sensors</li>
<li>Turning is done!!!!!</li>
<li>Clean up the code dump</li>
<li>what classes is everyone taking next semester?</li>
<li>Today implementing wall following</li>
<li>Saturday will be implementing better things</li>
</ul>

<h3 class="text-uppercase">11/10 Meeting</h3>

<ul class = "list-unstyled">

<li>11/10 Meeting</li>
<li>Present: Everyone!!!!</li>

<li>
<ul>Discussion of cold</ul>
<ul>TJ’s hypothetical: Know the year you die or the month you die</ul>
<ul>General morbidity</ul>
<ul>Need to do ethics hw -11/27</ul>
<ul>Have team meeting next friday, will talk about topic and then write up what we talked about</ul>
<ul>Topic: Self driving cars and fatalities</ul>
<ul>Everyone read about stuff</ul>
<ul>Team evals are due this saturday!</ul>
<ul>Robot!!! Stuff!!!</ul>
<ul>Milestone 4</ul>
<ul>Need to implement DFS, combine evan + TJ code</ul>
<ul>Combine difficulty</ul>
<ul>TO-DO</ul>
<ul>Combine DFS and FSM code</ul>
<ul>Put the sensors on the robot</ul>
<ul>Solder up the power strip</ul>
<ul>Re wire/Heat shrink tubing</ul>
<ul>move our power bank</ul>
<ul>Standardize communication</ul>
<ul>Final VGA stuff</ul>
</li>

<h3 class="text-uppercase">11/13 Meeting</h3>
<ul class ="list-unstyled">
  <li>11:15 Duffield </li>
  <li>Present: All</li>
  <li>Absent: None </li>
<ul>
  <p> We got ethical in our meeting today! You can find the transcript of this meeting inside of our ethics homework under the labs tab. </p>
  <p> MEETING ADJOURNED at 1:13PM </p>
  </ul>
  <h3 class="text-uppercase">12/1 Meeting</h3>
<ul class="list-unstyled">
  <li>11:15 Phillips 437</li>
  <li>Present: All</li>
  <li>Absent: None<li>
<ul>
<li> We begin, as always, with pleasantries and small talk.</li>
<li> Discuss mutual sadness that it is our last meeting of the semester.</li>
<li> We get TJ and Rhadika up to date on what we did in lab yesterday. </li>
<li>  We inform them that we programmed our FPGA so it will run with the monitor during competition. </li>
  <li> We also fill them in on the videos we took of the robot working, which we can put on our final website.  </li>
<li> We all agree that our robot is mainly finished and now our main priority should be updating our final website. </li>
<li> We discuss who will be working on what part of the final website.  </li>
  <li> We decide upon certian section headers that we should work to fill in.  </li>
  <li> Evan will take the DFS, Robot to Base Station, and treasure detection sections. </li>
  <li> Frannie will take the wall sensing and Base Station to FPGA sections. </li>
  <li> Katherine will take the verilog implementation of final design section. </li>
  <li> Michael will take the physical robot structure section and conclusion, and help TJ with the IR section. </li>
  <li> Rhadika will take the line following section. </li>
  <li> TJ will take the introduction, as well as the microphone/ IR/ FFT section.  </li> 
  <li> Katherine will update the website and put in the videos. </li> 
  <li> TJ will make all of our pictures lower resolution so that our website does not take as long to load. </li> 
  <li> We discuss that every person in his or her corresponding section should touch upon improvements made, and possible design flaws, </li>
  <li> In addion to adding as many detailed diagrams/ useful bits of code as possible to make the sections user-friendly and easy to understand. </li>
<li>  We decide that we should try to come for about an hour on sunday to make sure everything is good to go for the competition. </li>
<li>H</li>
</ul>
<li>MEETING ADJOURNED at 12:36PM</li>
</ul>


</p>

                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fa fa-times"></i>
                    Close Page</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

        <!-- Modal 9 -->
    <div class="portfolio-modal modal fade" id="portfolioModal9" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row text-left text-dark">
              <div class="col-lg-8 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-center">TEAM CONTRACT</h2>
                    <ul class = "list-unstyled"> 
                      <li> <p class="text-center">ECE 3400, Semester #FA17 Team #1</p> </li>
<li> <p class="text-center">Team Members: Radhika Chinni, Frances Koback, TJ Hurd, Katherine Lu, Michael  Solomentsev, Evan Kravitz</p> </li>

<li> <h3 class="text-left">Team Procedures</h3> </li>
<ul>
  <li>We will plan to meet every Friday at 11:15 in the lobby of the 3rd floor of Upson Hall.  If we decide additional meetings are necessary, we will decide the date and time of the next meeting at the end of the previous meeting. If there is a lecture scheduled on Friday so that we can’t have a full-length meeting, we will discuss what works for that week during or after our lab session on Monday in Phillips 427 depending on how busy we are. </li>
  <li>The team leader will set each agenda for all meetings in the period to which he or she has been assigned the team leader position.  Put the agenda in our Google Drive folder. The team leader will send a reminder message of the location and time of the next meeting the day prior in our GroupMe. The team leader will also be responsible for making sure the agenda for each meeting has been followed and that all assignments in that time period are turned in on time.  The team leader will have it under his or her discretion to decide how to respond when the rest of the team is not following the agenda, but should definitely open an honest discussion about any slack during a weekly meeting. </li>
  <li>This team will make all decisions by majority vote. If someone is particularly knowledgeable for one part of our project, we will take their opinion into extra consideration.</li>
  <li>Meeting minutes will be taking for all group meetings, partial or full. Minutes will by default be taken by the team leader next in succession (i.e. the individual who will lead the team during the next time period). Minutes should be added to website within a few days of a meeting. </li>
  <li>All members can communicate with the larger group through GroupMe. Everyone is responsible for responding within the course of a day through appropriate messaging, gif response, or heart emoji. </li>
  <li>Any changes to this contract require a majority vote by team members.</li>
</ul>
<li> <h3 class = "text-left">Team Expectations</h3>
  <ul>
<li> <h4 class ="text-left">Work Quality:</h4> </li>
  <ul>
    <li>We agree to always peer review our work on the website and strive to create the best website we possibly can. </li> 
    <li>Individuals /sub-teams must finish their part at least a day before the deadline, foregoing extraneous circumstances.  If any individual or subteam in charge of a certain part of the project feels overwhelmed and does not think that the portion to which the team or individual is assigned can be completed in this time frame, said individual or subteam will inform the rest of the group and the group will arrange to compensate to help get the project completed.  </li>
  </ul>
<li> <h4 class ="text-left">Strategies to fulfill these standards:</h4> </li>
  <ul>
    <li>Team Participation:</li>
      <ul>
        <li>Strategies to ensure cooperation and equal distribution of tasks:
          <ul>
            <li>The team leader will accordingly delegate and monitor all tasks.</li>
          </ul>
        <li>Strategies for encouraging/including ideas from all team members (team maintenance):</li>
          <ul>
            <li>We will have open brainstorming sessions before beginning a new part of our project.</li>
          </ul>
        <li>Strategies for keeping on task (task maintenance):</li>
          <ul>
              <li>We will be trying our best to hold ourselves accountable on a mobile app called Trello which serves as a virtual to-do list which tracks the progress of each task. Anyone can add an action point or mark an action point as in progress of completed. It has a pretty user-friendly GUI interface so we probably won’t write up a tutorial for it but we can if further inquiry arises. </li>
          </ul>
        <li>Strategies to get help if you're stuck:</li>
          <ul>
              <li>Ask for team help in GroupMe.</li>
              <li>Ask a T.A. </li>
          </ul>
      </ul>

    <li>Personal Accountability:</li>
      <ul>
        <li>Expected individual attendance, punctuality, and participation at all team meetings:</li>
          <ul>
            <li>Members are expected to be on time for and participate in all meetings and give advance notice for any absences. </li>
          </ul>
        <li>Expected level of responsibility for fulfilling team assignments, timelines, and deadlines:</li>
          <ul>
            <li>Each member is required to fulfill their responsibilities as they were delegated by the team lead. Subteam members should aid each other in meeting deadlines appropriately.</li>
          </ul>
        <li>Expected level of communication with other team members:</li>
          <ul>
            <li>Each member is responsible for communicating with all other team members when they have a high work load and/or are struggling with their task. We expect team members to freely reach out to each other.</li>
          </ul>
        <li>Expected level of commitment to team decisions and tasks: </li>
          <ul>
            <li>If a majority vote has been reached, even dissenting members are responsible for seeing through the majority decision. </li>
          </ul>
        <li>How should a team member catch up if they have to miss a meeting: </li>
          <ul>
            <li>Reach out to the team leader and get assigned a task to do to make up for missed work. </li>
          </ul>
      </ul>
    <li>Consequences for Failing to Follow Procedures and Fulfill Expectations:
      <ul>
        <li>Describe how, as a group, you would handle individuals who do not live up to this contract:</li>
          <ul>
            <li>At the next meeting, group will address the issue with the person who committed the infraction.  Based on how that individual responds to this confrontation the group will determine the best course of action moving forward.  </li>
          </ul>
        <li>Describe what your team will do if these infractions continue:</li>
          <ul>
            <li>After repeated infractions, the rest of the team will collectively decide a plan of action (either speaking to course staff or reaching out to said individual).</li>
          </ul>
      </ul>
  </ul>
<li> <h3 class = "text-left">Team Leadership</h3>
  <ul>
Every person on the team will have to take the role as a leader for at least two weeks. The role of the leader will be to organize meetings and make sure that everything is submitted in a timely manner. Here are some hints on what the leader should do. Please note here who will be responsible when: 

<ul>Aug 28th - Sep 15th (Lab 1, work on lab 2): Evan Kravitz</ul>
<ul>Sep 16th - Sep 29th (Lab 2, Milestone 1 and 2): Frannie Koback</ul>
<ul>Sep 30th - Oct 20th (Lab 3, work on lab 4):Radhika Chinni</ul>
<ul>Oct 21st - Nov 3rd (Lab 4 and Milestone 3): TJ Hurd</ul>
<ul>Nov 4th - Nov 17th (Milestone 4): Katherine Lu</ul>
<ul>Nov 18th - Dec 5th (Final competition and deadline for the website): Michael Solomentsev</ul>
</ul>
<li> I participated in formulating the standards, roles, and procedures as stated in this contract.</li>
<li>I understand that I am obligated to abide by these terms and conditions.</li>
<li>I understand that if I do not abide by these terms and conditions, I will suffer the consequences as stated in this contract.</li>
         
<p class="text-left">Evan Samuel Kravitz</p>  <p class = "text-right">date: Friday, September 1, 2017</p>
<p class="text-left">Radhika Priya Chinni</p>  <p class = "text-right">date: 9/1/17</p>
<p class="text-left">Michael Yuri Solomentsev</p>  <p class = "text-right">date: 9/1/17</p>
<p class="text-left">Jeffrey Joy Hurd Jr. </p>  <p class = "text-right">date: 9/1/17</p>
<p class="text-left">Katherine Lu </p>  <p class = "text-right">date: 9/1/17</p>
<p class="text-left">Frances Lydia Koback </p>  <p class = "text-right">date: 9/1/17</p>

                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fa fa-times"></i>
                    Close Page</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>


    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

    <!-- Contact form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>
    <script src="js/contact_me.js"></script>

    <!-- Custom scripts for this template -->
    <script src="js/agency.min.js"></script>

  </body>

</html>
